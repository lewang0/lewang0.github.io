[{"content":" 这几天在整理自己以前随意记录的文字,准备喂给 ChatGPT 看看能不能做出一个 AI, 真的 Talk to Myself, 顺便放几篇到博客上来充充数\n本文写于 2018 年 8 月 28 日, 天气晴 28-33°C\n这几天上海的天气都很不错，最近一个月台风特别多，而且巧得很都是周末来。最热的夏天已经过去了，早上骑着共享单车去云台路那边的星巴克办公，大概需要骑行 15 分钟。\n每天骑车路上，总是有汽车不让路权的情形发生，没办法，肉身是斗不过杀人机器的，只好让让他们，人们的驾驶素养如此的差劲，没有好转的迹象，越来越让自己失去了对这个中国最发达城市一点点的爱。像这样的情形，几乎走在马路的人天天都会遇到，也没人愿意出来指责，姑且就这样吧。\n想起来前几天在黄浦区人民政府那栋棺材楼附近，我绿灯走人行道过马路，还被转弯的烂司机指着警告，连一旁的金发外国友人都看了瞠目结舌。本想跟他较真到底，想想还是算了，祖国的人民警察那么忙，没空来处理这样的小屁事。就算来了又如何，对司机扣 2 分罚 100 块钱能有什么用？更何况，满大街的都是没有执法权的临时工警察(辅警协警), 喊了他们也没用, 就算喊来了，他们也是会催你赶紧走，别妨碍交通。哪里还有希望，我看不到。\n不想太烦心，随他去吧，爱怎样就怎样，没人在乎。\n每天的最快乐的时光是下班回到家里。和老婆一起陪陪孩子，做做游戏，聊聊天，轻松自在。今天和娃一起玩识字的游戏，一人写，家里剩下的人认字。儿子才三岁，当然不太认识几个汉字，但是他有很强的要“赢”的心态，一旦“输”就会伤心的哭起来。我妈说很像我小时候，自尊心太强了。\n我不太认同自尊心太强这个说法。好在自己小时的那种感觉还没有完全消失，希望能帮助儿子自己找到问题（也可能不是问题），要让他知道，输了也无妨，至少可以看到自己的弱在哪里，而且能认识冠军赢家也挺好，输了也可以大方的走过去为赢家送去祝贺。更何况，很多事情根本也不是比赛，不一定要有输赢。\n","permalink":"https://lewang.dev/posts/2023-03-20-thinking-daily-1/","summary":"这几天在整理自己以前随意记录的文字,准备喂给 ChatGPT 看看能不能做出一个 AI, 真的 Talk to Myself, 顺便放几篇到博客上来充充数\n本文写于 2018 年 8 月 28 日, 天气晴 28-33°C\n这几天上海的天气都很不错，最近一个月台风特别多，而且巧得很都是周末来。最热的夏天已经过去了，早上骑着共享单车去云台路那边的星巴克办公，大概需要骑行 15 分钟。\n每天骑车路上，总是有汽车不让路权的情形发生，没办法，肉身是斗不过杀人机器的，只好让让他们，人们的驾驶素养如此的差劲，没有好转的迹象，越来越让自己失去了对这个中国最发达城市一点点的爱。像这样的情形，几乎走在马路的人天天都会遇到，也没人愿意出来指责，姑且就这样吧。\n想起来前几天在黄浦区人民政府那栋棺材楼附近，我绿灯走人行道过马路，还被转弯的烂司机指着警告，连一旁的金发外国友人都看了瞠目结舌。本想跟他较真到底，想想还是算了，祖国的人民警察那么忙，没空来处理这样的小屁事。就算来了又如何，对司机扣 2 分罚 100 块钱能有什么用？更何况，满大街的都是没有执法权的临时工警察(辅警协警), 喊了他们也没用, 就算喊来了，他们也是会催你赶紧走，别妨碍交通。哪里还有希望，我看不到。\n不想太烦心，随他去吧，爱怎样就怎样，没人在乎。\n每天的最快乐的时光是下班回到家里。和老婆一起陪陪孩子，做做游戏，聊聊天，轻松自在。今天和娃一起玩识字的游戏，一人写，家里剩下的人认字。儿子才三岁，当然不太认识几个汉字，但是他有很强的要“赢”的心态，一旦“输”就会伤心的哭起来。我妈说很像我小时候，自尊心太强了。\n我不太认同自尊心太强这个说法。好在自己小时的那种感觉还没有完全消失，希望能帮助儿子自己找到问题（也可能不是问题），要让他知道，输了也无妨，至少可以看到自己的弱在哪里，而且能认识冠军赢家也挺好，输了也可以大方的走过去为赢家送去祝贺。更何况，很多事情根本也不是比赛，不一定要有输赢。","title":"日常吐槽"},{"content":"前几天亚马逊宣告 Kindle 中国电子书店运营进行调整，通知标题写得比较委婉，其实就是亚马逊电子书即将退出中国市场，到时候我们购买的国行版 Kindle 将不能购买新电子书，也不能下载已经购买的电子书了。\n如果购买的电子书比较多，手动一本一本的去下载是挺费时间的，我来分享一下我是如何使用 Python 一键下载所有电子书的。\n安装 Python 用 Chrome 浏览器打开 https://python.org，下载最新版本的 Python 3.10.4\n下载好然后运行 python-3.10.4-amd64.exe, 选择第一个选项，一定要记得勾选添加到 PATH，否则在命令行中执行 python 时会报错。\n准备 Python 一键下载脚本 用 Chrome 浏览器打开 https://github.com/yihong0618/Kindle_download_helper，下载 ZIP 包后并且解压:\n使用 Python 一键下载脚本 进入解压后的目录，点击鼠标右键打开一个命令行窗口\n打开的命令行窗口是这样的：\n接下来准备 python 的虚拟环境，在命令行窗口输入：\npython -m venv venv 创建好虚拟环境之后，再激活虚拟环境，在命令行窗口输入：\n.\\venv\\Scripts\\activate.bat 安装 Python 脚本的依赖库，在命令行窗口输入：\npip install -r requirements.txt 至此，一键下载脚本准备就绪，在命令行窗口输入：\npython kindle.py 这样看到了脚本的帮助提示：\n接下来我们准备脚本需要的 cookie 和 csrf_token, 这两个值都需要通过 Chrome 浏览器获取。\n获取 cookie 和 csrf_token 首先使用浏览器登录亚马逊账号，\n登录地址 https://z.cn， 登录之后访问 https://www.amazon.cn/hz/mycd/myx#/home/content/booksAll/dateDsc/ 点击鼠标右键打开审查元素，\n在网络标签下，察看任意的链接，就可以找到 cookie：\n在页面上点击右键查看页面源代码\n按 Ctrl + F 搜索 csrf_token，\ncookie 和 csrf_token 找到之后，执行命令即可进行下载\npython kindle.py \u0026lt;cookie\u0026gt; \u0026lt;csrf_token\u0026gt; --is-cn 这样就可以自动下载已经购买的电子书了。\ncookie 和 csrf_token 如果过期了，重复上面的步骤获取即可。\n如何阅读下载回来的电子书 存到自己的 Kindle 中阅读 使用自己的 Kindle 序列号清除 DRM 后使用 Calibre 阅读 ","permalink":"https://lewang.dev/posts/2022-06-06-save-your-kindle-ebooks/","summary":"前几天亚马逊宣告 Kindle 中国电子书店运营进行调整，通知标题写得比较委婉，其实就是亚马逊电子书即将退出中国市场，到时候我们购买的国行版 Kindle 将不能购买新电子书，也不能下载已经购买的电子书了。\n如果购买的电子书比较多，手动一本一本的去下载是挺费时间的，我来分享一下我是如何使用 Python 一键下载所有电子书的。\n安装 Python 用 Chrome 浏览器打开 https://python.org，下载最新版本的 Python 3.10.4\n下载好然后运行 python-3.10.4-amd64.exe, 选择第一个选项，一定要记得勾选添加到 PATH，否则在命令行中执行 python 时会报错。\n准备 Python 一键下载脚本 用 Chrome 浏览器打开 https://github.com/yihong0618/Kindle_download_helper，下载 ZIP 包后并且解压:\n使用 Python 一键下载脚本 进入解压后的目录，点击鼠标右键打开一个命令行窗口\n打开的命令行窗口是这样的：\n接下来准备 python 的虚拟环境，在命令行窗口输入：\npython -m venv venv 创建好虚拟环境之后，再激活虚拟环境，在命令行窗口输入：\n.\\venv\\Scripts\\activate.bat 安装 Python 脚本的依赖库，在命令行窗口输入：\npip install -r requirements.txt 至此，一键下载脚本准备就绪，在命令行窗口输入：\npython kindle.py 这样看到了脚本的帮助提示：\n接下来我们准备脚本需要的 cookie 和 csrf_token, 这两个值都需要通过 Chrome 浏览器获取。\n获取 cookie 和 csrf_token 首先使用浏览器登录亚马逊账号，\n登录地址 https://z.cn， 登录之后访问 https://www.","title":"Kindle 中国停止运营，一键下载已购买的电子书"},{"content":"前几天刷新闻的时候，看到了一个代码仓库 YouTubeDrive 的介绍，他的作者在多年前用 Wolfram 语言（也就是 Mathematica） 编写了一段代码，可以将油管变成一个无限容量的大网盘，看完介绍之后我脑子里直接蹦出无数个“卧槽”，心里顿生“这样也行”的膜拜之情，不禁提问：这个是薅羊毛的最高境界吗？\n说起 Wolfram 语言和 Mathematica，不得不提一下，它是我学习的第一个编程语言（汇编是第二个）。多年前我是在学校机房学的，当时只用它画画数学公式的图，今天看着 YouTubeDrive 的实现，才了解到 Wolfram 还可以这样用。\n首先，和原作者一样，我也不提倡这样把 YouTube 当成一个无限容量的网盘使用，相同的道理，我也不提倡在国内把 B 站或者任意视频平台当做位无限容量的网盘来用。\n昨天在看完 YouTubeDrive 源码之后，想着要不我也用 Python 实现一个，正好傍晚溜娃的时候，啥也不能干，就边走边想，我用 Python 应该怎么来实现一个？ 在坐着等娃的时候，就用手机查下资料，大概了解了一下 numpy 和 opencv 的使用，晚上吃过晚饭就开始写了，很快也实现了一个可以工作的 Python 版的。\n我觉得这个想法还是挺有意思的，虽然不太靠谱，但是真的好玩。不想去读 Wolfram 源码的朋友可以看看我接下来的分析，看看是如何把文件变成 YouTube 视频的进行存储的。\n磁盘上的文件是什么 在我们的计算机（无论电脑还是手机都是计算机）磁盘里，存放了很多很多的文件，例如图片，文档，视频等等，每种文件都有自己的类型，或者叫格式，一般我们都会给文件添加一个后缀名展示文件的类型，但是对于电脑而言，无论是什么文件，它都只是由比特（bit） 0 和 1 组成的数据。\n例如这张图片：\n用 vim 执行命令 :%!xxd，打开是这样的：\n图片文件的头 4 个字节是 ffd8（其实 ffd8 说明了这个是 JPEG 格式的文件），ffd8 是 16 进制的表示法，比 2 进制看起来更清晰。\n在计算机里，用 8 个 bit 表示一个 byte，即 1 个字节有 8 位，一个字节需要用 2 个 16 进制数来表示，例如：ffd8 是 2 个字节。\n视频文件又是什么 视频文件也是有各种类型的，对计算机而言，视频文件也是由比特 0 和 1 组成的数据，但是视频文件的头部是有规律的，这样计算机就能区分去视频文件的类型。\n视频通过播放器播放，人类去看视频的时候，眼睛看到的其实是一帧一帧播放的图片，超过每秒 20 帧，也就是一秒中播放 20 张图片，人类的大脑就会认为这是一个连续的画面，这样的画面就叫做视频，存放这些图片数据的就是视频文件。\n我们姑且不讨论视频中声音的部分，在后续我把文件转成视频的过程中，没有产生声音。其实声音也可以用来存储数据的，比如我们可以把文件编码成摩斯密码声波存储到视频中去。\n图片是什么 既然视频是由图片组成的，那图片又是什么？我们在日常的工作或者生活中，会常常需要调整图片长宽大小，我们可以简单的用像素来表述图片的长宽，例如上面手提包图片的长宽是 1024x768, 表示长有 1024 个像素点，宽有 768 个像素点。\n每一个像素点都有一种颜色，这个颜色我们可以用 RGB 来表示。例如这样的颜色值#ff0000，表示红色，#00ff00 表示绿色，#0000ff 表示蓝色，用 3 个字节就可以表示颜色值了，颜色值还有另外的表示方法，例如红色可以用这样来表示：(ff, 00, 00) 或者 (255, 0, 0)，用了方便人类阅读，我们使用 (255, 0, 0) 这种方式来表示像素点的颜色。\n任意文件如何图片来表示 文件是一个连续的由 0 和 1 组成的二进制数据，我们可以用一个一维的十进制数组来表示这个文件：假设文件由 n 个 bit 组成，那么这个一维数组的长度就是 n，数组的每一个元素对应着文件中的每一个 bit。我们再给十进制数组的每一个元素乘以 255 后，会得到一个新的数组，如图：\n这样十进制数组每 3 个元素就可以表示一个像素点的颜色了\n我们只要准备一个足够大的图片，就可以把这个数组中的数据拷贝到这个图片中去，这样就可以把文件转成图片了。\n用视频来存放图片 我们不需要准备一张足够大的图片，我们可以用很多张小的图片来分块存储这些像素点，但是考虑到 YouTube 视频在上传后会被平台转成不同的画幅大小，所以我们可以把图片分成不同的尺寸，比如我们可以把图片分成 1280x720。\n在代码实现过程中，一张原始图片的长宽像素是 64 x 36，这样每张图片可以存储 2304 个比特位的数据，考虑到视频在平台被转码压缩后会有颜色变化，我们用 20x20 的小色块来表示一个像素点，那么 1280x720 的视频一帧恰好也是存储 2304 个比特位。\n视频我选择的 fps 是 20，也就是每秒播放 20 张图片，计算一些简单的计算，很容易就可以得到一个完整的视频。\n将视频转回文件 由于视频在转码的过程中会有一些数据丢失，在转回的过程中，需要对 20x20 的色块进行采样，计算出平均值后就很轻易的反推出比特位是 0 还是 1 了。\n代码实现 我用 Python 实现的 youtube-drive: https://github.com/lewangdev/youtube-drive 原版 Wolfram 实现的 YouTubeDrive: https://github.com/dzhang314/YouTubeDrive ","permalink":"https://lewang.dev/posts/2022-05-27-store-files-as-youtube-videos/","summary":"前几天刷新闻的时候，看到了一个代码仓库 YouTubeDrive 的介绍，他的作者在多年前用 Wolfram 语言（也就是 Mathematica） 编写了一段代码，可以将油管变成一个无限容量的大网盘，看完介绍之后我脑子里直接蹦出无数个“卧槽”，心里顿生“这样也行”的膜拜之情，不禁提问：这个是薅羊毛的最高境界吗？\n说起 Wolfram 语言和 Mathematica，不得不提一下，它是我学习的第一个编程语言（汇编是第二个）。多年前我是在学校机房学的，当时只用它画画数学公式的图，今天看着 YouTubeDrive 的实现，才了解到 Wolfram 还可以这样用。\n首先，和原作者一样，我也不提倡这样把 YouTube 当成一个无限容量的网盘使用，相同的道理，我也不提倡在国内把 B 站或者任意视频平台当做位无限容量的网盘来用。\n昨天在看完 YouTubeDrive 源码之后，想着要不我也用 Python 实现一个，正好傍晚溜娃的时候，啥也不能干，就边走边想，我用 Python 应该怎么来实现一个？ 在坐着等娃的时候，就用手机查下资料，大概了解了一下 numpy 和 opencv 的使用，晚上吃过晚饭就开始写了，很快也实现了一个可以工作的 Python 版的。\n我觉得这个想法还是挺有意思的，虽然不太靠谱，但是真的好玩。不想去读 Wolfram 源码的朋友可以看看我接下来的分析，看看是如何把文件变成 YouTube 视频的进行存储的。\n磁盘上的文件是什么 在我们的计算机（无论电脑还是手机都是计算机）磁盘里，存放了很多很多的文件，例如图片，文档，视频等等，每种文件都有自己的类型，或者叫格式，一般我们都会给文件添加一个后缀名展示文件的类型，但是对于电脑而言，无论是什么文件，它都只是由比特（bit） 0 和 1 组成的数据。\n例如这张图片：\n用 vim 执行命令 :%!xxd，打开是这样的：\n图片文件的头 4 个字节是 ffd8（其实 ffd8 说明了这个是 JPEG 格式的文件），ffd8 是 16 进制的表示法，比 2 进制看起来更清晰。\n在计算机里，用 8 个 bit 表示一个 byte，即 1 个字节有 8 位，一个字节需要用 2 个 16 进制数来表示，例如：ffd8 是 2 个字节。","title":"写个程序把油管 YouTube 变成无限容量的网盘"},{"content":"趁着周末空隙把自己年久失修博客整理了一下，用到了 grep，xargs 和 sed 命令，使用这 3 个命令组合批量替换了所有 Markdown 文件中的图片链接。\n我的博客从我的学生时代就开始了，不断折腾自己的博客，所以学会了 HTML/CSS/JS，下次和大家分享一下我的博客旅程。\n这里不详细讲解这 3 个命令的使用，这 3 个命令的使用可以写出来厚厚的一本书。如果希望详细的了解这些命令，可以在 Linux 的终端下输入这样的命令查看文档，例如查看 grep 如何使用：\nman grep man 命令的常用操作:\n退出: 按 q 键 查找：按 / 后输入查找关键字 下一页: 按 ctrl + d 或者 ctrl + f，tips: 这里的 d 大概是 down，f 大概是 forward 上一页: 按 ctrl + u 或者 ctrl + b，tips: 这里的 d 大概是 up，b 大概是 backward 查看其它命令的手册也是类似的。\n我博客的问题 我的博客是用 hugo 构建的，所有的文章都放在 post 下面的目录里，图片则需要放在 static 的 images 下面，这样在用 vscode 写博客 Markdown 的时候无法在预览里面看到图片。于是我在 hugo 项目的根目录下添加了的一个 images 的符号链接到 static 目录下的 images， 才能解决图片预览的问题。\n另外博客里面的图片越来越多也导致博客的 Git 仓库的体积越来越大，会导致上传下载都变得较慢，于是决定把博客里面的图片二进制文件单独放到一个 GitHub 仓库里面去，这个存放图片等二进制文件的仓库地址是 picb0，让博客仓库本身只保留一些主题文件和文章的 Markdown。\n开始替换 grep 使用 grep 命令查找出所有包括图片的文件，并且显示将要被替换的文件内容\ngrep -nr \u0026#39;/images\u0026#39; . 其中：\n-n: 表示查找文件的名字并且显示匹配的文件行号和内容 -r: 表示递归查找当前目录下的所有目录 输入结果是这样的：\nsed 我常用的 sed 是这样替换文件内容，一般处理单个文件内容的替换，我会直接用 vim 来进行，替换的语法和 sed 也是差不多的。\nsed -i \u0026#39;s/oldstr/newstr/g\u0026#39; filename 其中：\n-i: 表示修改文件后保持到原文件名，并且创建一个 .bak 结尾的备份 oldstr：为需要被替换的字符串 newstr：为替换后的字符串 为了修改博客 Markdown 文件的图片链接，需要这样来修改\nsed -i \u0026#39;s/\\/images/https:\\/\\/raw.githubusercontent.com\\/lewangdev\\/picb0\\/main\\/oh-my-blog/g\u0026#39; 2013-03-04-so-load-path-in-linux.markdown 注意如果 oldstr 或者 newstr 中有 / 符号，需要进行转义为 \\/, 所以这里:\noldstr \\/images newstr https:\\/\\/raw.githubusercontent.com\\/lewangdev\\/picb0\\/main\\/oh-my-blog xargs 弄清楚 grep 和 sed 之后，在使用 xargs 和|(管道符)把这几个命令连起来\ngrep -rl \u0026#34;oldstr\u0026#34; .| xargs sed -i \u0026#39;s/oldstr/newstr/g\u0026#39; grep 的 n 参数换成了 l，因为我只需要文件名 xargs 命令可以使用分割标准输入的内容作为另外一个命令的参数 替换为我博客的实际需要替换的内容：\ngrep -rl \u0026#34;/images\u0026#34; .| xargs sed -i \u0026#39;s/\\/images/https:\\/\\/raw.githubusercontent.com\\/lewangdev\\/picb0\\/main\\/oh-my-blog/g\u0026#39; 使用 git log -p 查看一下是否替换成功\n其它的替换方法 除了命令行，我们使用 ide 或者编辑器也很容易进行替换，比如 vscode 和 idea 系列的。\nvscode idea ","permalink":"https://lewang.dev/posts/2022-05-21-replace-strings-in-all-files/","summary":"趁着周末空隙把自己年久失修博客整理了一下，用到了 grep，xargs 和 sed 命令，使用这 3 个命令组合批量替换了所有 Markdown 文件中的图片链接。\n我的博客从我的学生时代就开始了，不断折腾自己的博客，所以学会了 HTML/CSS/JS，下次和大家分享一下我的博客旅程。\n这里不详细讲解这 3 个命令的使用，这 3 个命令的使用可以写出来厚厚的一本书。如果希望详细的了解这些命令，可以在 Linux 的终端下输入这样的命令查看文档，例如查看 grep 如何使用：\nman grep man 命令的常用操作:\n退出: 按 q 键 查找：按 / 后输入查找关键字 下一页: 按 ctrl + d 或者 ctrl + f，tips: 这里的 d 大概是 down，f 大概是 forward 上一页: 按 ctrl + u 或者 ctrl + b，tips: 这里的 d 大概是 up，b 大概是 backward 查看其它命令的手册也是类似的。\n我博客的问题 我的博客是用 hugo 构建的，所有的文章都放在 post 下面的目录里，图片则需要放在 static 的 images 下面，这样在用 vscode 写博客 Markdown 的时候无法在预览里面看到图片。于是我在 hugo 项目的根目录下添加了的一个 images 的符号链接到 static 目录下的 images， 才能解决图片预览的问题。","title":"grep，xargs 和 sed 的一次日常使用"},{"content":"今天要改 Docker 的两个配置 hostconfig.json 和 config.v2.json，打开一看，这个文件是单行的，在编辑器里面显示这是这样的：\n代码都堆在一起，用 vim 格式化也没啥效果，编辑起来不是很方便。\nPython 自带模块格式化 JSON 格式化 JSON 文件有很多方法，我最常用的就是 Python 自带的 json.tool 这个模块，只要安装了 Python 的电脑，都可以直接使用，这样就可以了：\npython -m json.tool hostconfig.json \u0026gt; hostconfig-formatted.json 格式化以后再打开看一看：\n这样编辑文件就方便多了。\n与管道符一起使用 前面的例子我们还可以使用管道符(|)来实现，例如:\ncat hostconfig.json | python -m json.tool \u0026gt; hostconfig-formatted.json 从 RESTful 接口直接获取数据并且格式化:\ncurl -s https://api.github.com/users/lewangdev | python -m json.tool 其它本地格式化工具 DevToysMac: MacOS 版的 DevToys or Windows，我是用 Windows 11 时候看到这个软件的，于是顺手搜了一下 MacOS 版的，也挺好用的。 jq: 除了像 sed 一样的处理 JSON 以外，还能把输出的 JSON 变成彩色的。 curl \u0026#39;https://api.github.com/users/lewangdev\u0026#39; | jq \u0026#39;.\u0026#39; 输出这样效果：\n","permalink":"https://lewang.dev/posts/2022-05-20-format-json-in-command-line-copy/","summary":"今天要改 Docker 的两个配置 hostconfig.json 和 config.v2.json，打开一看，这个文件是单行的，在编辑器里面显示这是这样的：\n代码都堆在一起，用 vim 格式化也没啥效果，编辑起来不是很方便。\nPython 自带模块格式化 JSON 格式化 JSON 文件有很多方法，我最常用的就是 Python 自带的 json.tool 这个模块，只要安装了 Python 的电脑，都可以直接使用，这样就可以了：\npython -m json.tool hostconfig.json \u0026gt; hostconfig-formatted.json 格式化以后再打开看一看：\n这样编辑文件就方便多了。\n与管道符一起使用 前面的例子我们还可以使用管道符(|)来实现，例如:\ncat hostconfig.json | python -m json.tool \u0026gt; hostconfig-formatted.json 从 RESTful 接口直接获取数据并且格式化:\ncurl -s https://api.github.com/users/lewangdev | python -m json.tool 其它本地格式化工具 DevToysMac: MacOS 版的 DevToys or Windows，我是用 Windows 11 时候看到这个软件的，于是顺手搜了一下 MacOS 版的，也挺好用的。 jq: 除了像 sed 一样的处理 JSON 以外，还能把输出的 JSON 变成彩色的。 curl \u0026#39;https://api.","title":"命令行格式化 JSON"},{"content":"本项目正在调整，请稍等再使用\n一个对国内开发者可能有点用的网络工具，cndevnet 帮助开发者，尤其是初学者不用再费心折腾 pip/npm/golang/flutter/android/blockchain 等等无法访问的问题。\n背景 由于某些原因，国内开发者需要的不少技术站点或者镜像源都无法直接访问，这使得在开发者在日常工作中会消耗额外的时间，去设置各种代理或者寻找国内的可替代的镜像源来使用。\n在开源软件的世界里，几乎所有的知名项目，原本只要把代码 clone 回来，不需要做额外任何配置，只需要按照它的说明就可以直接编译源码。但由于网络的原因，在国内甚至连开源软件的源码都不太方便直接下载，一些原本只需要从 GitHub 拉下来代码就可以直接编译成功的项目，在国内也是连编译都编译不过。\n国内开发者群体是非常庞大的，所以我看到了很多知名的开源项目为中国用户在 README.md 文档或是页面的显著位置都增加了中文提示，去引导国内开发者去使用国内的镜像。\nFlutter\npowerlevel10k\n但是，我想这种做法应该不属于 i18n，因为我很少看到有引导日本的开发者去用日本的镜像，或者引导德国的开发者去用德国的镜像，这看似解决了访问慢或者无法访问的问题，但其实是加剧了国内开发者与全球互联网的割裂，在开发者的世界里面，也形成了国内和国外两个网络。\n给系统或软件单独设置代理，或者寻找国内的可替代的镜像源我都觉得不是一个好方案，因为这样在国内的你总会遇到各种各样的国外开发者就不会遇到的问题，最好还是能够拥有一个与国外开发者“用起来”好像是一样的网络环境。\ncndevnet 就是为了解决这个问题而创建的，希望能帮助到和我一样遇到相同问题的国内开发者。\n从 Linux 开始 cndevnet 可以在 Linux 环境下搭建一个专为初学开发者设置的开发网络，搭配使用 vscode 进行远程开发是一种不错的体验，适合学习 python/golang 等。\nLinux 环境可以是在国内云平台上的一台云主机，也可以是运行在本地虚拟机里面的主机，或者是局域网中的一台 Linux 主机。\nDebian 是一个非常棒的 Linux 发行版，推荐希望学习 Linux 的初学者使用。如果希望使用带有图形界面的 Linux 系统，Ubuntu 也是一个非常好的选择。\ncndevnet 使用了以下软件和服务 Debian：目前支持的 Linux 系统 Docker: 用于运行 gost 和 smartdns 服务 gost: 用于建立 WSS(Websocket over TLS) 服务 smartdns： 用于解决 DNS 污染 dnsmasq-china-list： 国内域名 Cloudflare IP Range: Cloudflare 的 IP 范围 Cloudflare: Cloudflare 的 WSS 代理服务 Oracle Cloud: Oracle Cloud 的云主机 cndevnet 原理 cndevnet 通过 iptables 等工具和数据实现了系统的透明代理，由于是系统级的透明代理，所以在启用了 cndevnet 的 Linux 系统上，是不需要为系统或者各类开发工具或者服务单独设置代理的。\ncndevnet 是免费的 cndevnet 所使用的所有的软件都是开源免费的，另外 cndevnet 使用了 Cloudflare 的免费版域名和 CDN 服务以及 Oracle Cloud 的永久免费的云主机。\n正是因为有 Cloudflare 和 Oracle Cloud 的免费服务，我才想到可以用它们来搭建一个给国内初学者使用的开发环境。\n但是不得不说，这是一种薅羊毛的行为。资源有限，为了防止滥用，cndevnet 的密钥每天会在北京时间 0 点重新生成，如果希望继续使用，请在使用前，从 GitHub 拉取最新的代码来获取正确的密钥。\n安装和使用 请访问 cndevnet 查看。\n","permalink":"https://lewang.dev/posts/2022-05-16-cndevnet-intro/","summary":"本项目正在调整，请稍等再使用\n一个对国内开发者可能有点用的网络工具，cndevnet 帮助开发者，尤其是初学者不用再费心折腾 pip/npm/golang/flutter/android/blockchain 等等无法访问的问题。\n背景 由于某些原因，国内开发者需要的不少技术站点或者镜像源都无法直接访问，这使得在开发者在日常工作中会消耗额外的时间，去设置各种代理或者寻找国内的可替代的镜像源来使用。\n在开源软件的世界里，几乎所有的知名项目，原本只要把代码 clone 回来，不需要做额外任何配置，只需要按照它的说明就可以直接编译源码。但由于网络的原因，在国内甚至连开源软件的源码都不太方便直接下载，一些原本只需要从 GitHub 拉下来代码就可以直接编译成功的项目，在国内也是连编译都编译不过。\n国内开发者群体是非常庞大的，所以我看到了很多知名的开源项目为中国用户在 README.md 文档或是页面的显著位置都增加了中文提示，去引导国内开发者去使用国内的镜像。\nFlutter\npowerlevel10k\n但是，我想这种做法应该不属于 i18n，因为我很少看到有引导日本的开发者去用日本的镜像，或者引导德国的开发者去用德国的镜像，这看似解决了访问慢或者无法访问的问题，但其实是加剧了国内开发者与全球互联网的割裂，在开发者的世界里面，也形成了国内和国外两个网络。\n给系统或软件单独设置代理，或者寻找国内的可替代的镜像源我都觉得不是一个好方案，因为这样在国内的你总会遇到各种各样的国外开发者就不会遇到的问题，最好还是能够拥有一个与国外开发者“用起来”好像是一样的网络环境。\ncndevnet 就是为了解决这个问题而创建的，希望能帮助到和我一样遇到相同问题的国内开发者。\n从 Linux 开始 cndevnet 可以在 Linux 环境下搭建一个专为初学开发者设置的开发网络，搭配使用 vscode 进行远程开发是一种不错的体验，适合学习 python/golang 等。\nLinux 环境可以是在国内云平台上的一台云主机，也可以是运行在本地虚拟机里面的主机，或者是局域网中的一台 Linux 主机。\nDebian 是一个非常棒的 Linux 发行版，推荐希望学习 Linux 的初学者使用。如果希望使用带有图形界面的 Linux 系统，Ubuntu 也是一个非常好的选择。\ncndevnet 使用了以下软件和服务 Debian：目前支持的 Linux 系统 Docker: 用于运行 gost 和 smartdns 服务 gost: 用于建立 WSS(Websocket over TLS) 服务 smartdns： 用于解决 DNS 污染 dnsmasq-china-list： 国内域名 Cloudflare IP Range: Cloudflare 的 IP 范围 Cloudflare: Cloudflare 的 WSS 代理服务 Oracle Cloud: Oracle Cloud 的云主机 cndevnet 原理 cndevnet 通过 iptables 等工具和数据实现了系统的透明代理，由于是系统级的透明代理，所以在启用了 cndevnet 的 Linux 系统上，是不需要为系统或者各类开发工具或者服务单独设置代理的。","title":"如何打造国内开发所需要的网络"},{"content":"gost 是一个非常有用的网络工具，可以在 ShadowsocksX-NG 中安装 gost 插件，方便在 ShadowsocksX-NG 中使用 gost。\n原由 自从查资料上网工具换成 gost 之后，由于 MacOS 上没有 gost 专用的智能代理（也就是该翻的时候翻，不用翻的时候不翻）桌面客户端，所以需要用 gost 在本地把 wss 代理转成 ss 后再继续使用 ShadowsocksX-NG。 虽然可以用 launchctl 启动一个 gost 后台服务，但是用起来还是不太方便。\n看了下 ShadowsocksX-NG 是如何工作的： ShadowsocksX-NG 会在本地启动 ss-local 进程跑一个 socks5 服务，而且 ShadowsocksX-NG 实现智能代理的逻辑与 ss-local 并没有太多的关系，所以只要在想办法本地能提供一个 socks5 服务就够了。\n于是写了以下脚本替换了 ShadowsocksX-NG 安装目录下的 ss-local(替换之前要备份一下这个文件)\n#!/bin/sh - #/opt/gost/gost -L=sock5://:1086 -F=wss://username:password@1.1.1.1:443 # Use gost.json #{ # \u0026#34;Retries\u0026#34;: 3, # \u0026#34;Debug\u0026#34;: false, # \u0026#34;ServeNodes\u0026#34;: [ # \u0026#34;socks5://127.0.0.1:1086\u0026#34; # ], # \u0026#34;ChainNodes\u0026#34;: [ # \u0026#34;wss://username:password@1.1.1.1:443\u0026#34; # ] #} /opt/gost/gost -C /opt/gost/gost.json 替换之后，ShadowsocksX-NG 可以正常工作，但是这样 ShadowsocksX-NG 的其它设置就无法工作了，所以用 python3 把功能加强了一下，编写了这个脚本。\n安装插件前的准备 安装好 ShadowsocksX-NG 并至少启动过一次 系统已经安装好 python3 手动安装插件 手动安装过程包括以下几个步骤，主要是文件的替换：\n下载 gost 并解压到目录 \u0026quot;${HOME}/Library/Application Support/ShadowsocksX-NG/gost\u0026quot;， 确保 \u0026quot;${HOME}/Library/Application Support/ShadowsocksX-NG/gost\u0026quot; 目录下可执行文件名称为 gost 备份 /Applications/ShadowsocksX-NG.app/Contents/Resources/ss-local 为 /Applications/ShadowsocksX-NG.app/Contents/Resources/real-ss-local 用 https://raw.githubusercontent.com/lewangdev/gost-ss-local/master/ss-local 替换 /Applications/ShadowsocksX-NG.app/Contents/Resources/ss-local 退出 ShadowsocksX-NG 应用，再打开即可正常使用 通过自动安装脚本安装插件 把上面的手动安装的过程变成自动安装的脚本\ncurl -L https://github.com/lewangdev/ShadowsocksX-NG-GostPlugin/raw/master/gost-plugin-installer | bash 设置 ShadowsocksX-NG 客户端的配置并不能与 gost 的配置对应上，gost-ss-local 使用了 Address，Port，Password，Plugin，Plugin Opts 来设置 gost。假设 gost 在服务器 1.2.3.4 上是这样启动的：\ngost -L wss://username:password@:443 那么在 Plugin 使用 gost 之后，各参数设置如下:\nPlugin，如果希望使用 gost，那么 Plugin 需要填写 gost，例如 gost，不填或填其它内容，则与 ShadowsocksX-NG 原行为一致 Address, 表示 gost 的服务器地址，可以是 IP 或域名, 例如填写 1.2.3.4 Port, 表示 gost 的端口, 例如填写 443 Password, 由于 ShadowsocksX-NG 不能设置用户名，密码这里需要填写 gost 的用户名和密码，格式为 username:password, 例如填写 username:password Plugin Opts, 如果填写了插件参数，则前 1-3 的设置无效，并且会把 Plugin Opts 填写的内容直接全部传给 gost 命令。 1-3 的设置要求 gost 服务器端为 wss 代理，如果为其它类型的代理，可以通过设置 Plugin Opts 的参数来设置，例如与前面 1-3 等价的 Plugin Opts 配置为 -L socks5://127.0.0.1:1086 -F wss://username:password@1.2.3.4:443\n说明 目前脚本只测试了 gost，对于 SIP003 Plugin 是否影响没有做过测试，如果有问题，欢迎前往代码仓库提 Issues。\n","permalink":"https://lewang.dev/posts/2020-12-02-add-gost-plugin-for-shadowsocks-ng/","summary":"gost 是一个非常有用的网络工具，可以在 ShadowsocksX-NG 中安装 gost 插件，方便在 ShadowsocksX-NG 中使用 gost。\n原由 自从查资料上网工具换成 gost 之后，由于 MacOS 上没有 gost 专用的智能代理（也就是该翻的时候翻，不用翻的时候不翻）桌面客户端，所以需要用 gost 在本地把 wss 代理转成 ss 后再继续使用 ShadowsocksX-NG。 虽然可以用 launchctl 启动一个 gost 后台服务，但是用起来还是不太方便。\n看了下 ShadowsocksX-NG 是如何工作的： ShadowsocksX-NG 会在本地启动 ss-local 进程跑一个 socks5 服务，而且 ShadowsocksX-NG 实现智能代理的逻辑与 ss-local 并没有太多的关系，所以只要在想办法本地能提供一个 socks5 服务就够了。\n于是写了以下脚本替换了 ShadowsocksX-NG 安装目录下的 ss-local(替换之前要备份一下这个文件)\n#!/bin/sh - #/opt/gost/gost -L=sock5://:1086 -F=wss://username:password@1.1.1.1:443 # Use gost.json #{ # \u0026#34;Retries\u0026#34;: 3, # \u0026#34;Debug\u0026#34;: false, # \u0026#34;ServeNodes\u0026#34;: [ # \u0026#34;socks5://127.0.0.1:1086\u0026#34; # ], # \u0026#34;ChainNodes\u0026#34;: [ # \u0026#34;wss://username:password@1.","title":"写了一个 ShadowsocksX-NG 的 gost 插件"},{"content":"创业这段时间以来，我们的 IoT 系统已经在不少客户的机房做了私有化部署，客户大多都是机加工厂、商业大楼、医院和大学实验室等，客户的机房都有一个相同的特点：私有云，与外网隔离，不能访问互联网。或者更为准确的说，是我们部署的服务器不能访问互联网，在没有互联网访问权限的情况下，系统的包管理工具(yum/apt/docker)都无法使用了，在这种情况下进行系统部署安装，费时费力，而且无法进行远程部署维护，也大大增加了项目的实施成本。\n在最近的一个客户项目的实施过程中，看到客户的一些其他供应商在系统部署过程中非常艰难，甚至是 CentOS 系统初始化和 Docker 的安装就花掉了两个礼拜的人力，不排除一些供应商这样折腾会给他的客户留下工作敬业钱花的值的好印象，但对于我们这样的小创业公司来说，这样的时间浪费和低效是无法承担的成本，因为来实操部署的人就是公司老板本人了，我也不想出差在客户这里待上两个礼拜。\n在工作完成之后，想想可以把解决问题的方法记录一下，也许能给遇到相同问题的同行一些启发和帮助。好了，废话不多说，接下来我们就来解决这个无外网的部署问题，顺便再解决一下远程维护的问题。\n一、面临的问题 在部署和维护一个私有化企业内部使用且无互联网访问的系统中，可能会面临以下问题:\n机房服务器无法访问 Internet 可通过接入企业内网来访问服务器，而从服务器无法直连办公室网络，即机房和办公室在不同的网段 无互联网访问权限的情况下，无法直接使用系统的配置工具，如 yum/apt/docker 等，配置系统和部署服务费时费力 无法远程进行维护 客户内网拓扑示意图，此处省略了防火墙，简化拓扑图的复杂度，如下:\n网络拓扑图说明:\n机房和办公室不在一个网段 机房网段假设为 172.22.0.0/16，办公室内网 WiFi 的网段为 192.168.137.0/24 机房服务器之间是互通的，办公室可以 ping 通机房服务器，在机房服务器上无法 ping 通办公室部署控制主机，这里假设办公室网络作为一个 NAT 放在上层交换机后面 内网没有互联网访问权限，包括机房服务器和办公室内网 WiFI 二、解决问题的方法 既然是由于机房服务器没有互联网访问权限，不能联网下载安装包，那就想办法让机房服务器可以连接互联网或者搭建内网的软件包镜像服务，于是想到一些方法来达到目的:\n告知客户问题，申请开通互联网访问权限，可以限定为指定的网址和协议(HTTP/HTTPS)，需要远程维护的化，还需要申请可以连接到服务器的 VPN。这个方法在需要客户的进行审批，可能时间比较长。我们的客户中有不少都没有自建 VPN，或这不方便给我们开通 VPN，另外也无法开通需要我们部署的服务器的互联网访问权限，所以不能使用这个方法\n在客户机房放置可以通过 4G 上网的堡垒机，堡垒机接入客户机房网络。在客户机房放一个堡垒机，虽然说是堡垒机，但可能客户那边的机房管理也还是不容许放置这样的机器的，所以也不能使用这个方法\n搭建 yum(CentOS)/apt(Debian/Ubuntu)/docker 的内网镜像服务，搭建内网镜像服务可能就是一个比较艰巨的任务，难以接受给自己又添加了一个艰难的任务，此方法也作罢\n通过在办公室网里放置部署控制机，同时连接内网和 4G 路由器提供的外网(互联网)，在部署控制机上搭建 SDWAN 或者 HTTP 代理，yum/apt/docker 都支持 HTTP 代理，这样修改系统配置之后，就可以通过代理安装部署服务，这个方法比较简单，而且几乎不需要客户的参与就可以完成。不过也有一些前置条件，例如:\n办公室中主机可以接入客户网络\n客户服务器允许办公室网络中主机通过 TCP 或者 UDP 访问其任意或者指定的端口\n客户办公室的 4G 网络信号要足够好，这样可以提供更好的外网速度\n拥有服务器的 root 管理员权限(需要安装软件和修改系统配置)\n通过权衡利弊，我们最终使用的是第 4 个方法来搭建的，下面来讲讲搭建的过程。\n三、搭建可以访问互联网的部署环境 我们希望使用第 4 个方法来搭建部署的网络环境，通过测试客户的内网环境，几个前置条件都已满足，这样第 4 个方法的搭建过程不需要客户的参与就可以完成。首先要解决的是网络通路问题，我们在客户办公室添加了一台 4G 路由器，添加 4G 路由器之后的网络拓扑图如图:\n部署控制主机连接好 4G 路由器之后，获取到一个 192.168.8.106 的 IP，注意 4G 路由器的网段要与办公室网段不同，例如办公室网段是 192.168.137.0/24 (也就是子网掩码为 255.255.255.0)，4G 路由器的网段为 192.168.8.0/24，也就是说部署控制主机需要有两个网络接口(网卡)：一个接内网，一个接外网（4G 路由器），如果部署控制主机刚好有一个 RJ45 的以太网卡和一个 WiFI 网卡（很多笔记本电脑就是这样），那部署控制主机在硬件上就不需要在添加额外的硬件了。\n关于网络搭建过程中的使用到硬件就讲这些，各位读者可以根据自己的情况选用合适的网络设备，比如 4G 无线网卡，带 4G 模块的工控主机等等，原则上只要能建立一个互联网访问的通道就行了。\n接下来我们再一起探讨一下如果利用开源软件来搭建互联网访问的通道，如图：\n现在解决问题的思路应该更加清晰了：需要在机房服务器和办公室部署控制主机之间建立一个通道。建立通道可以使用的开源软件有不少，相信很多人因为某些原因都或多或少使用过，从我自己长期实际使用的经验来看，frp 和 WireGuard 非常适合用在当前情况下建立通道，gost 也十分容易搭建 HTTP 或者 SOCK5 代理。\n可以用一句话来描述搭建的过程：\n在机房一台服务器上面安装 frp 或 WireGuard 做服务端，在可以连接外网内网的部署控制主机上安装 frp 或 WireGuard 做客户端，并且在部署控制主机上安装 gost 服务启用 HTTP 代理服务，最后在服务器端的修改系统配置，让 yum 和 docker 拉镜像走 HTTP 代理。\n因为部署系统使用 HTTP 代理就够了，这样 frp + gost 的组合可能比 WireGuard + gost 的组合配置起来会更加简单，WireGuard 是一个可以用于 SDWAN 组网的高性能通道软件，本文就不说明如何使用它来搭建，如果对 WireGuard 搭建 SDWAN 感兴趣，可以自行研究一下或者留言私信给我。\n以下使用 frp + gost 来说明具体的搭建过程。\n3.1 准备需要的软件 请根据自己部署控制主机对应的平台下载需要的软件\nfrp 是一个专注于内网穿透的高性能的反向代理应用，支持 TCP、UDP、HTTP、HTTPS 等多种协议。可以将内网服务以安全、便捷的方式通过具有公网 IP 节点的中转暴露到公网。 Windows x86_64 系统请下载 frp_0.34.3_windows_amd64.zip Linux x86_64 系统请下载 frp_0.34.3_linux_amd64.tar.gz MacOS 系统请下载 frp_0.34.3_darwin_amd64.tar.gz gost 是 GO 语言实现的安全隧道 Windows x86_64 系统请下载 gost-windows-amd64-2.11.1.zip Linux x86_64 系统请下载 gost-linux-amd64-2.11.1.gz MacOS 系统请下载 gost-darwin-amd64-2.11.1.gz 如果部署控制主机是 ARM 或者 MIPS 架构的，需要上面两个软件需要下载对应的版本来安装，在使用上没有任何差异。\n3.2 配置路由和安装软件 frp 和 gost 安装都比较简单，上传到服务器上解压后就就可以了，我们只需要在其中一台机房服务器上安装 frp 作为服务端启动，机房其它服务器不需要安装 frp，总结一下需要进行的安装步骤：\n在部署控制主机上面配置路由，使得部署控制主机可以访问机房网络也可以访问互联网 其中一台机房服务器上安装 frp，作为服务端启动 部署控制主机上安装 gost，启动一个 HTTP 代理服务器 部署控制主机上安装 frp，作为客户端启动 以下部署过程以部署控制主机系统为 MacOS，机房服务器系统为 CentOS 7.6 为例，如果读者在实际部署过程中由于系统与本文不同而遇到问题不知如何解决，比如服务器为 Ubuntu，部署机是 Windows 10，欢迎留言一起探讨。\n在部署控制主机上面配置路由 如果部署控制主机和机房服务器在同一个子网，则不需要添加路由。由于本次部署控制主机和机房服务器不在一个子网，在接了两个网卡之后，在部署控制主机上的 IP 包是不知道如何路由到机房网络的，如果不做路由设置，172.22.0.0/16 网段会走系统默认的路由，可能无法访问到机房网络。所以在部署控制主机上（ MacOS 系统）添加以下路由:\nsudo route add -net 172.22.0.0/16 192.168.137.1 如果部署控制主机为 Linux 或者 Windows 也需要手动添加路由。\n在机房任意一台服务器上安装 frp 上传 frp_0.34.3_linux_amd64.tar.gz 到服务器，解压 frp_0.34.3_linux_amd64.tar.gz 安装包\n$ tar -zxvf frp_0.34.3_linux_amd64.tar.gz frp_0.34.3_linux_amd64/ frp_0.34.3_linux_amd64/frps_full.ini frp_0.34.3_linux_amd64/frps.ini frp_0.34.3_linux_amd64/frpc frp_0.34.3_linux_amd64/frpc_full.ini frp_0.34.3_linux_amd64/frps frp_0.34.3_linux_amd64/LICENSE frp_0.34.3_linux_amd64/frpc.ini 进入 frp_0.34.3_linux_amd64 目录并新建 frps-deployment.ini 文件，内容为\n[common] bind_port = 7000 找到 frps 命令后启动：\n$ ./frps -c frps-deployment.ini 2020/11/30 06:53:01 [I] [service.go:128] frps tcp listen on 0.0.0.0:7000 2020/11/30 06:53:01 [I] [root.go:190] Start frps success 如果服务无法启动，可能是 7000 端口已经被占用或者是 frps 没有执行权限，请注意具体的报错信息。\n在部署控制主机上安装 gost 解压 gost 包，并且添加执行权限\n$ gunzip gost-darwin-amd64-2.11.1.gz $ chmod +x gost-darwin-amd64-2.11.1 启动 HTTP 代理, 在端口 18080 上监听\n$ ./gost-darwin-amd64-2.11.1 -L http://:18080 在控制主机上安装 frp 解压 frp 安装包后在目录中新建 frpc-deployment.ini 文件，内容为\n[common] server_addr = 192.168.52.79 server_port = 7000 [gost] type = tcp local_ip = 127.0.0.1 local_port = 18080 remote_port = 18080 作为客户端启动 frpc\n$ ./frpc -c frpc-deployment.ini 2020/11/30 14:59:30 [I] [proxy_manager.go:300] proxy removed: [] 2020/11/30 14:59:30 [I] [proxy_manager.go:310] proxy added: [gost] 2020/11/30 14:59:30 [I] [proxy_manager.go:333] visitor removed: [] 2020/11/30 14:59:30 [I] [proxy_manager.go:342] visitor added: [] 2020/11/30 14:59:30 [I] [control.go:246] [f51d0bf5d26ef627] login to server success, get run id [f51d0bf5d26ef627], server udp port [0] 2020/11/30 14:59:30 [I] [control.go:169] [f51d0bf5d26ef627] [gost] start proxy success 至此通道就搭建完成了，如图所示。\n3.3 启用代理 机房服务器使用的都是 CentOS 7.6 的系统，需要用到的 yum 和 docker 也都支持通过 HTTP 代理进行软件包和容器镜像的下载，如果使用的是 ubuntu 系统，通过 apt 也可以配置为通过 HTTP 代理下载软件包，以下还是以 CentOS 7.6 系统为例。\nyum 启用 http 代理 修改 /etc/yum.conf 文件，添加代理配置\nproxy=http://127.0.0.1:18080 我们测试一下代理是否成功\n$ sudo yum makecache Loaded plugins: fastestmirror Loading mirror speeds from cached hostfile epel/x86_64/metalink | 23 kB 00:00:01 * base: mirrors.neusoft.edu.cn * epel: ftp.iij.ad.jp * extras: ftp.sjtu.edu.cn * updates: ftp.sjtu.edu.cn base | 3.6 kB 00:00:00 docker-ce-stable | 3.5 kB 00:00:00 epel | 4.7 kB 00:00:00 extras | 2.9 kB 00:00:00 updates | 2.9 kB 00:00:00 (2/3): epel/x86_64/primary_db 20% [=================== ] 790 kB/s | 4.6 MB 00:00:22 ETA 代理看起来没有问题，我们来安装 git 试试。\n$ sudo yum install -y git Loaded plugins: fastestmirror Loading mirror speeds from cached hostfile * base: mirrors.neusoft.edu.cn * epel: d2lzkl7pfhq30w.cloudfront.net * extras: ftp.sjtu.edu.cn * updates: ftp.sjtu.edu.cn Resolving Dependencies --\u0026gt; Running transaction check ---\u0026gt; Package git.x86_64 0:1.8.3.1-23.el7_8 will be installed --\u0026gt; Processing Dependency: perl-Git = 1.8.3.1-23.el7_8 for package: git-1.8.3.1-23.el7_8.x86_64 --\u0026gt; Processing Dependency: perl(Git) for package: git-1.8.3.1-23.el7_8.x86_64 --\u0026gt; Running transaction check ---\u0026gt; Package perl-Git.noarch 0:1.8.3.1-23.el7_8 will be installed --\u0026gt; Finished Dependency Resolution Dependencies Resolved ============================================================================================================================================================================================================================================ Package Arch Version Repository Size ============================================================================================================================================================================================================================================ Installing: git x86_64 1.8.3.1-23.el7_8 base 4.4 M Installing for dependencies: perl-Git noarch 1.8.3.1-23.el7_8 base 56 k Transaction Summary ============================================================================================================================================================================================================================================ Install 1 Package (+1 Dependent package) Total download size: 4.5 M Installed size: 22 M Downloading packages: (1/2): perl-Git-1.8.3.1-23.el7_8.noarch.rpm | 56 kB 00:00:01 (2/2): git-1.8.3.1-23.el7_8.x86_64.rpm | 4.4 MB 00:00:06 -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- Total 669 kB/s | 4.5 MB 00:00:06 Running transaction check Running transaction test Transaction test succeeded Running transaction Installing : perl-Git-1.8.3.1-23.el7_8.noarch 1/2 Installing : git-1.8.3.1-23.el7_8.x86_64 2/2 Verifying : git-1.8.3.1-23.el7_8.x86_64 1/2 Verifying : perl-Git-1.8.3.1-23.el7_8.noarch 2/2 Installed: git.x86_64 0:1.8.3.1-23.el7_8 Dependency Installed: perl-Git.noarch 0:1.8.3.1-23.el7_8 Complete! 太令人激动了，我们的代理起作用了，接下来可以愉快的安装软件了。\ndocker 启用 http 代理 首先需要通过 yum 安装 docker 服务，关于 docker 的安装本文不再说明，请参考官方文档 Install Docker Engine on CentOS。安装完 docker 服务之后，通过以下步骤来配置 Docker 服务使用 HTTP 代理\n创建目录和文件\nsudo mkdir -p /etc/systemd/system/docker.service.d sudo touch /etc/systemd/system/docker.service.d/http-proxy.conf 添加以下内容到配置文件 http-proxy.conf 中\n[Service] Environment=\u0026#34;HTTP_PROXY=http://127.0.0.1:18080\u0026#34; Environment=\u0026#34;NO_PROXY=localhost,127.0.0.1\u0026#34; 重启 docker 服务，使得配置生效\nsudo systemctl daemon-reload sudo systemctl restart docker 验证配置\nsudo systemctl show --property=Environment docker Environment=HTTP_PROXY=http://127.0.0.1:18080 NO_PROXY=localhost,127.0.0.1 我们来运行一个 docker 镜像试试\n$ sudo docker run hello-world Unable to find image \u0026#39;hello-world:latest\u0026#39; locally latest: Pulling from library/hello-world 0e03bdcc26d7: Pull complete Digest: sha256:e7c70bb24b462baa86c102610182e3efcb12a04854e8c582838d92970a09f323 Status: Downloaded newer image for hello-world:latest Hello from Docker! This message shows that your installation appears to be working correctly. To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the \u0026#34;hello-world\u0026#34; image from the Docker Hub. (amd64) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal. To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bash Share images, automate workflows, and more with a free Docker ID: https://hub.docker.com/ For more examples and ideas, visit: https://docs.docker.com/get-started/ 通过代理拉取 docker 镜像也成功了，这样就可以直接从我们的公网上搭建的 docker registry 服务拉取待部署的镜像，真是太省事了。\n命令行全局启用代理 也可以在 shell 中启用 HTTP 代理，请根据需要启用\n$ export HTTP_PROXY=”http://127.0.0.1:18080” 在机房其它服务器上使用 HTTP 代理 我们是把 frp 安装到 172.22.121.110 这台服务器上并启动了 frps 服务，通过 frp 的穿透，相当于在 172.22.121.110 这台服务器上启动了一个 HTTP 代理，在 172.22.121.110 本机上使用 http://127.0.0.1:18080 来使用 HTTP 代理，在机房其它服务器上则需要使用 http://172.22.121.110:18080 来使用 HTTP 代理。\n四、实验测试环境的搭建 需要 CentOS 7 环境，且虚拟机不能访问外网\n使用 vagrant 启动一个 centos/7 虚拟机，并且使用桥接模式获取局域网 IP, 例如 IP 为 192.168.52.79 在网关路由器上进行配置使得测试的 CentOS 7 虚拟机无法访问互联网，如果网关路由器是个 linux based 的系统则可以尝试用 iptables 限制虚拟机访问互联网: iptables -A FORWARD -s 192.168.52.79 -j DROP 五、远程维护 通过前面关于 frp 的使用，不难看出来，只要在部署控制主机再启动一个 frp 客户端，把机房或者部署控制主机的 SSH 端口映射到到公网中的 frp 服务器可以了。当然这种情况下还在需要多做一些配置工作，比如在部署控制主机上配置好服务的自启动，然后把部署控制主机放在客户的办公室，在需要远程维护的时候，开机就好。\n对于远程维护，使用 frp 可能不太安全，毕竟直接把 SSH 端口暴露在公网之中，所以在这种情况下，推荐使用 WireGuard 进行 SDWAN 组网，把部署控制主机加入到自建的私有网络中。\n","permalink":"https://lewang.dev/posts/2020-11-27-go-through-the-system-firewall/","summary":"创业这段时间以来，我们的 IoT 系统已经在不少客户的机房做了私有化部署，客户大多都是机加工厂、商业大楼、医院和大学实验室等，客户的机房都有一个相同的特点：私有云，与外网隔离，不能访问互联网。或者更为准确的说，是我们部署的服务器不能访问互联网，在没有互联网访问权限的情况下，系统的包管理工具(yum/apt/docker)都无法使用了，在这种情况下进行系统部署安装，费时费力，而且无法进行远程部署维护，也大大增加了项目的实施成本。\n在最近的一个客户项目的实施过程中，看到客户的一些其他供应商在系统部署过程中非常艰难，甚至是 CentOS 系统初始化和 Docker 的安装就花掉了两个礼拜的人力，不排除一些供应商这样折腾会给他的客户留下工作敬业钱花的值的好印象，但对于我们这样的小创业公司来说，这样的时间浪费和低效是无法承担的成本，因为来实操部署的人就是公司老板本人了，我也不想出差在客户这里待上两个礼拜。\n在工作完成之后，想想可以把解决问题的方法记录一下，也许能给遇到相同问题的同行一些启发和帮助。好了，废话不多说，接下来我们就来解决这个无外网的部署问题，顺便再解决一下远程维护的问题。\n一、面临的问题 在部署和维护一个私有化企业内部使用且无互联网访问的系统中，可能会面临以下问题:\n机房服务器无法访问 Internet 可通过接入企业内网来访问服务器，而从服务器无法直连办公室网络，即机房和办公室在不同的网段 无互联网访问权限的情况下，无法直接使用系统的配置工具，如 yum/apt/docker 等，配置系统和部署服务费时费力 无法远程进行维护 客户内网拓扑示意图，此处省略了防火墙，简化拓扑图的复杂度，如下:\n网络拓扑图说明:\n机房和办公室不在一个网段 机房网段假设为 172.22.0.0/16，办公室内网 WiFi 的网段为 192.168.137.0/24 机房服务器之间是互通的，办公室可以 ping 通机房服务器，在机房服务器上无法 ping 通办公室部署控制主机，这里假设办公室网络作为一个 NAT 放在上层交换机后面 内网没有互联网访问权限，包括机房服务器和办公室内网 WiFI 二、解决问题的方法 既然是由于机房服务器没有互联网访问权限，不能联网下载安装包，那就想办法让机房服务器可以连接互联网或者搭建内网的软件包镜像服务，于是想到一些方法来达到目的:\n告知客户问题，申请开通互联网访问权限，可以限定为指定的网址和协议(HTTP/HTTPS)，需要远程维护的化，还需要申请可以连接到服务器的 VPN。这个方法在需要客户的进行审批，可能时间比较长。我们的客户中有不少都没有自建 VPN，或这不方便给我们开通 VPN，另外也无法开通需要我们部署的服务器的互联网访问权限，所以不能使用这个方法\n在客户机房放置可以通过 4G 上网的堡垒机，堡垒机接入客户机房网络。在客户机房放一个堡垒机，虽然说是堡垒机，但可能客户那边的机房管理也还是不容许放置这样的机器的，所以也不能使用这个方法\n搭建 yum(CentOS)/apt(Debian/Ubuntu)/docker 的内网镜像服务，搭建内网镜像服务可能就是一个比较艰巨的任务，难以接受给自己又添加了一个艰难的任务，此方法也作罢\n通过在办公室网里放置部署控制机，同时连接内网和 4G 路由器提供的外网(互联网)，在部署控制机上搭建 SDWAN 或者 HTTP 代理，yum/apt/docker 都支持 HTTP 代理，这样修改系统配置之后，就可以通过代理安装部署服务，这个方法比较简单，而且几乎不需要客户的参与就可以完成。不过也有一些前置条件，例如:\n办公室中主机可以接入客户网络\n客户服务器允许办公室网络中主机通过 TCP 或者 UDP 访问其任意或者指定的端口\n客户办公室的 4G 网络信号要足够好，这样可以提供更好的外网速度\n拥有服务器的 root 管理员权限(需要安装软件和修改系统配置)\n通过权衡利弊，我们最终使用的是第 4 个方法来搭建的，下面来讲讲搭建的过程。","title":"机房不能访问互联网，轻松搞定系统部署"},{"content":" 小码哥：“与大象（Gradle）一见如故？你就是 Gradle？”\n大象：“对，我就是那个用来构建 Java 项目的 Gradle 大象。 ”\n小码哥：“我好像天天都在用你啊。看，我的项目都是用你构建的。”\n大象：“但你不一定真的认识我，你每次修改点构建代码时是不是都要问下谷哥哥（Google）或溢栈哥哥（StackOverflow）？”\n小码哥：“额。。。”\n大象：“我是你的老朋友了，不要天天如初见哦，咱们得多聊聊，我爸妈给我写了传记（文档），估计你也懒得细看，不如我给你做个自我介绍吧。”\n小码哥：“👌ok”\n大象：“你有用 InteliJ IDEA 吗？ ”\n小码哥：“对，用的社区版。”\n大象：“那我就用 InteliJ IDEA CE 版来给你介绍自己”。\n你好，我是 Gradle！ Gradle 是一个用来自动化构建项目的的工具，可以用来构建你常用的 Java、Kotlin 等 JVM 语言开发的项目。我的配置文件可以使用 Gvoovy 或者 Kotlin 来编写，不像隔壁前辈 Maven 那样，要写一大段 XML，你可以很开心的像写代码一样来调整我的配置。\n其实我就是你的代码自动化产线，产线有几个工序（Task），你负责喂我代码，我负责打包（Jar/War/JavaDoc/Test）。是不是觉得与科幻片里面的工厂很像？\n创建项目 请打开你的 InteliJ IDEA CE，使用 idea 可以很方便的创建一个由我构建的项目(File \u0026gt; New \u0026gt; Project\u0026hellip;)。\n这里在对话框的左边栏选择 Gradle，右边选择 Java 项目。\n输入好项目名之后点击 Finish 就可以啦。\n探索项目 idea 帮我们创建了一个 Java 项目，浏览项目很容易发现两个以 gradle 为结尾的文件： build.gradle 和 settings.gradle。我们来看一下它们俩的内容。\nsettings.gradle\nrootProject.name = \u0026#39;MyProject\u0026#39; build.gradle\nplugins { id \u0026#39;java\u0026#39; } group \u0026#39;org.example\u0026#39; version \u0026#39;1.0-SNAPSHOT\u0026#39; sourceCompatibility = 1.8 repositories { mavenCentral() } dependencies { testCompile group: \u0026#39;junit\u0026#39;, name: \u0026#39;junit\u0026#39;, version: \u0026#39;4.12\u0026#39; } 小码哥插话：“settings.gradle 很好懂，给 rootProject.name 这个变量赋了一个值，但是 build.gradle 里面写的是什么啊？”\n大象：“gradle 的魔法确实就在 build.gradle 之中。build.gradle 是使用 Groovy 编写的脚本，我先介绍一下 Groovy 同学吧。”\n你好，Groovy 同学 Gradle 的构建脚本可以使用 Groovy 编写（Kotlin 也可以）。Groovy 也是一种 JVM 语言，并且与 Java 比较相似，写起来比 Java 要简洁得多 (Kotlin 也是)，Groovy 是 Java 的超集，也就是说 Java 代码可以当成是 Groovy 代码运行。我们来了解一下 Groovy，以便更容易读懂和修改 build.gradle。\n初识 Groovy 在 idea 中打开 Groovy 控制台（Tools \u0026gt; Groovy Console\u0026hellip;）\n接着在控制台里输入一些 Java 代码\n点击绿色三角形来运行这段代码，可以在下面的窗口看到输出\n小码哥：“大象，你说这是 Java 代码，为什么没有定义 class 和 main 函数呢？”\n大象：“只是看起来是 Java，其实这个就是 Groovy 了，Grovvy 脚本不需要定义 class 和 main 函数就可以执行的，我们继续把它变得更 Groovy 一些吧。”\n由于 Groovy 会自动导入 System.out，我们可以把代码简写成这样\n是不是看起来与 Java 里面函数静态导入写起来一样，我们可以更进一步：\n在 Groovy 里面如果函数只有一个参数，那么括弧可以省略; 语句末尾的分号也可以省略； 单引号和双引号是（大部分情况下）可以替换（推荐用双引号，方便迁移到 Kotlin DSL） 现在很清楚了：原来 println 是一个函数，在代码里面调用了它，并且给它参数传了一个字符串 my project。\nGroovy 闭包(Groovy Closure) 提到闭包，应该或多或少都听说过，Gradle 的 build.gradle 脚本中大量使用了闭包，我们还是用一段代码来说明。\n先定义一个类\n这个类看起来和 Java 没什么区别，我们再添加一个可以接受 Closure 类型参数的函数\n大象：“是不是看起来与 Java 8 的 Lambda 非常的像，比如 Function 接口？”\n小码哥：“是的，难道是一样的东西，只是不同语言写法不同？那在 Groovy 里面如何来使用闭包呢？”\n大象：“正是如此，我们来看下如何在 Groovy 里面来使用闭包吧。”\n首先需要创建一个 MyProject 实例，然后再调用 doTask 方法。\n同样点击绿色三角形，运行这段代码\n我们再回过头来看看 build.gradle, 比如这段代码\ndependencies { testCompile group: \u0026#39;junit\u0026#39;, name: \u0026#39;junit\u0026#39;, version: \u0026#39;4.12\u0026#39; } 是不是很好理解：脚本调用了 dependencies 方法，它的参数是一个闭包，在这个闭包里面又调用了 testCompile 方法，并传入了一个字典（Map）参数： group: \u0026lsquo;junit\u0026rsquo;, name: \u0026lsquo;junit\u0026rsquo;, version: \u0026lsquo;4.12\u0026rsquo;\n好了，Groovy 同学暂时就介绍到这里，我要继续介绍我自己了。\n探索 build.gradle Gradle 最核心的部分就是 Project 和 Task 了 ，build.gradle 可以直接操控 Project 对象（org.gradle.api.Project 的实例) ，遵循“代码即配置”的基本原则。项目代码可以包括多个 build.gradle, 多个 Project 需要在 settings.gradle 定义。每一个 build.gradle 文件都会对应一个 Project 对象，我们每一个项目的构建信息都会存在对应的 Project 对象中。\n站在写代码的角度上可以这样来理解，Gradle 会根据 settings.gradle 定义为每个 Project 创建 org.gradle.api.Project 对象，之后会根据 build.gradle 的配置执行相应的任务（Task）。除了“代码即配置”这个原则之外，还有“约定即配置”这个原则。比如 Gradle 会有默认约定的 Java 项目结构（Java Plugin Project Layout），每一个 Gradle 项目也会约定一些默认的 Task 等。\n也就是说，Gradle 的 Project 构建过程是由一系列 Task 组成的，我们可以通过这个命令查看项目默认的有哪些 Task。好，我们把 idea 创建的 build.gradle 清空，然后执行下面的命令。\ngradle tasks 可以看到所有默认的 Task。\n接着一步步恢复 idea 默认创建的 build.gradle，先往空的 build.gradle 文件中添加：\nplugins { id \u0026#39;java\u0026#39; } 可以理解这段代码了么？没错，我们往 build.gradle 中添加了 Java 插件，这样就可以很方便的构建 Java 项目，再次查看 Task。\n插件可以在 Project 中添加 Task，Gradle 会把这些 Task 构建成一个有向无环图（DAG，Directed Acyclic Graph），加了 Java 插件之后的 DAG 是这样的。\n每一个 Project 包括一系列的 Task，同样，每个 Project 也有很多的属性，例如添加这里代码来修改属性：\ngroup \u0026#39;org.example\u0026#39; version \u0026#39;1.0-SNAPSHOT\u0026#39; sourceCompatibility = 1.8 我们可以在 build.gradle 中对 Project 的属性进行修改，也可以像查看 Task 一样来查看 Project 所有的属性：\ngradle properties 哇，Project 的属性还真不少（只截取了部分属性）。\n自定义 Task Gradle 的构建过程包括三个阶段：初始化（Initialization）、配置（Configuration）和执行（Execution），为了弄清楚这三个阶段，我们在 build.gradle 中添加这样代码：\nprintln \u0026#34;config\u0026#34; task task1 { println \u0026#34;config in task1\u0026#34; } task task2 { doLast { println \u0026#34;do last in task2\u0026#34; } println \u0026#34;config in task2\u0026#34; } task task3 { doFirst { println \u0026#34;do first in task3\u0026#34; } doLast { println \u0026#34;do last in task3\u0026#34; } println \u0026#34;config in task3\u0026#34; } 在 settings.gradle 中添加：\nprintln \u0026#34;init\u0026#34; 然后执行：\ngradle task2 task3 可以看到这样的输出：\n从输出日志中可以清晰的看到，Gradle 第一步初始化，然后进行配置，最后执行具体任务，如图所示：\n弄清楚构建过程之后，我们可以很容易根据我们的需要对 Task 进行自定义配置或者是新建一个 Task。\n老朋友，你好 大象：“我就说到这里，有没有一见如故的感觉？我的 API 非常多，想弄清楚我的细枝末节还是得去看文档，希望我的这个介绍能帮助到你去理解文档。 ”\n小码哥：“有种恍然大悟的感觉，配置 Gradle 确实就像写 Java 代码差不多，原来 Gradle 只用通过 build.gradle 想办法修改 Project 对象就可以了。哦对，我还个问题，gradlew 是什么啊？”\n大象：“呃，gradlew 我也不知道它是啥啊，你自己查查去吧。”\n参考资料 PyScript 官网 Pyodide - 基于 WebAssembly 的 Python ","permalink":"https://lewang.dev/posts/2020-02-22-hello-gradle-1/","summary":"小码哥：“与大象（Gradle）一见如故？你就是 Gradle？”\n大象：“对，我就是那个用来构建 Java 项目的 Gradle 大象。 ”\n小码哥：“我好像天天都在用你啊。看，我的项目都是用你构建的。”\n大象：“但你不一定真的认识我，你每次修改点构建代码时是不是都要问下谷哥哥（Google）或溢栈哥哥（StackOverflow）？”\n小码哥：“额。。。”\n大象：“我是你的老朋友了，不要天天如初见哦，咱们得多聊聊，我爸妈给我写了传记（文档），估计你也懒得细看，不如我给你做个自我介绍吧。”\n小码哥：“👌ok”\n大象：“你有用 InteliJ IDEA 吗？ ”\n小码哥：“对，用的社区版。”\n大象：“那我就用 InteliJ IDEA CE 版来给你介绍自己”。\n你好，我是 Gradle！ Gradle 是一个用来自动化构建项目的的工具，可以用来构建你常用的 Java、Kotlin 等 JVM 语言开发的项目。我的配置文件可以使用 Gvoovy 或者 Kotlin 来编写，不像隔壁前辈 Maven 那样，要写一大段 XML，你可以很开心的像写代码一样来调整我的配置。\n其实我就是你的代码自动化产线，产线有几个工序（Task），你负责喂我代码，我负责打包（Jar/War/JavaDoc/Test）。是不是觉得与科幻片里面的工厂很像？\n创建项目 请打开你的 InteliJ IDEA CE，使用 idea 可以很方便的创建一个由我构建的项目(File \u0026gt; New \u0026gt; Project\u0026hellip;)。\n这里在对话框的左边栏选择 Gradle，右边选择 Java 项目。\n输入好项目名之后点击 Finish 就可以啦。\n探索项目 idea 帮我们创建了一个 Java 项目，浏览项目很容易发现两个以 gradle 为结尾的文件： build.gradle 和 settings.gradle。我们来看一下它们俩的内容。\nsettings.gradle","title":"大象（Gradle）的故事：一见如故"},{"content":"昨日陪小糍粑参加幼儿园秋游活动，游览了一下位于松江区的方塔园，校方安排幼儿在白色布袋上绘画，于是有了以下大作。\n观察幼儿绘画的过程挺有意思的，我们父母无须提供任何绘画的指导，只要等待小朋友们绘画完毕，来听听他们关于自己的画的解释即可。\n关于上面的画，小糍粑是这样解释的。\n他和爸爸来看方塔，想象和爸爸在方塔里面，草地的旁边有水，有果树(梨树)，有蓝天，蓝天上面有飞机在飞，他穿着红色的衣服和黑色的鞋子。\n我感觉他画的非常自信，有考虑绘画的布局，所有的线条几乎都是一笔成型，丝毫不拖沓，很符合这个年龄幼儿的表现。\n图里面有个地方是我画的，大家可以猜猜是哪里。\n","permalink":"https://lewang.dev/posts/2019-11-02-fangta-paintings/","summary":"昨日陪小糍粑参加幼儿园秋游活动，游览了一下位于松江区的方塔园，校方安排幼儿在白色布袋上绘画，于是有了以下大作。\n观察幼儿绘画的过程挺有意思的，我们父母无须提供任何绘画的指导，只要等待小朋友们绘画完毕，来听听他们关于自己的画的解释即可。\n关于上面的画，小糍粑是这样解释的。\n他和爸爸来看方塔，想象和爸爸在方塔里面，草地的旁边有水，有果树(梨树)，有蓝天，蓝天上面有飞机在飞，他穿着红色的衣服和黑色的鞋子。\n我感觉他画的非常自信，有考虑绘画的布局，所有的线条几乎都是一笔成型，丝毫不拖沓，很符合这个年龄幼儿的表现。\n图里面有个地方是我画的，大家可以猜猜是哪里。","title":"游方塔园"},{"content":"背景 搭建 VPN 方便连接无公网 IP 云主机进行开发，WireGuard 配置比 OpenVPN 要简单很多，WireGuard 是通过 Linux 内核模块的方式实现的，这样性能最好，但是只能用在 Linux 系统上。本文使用的 wireguard-go， 则是使用 Golang 实现的 WireGuard 协议，属于用户空间(User Space)的实现，性能没有内核模块方式好，但好处就是跨平台且更简单易用。\nVPN 的用处非常的多，不像 frp 之类的端口穿透应用，它是直接建立虚拟的网络，网络中的每个客户端也都可以拥有自己独立的 IP，于是测试调试就没有了端口的限制，非常的方便。\n除了方便安全连接云服务器，还可以通过 VPN 搭建工业设备的远程部署和维护的解决方案。\n编译 wireguard-go # 使用 GitHub 的源码镜像，速度会快一些 git clone git@github.com:wireguard/wireguard-go.git # 在 MacOS 下交叉编译 CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build -v -o \u0026#34;wireguard-go\u0026#34; # Linux 环境下直接编译 go build -v -o \u0026#34;wireguard-go\u0026#34; cp wireguard-go /usr/sbin/ 编译 WireGuard tools git clone git@github.com:wireguard/wireguard.git # 安装依赖 ## debian\u0026amp;ubuntu sudo apt-get install libmnl-dev libelf-dev ## centos sudo yum install libmnl-devel elfutils-libelf-devel cd wireguard/src/tools make sudo make install 配置 WireGuard 生成密钥\ncd /etc/wireguard wg genkey | tee server_privatekey | wg pubkey \u0026gt; server_publickey 生成服务器端配置文件 wg0.conf\necho \u0026#34;[Interface] PrivateKey = $(cat server_privatekey) Address = 10.0.0.1/24 PostUp = iptables -A FORWARD -i wg0 -o eth0 -j ACCEPT; iptables -A FORWARD -i eth0 -o wg0 -j ACCEPT; iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE PostDown = iptables -D FORWARD -i wg0 -o eth0 -j ACCEPT; iptables -D FORWARD -i eth0 -o wg0 -j ACCEPT; iptables -t nat -D POSTROUTING -o eth0 -j MASQUERADE ListenPort = 1194 MTU = 1420 \u0026#34;\u0026gt; wg0.conf 生成客户端配置文件 client-wg0.conf\necho \u0026#34;[Interface] PrivateKey = $(cat client_privatekey) Address = 10.0.0.2/24 DNS = 8.8.8.8 MTU = 1420 [Peer] PublicKey = $(cat server_publickey) Endpoint = ${server_ip}:1194 AllowedIPs = 0.0.0.0/0, ::0/0 PersistentKeepalive = 30\u0026#34; | sed \u0026#39;/^#/d;/^\\s*$/d\u0026#39; \u0026gt; client-wg0.conf 在服务器端开启数据包转发\necho 1 \u0026gt; /proc/sys/net/ipv4/ip_forward echo \u0026#34;net.ipv4.ip_forward = 1\u0026#34; \u0026gt;\u0026gt; /etc/sysctl.conf sysctl -p 最后在服务器端启动 WireGuard\nwg-quick up wg0 客户端需要根据前面生成的配置文件进行配置\n参考 https://www.wireguard.com https://medium.com/@xtarin https://www.linode.com/docs ","permalink":"https://lewang.dev/posts/2019-10-30-wireguard-go-setup/","summary":"背景 搭建 VPN 方便连接无公网 IP 云主机进行开发，WireGuard 配置比 OpenVPN 要简单很多，WireGuard 是通过 Linux 内核模块的方式实现的，这样性能最好，但是只能用在 Linux 系统上。本文使用的 wireguard-go， 则是使用 Golang 实现的 WireGuard 协议，属于用户空间(User Space)的实现，性能没有内核模块方式好，但好处就是跨平台且更简单易用。\nVPN 的用处非常的多，不像 frp 之类的端口穿透应用，它是直接建立虚拟的网络，网络中的每个客户端也都可以拥有自己独立的 IP，于是测试调试就没有了端口的限制，非常的方便。\n除了方便安全连接云服务器，还可以通过 VPN 搭建工业设备的远程部署和维护的解决方案。\n编译 wireguard-go # 使用 GitHub 的源码镜像，速度会快一些 git clone git@github.com:wireguard/wireguard-go.git # 在 MacOS 下交叉编译 CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build -v -o \u0026#34;wireguard-go\u0026#34; # Linux 环境下直接编译 go build -v -o \u0026#34;wireguard-go\u0026#34; cp wireguard-go /usr/sbin/ 编译 WireGuard tools git clone git@github.com:wireguard/wireguard.git # 安装依赖 ## debian\u0026amp;ubuntu sudo apt-get install libmnl-dev libelf-dev ## centos sudo yum install libmnl-devel elfutils-libelf-devel cd wireguard/src/tools make sudo make install 配置 WireGuard 生成密钥","title":"WireGuard 使用简介"},{"content":"2019/10/13 上午大作 画了一辆坦克\n2019/10/10 晚大作 1 2 3 4 小糍粑自己介绍： 爸爸妈妈宝宝奶奶和他的同学，右一是奶奶，右二是爸爸，右三是他自己，右四是妈妈，奶奶没地方画了\n点评： 很明显的出现头足人像\n","permalink":"https://lewang.dev/posts/2019-10-13-sons-paintings/","summary":"2019/10/13 上午大作 画了一辆坦克\n2019/10/10 晚大作 1 2 3 4 小糍粑自己介绍： 爸爸妈妈宝宝奶奶和他的同学，右一是奶奶，右二是爸爸，右三是他自己，右四是妈妈，奶奶没地方画了\n点评： 很明显的出现头足人像","title":"小糍粑的画"},{"content":"背景 树莓派 raspbian 系统日志默认的配置会导致日志过大而占用太多的存储空间，并且频繁写日志也可能减短 EMMC 和 SD 卡的寿命，需要重新配置来满足项目的需求。\n日志位置 /var/log /var/log/syslog /var/log/daemon.log /var/log/mail.info /var/log/mail.warn /var/log/mail.err /var/log/mail.log /var/log/kern.log /var/log/auth.log /var/log/user.log /var/log/lpr.log /var/log/cron.log /var/log/debug /var/log/messages 配置 rsyslog 与 logrotate rsyslog 的配置文件为 /etc/rsyslog.conf, 找到其中 RULES 段\n############### #### RULES #### ############### # # First some standard log files. Log by facility. # auth,authpriv.* /var/log/auth.log *.*;auth,authpriv.none -/var/log/syslog #cron.* /var/log/cron.log #daemon.* -/var/log/daemon.log kern.* -/var/log/kern.log lpr.* -/var/log/lpr.log mail.* -/var/log/mail.log user.* -/var/log/user.log 将其中 daemon.* -/var/log/daemon.log 行注释掉，syslog中已经包含 daemon 的日志。\n修改 rsyslog 的 logrotate 配置 /etc/logrotate.d/rsyslog\n/var/log/syslog /var/log/daemon.log { rotate 3 daily missingok notifempty nodelaycompress compress postrotate invoke-rc.d rsyslog rotate \u0026gt; /dev/null endscript } /var/log/mail.info /var/log/mail.warn /var/log/mail.err /var/log/mail.log /var/log/kern.log /var/log/auth.log /var/log/user.log /var/log/lpr.log /var/log/cron.log /var/log/debug /var/log/messages { rotate 3 weekly missingok notifempty compress nodelaycompress sharedscripts postrotate invoke-rc.d rsyslog rotate \u0026gt; /dev/null endscript } 将 delaycompress 改为 nodelaycompress ，分割文件后立即压缩归档；另外 rotate 都设置为 3\n立即测试一下配置\nsudo /usr/sbin/logrotate /etc/logrotate.conf 写日志到内存 首先清空 /var/log 目录下面的日志(如果日志不多，可以不用清空)。\n在 /etc/fstab 文件中添加以下内容, /var/log 最大可以使用 100MB 内存，也同时给其他常用的写目录/tmp、/var/tmp 挂载到内存中。\ntmpfs /var/log tmpfs defaults,noatime,nosuid,mode=0755,size=100m 0 0 tmpfs /tmp tmpfs defaults,noatime,nosuid,size=10m 0 0 tmpfs /var/tmp tmpfs defaults,noatime,nosuid,size=10m 0 0 重启系统或者手动挂载文件系统使之生效。\n","permalink":"https://lewang.dev/posts/2019-09-19-rpi-log-config/","summary":"背景 树莓派 raspbian 系统日志默认的配置会导致日志过大而占用太多的存储空间，并且频繁写日志也可能减短 EMMC 和 SD 卡的寿命，需要重新配置来满足项目的需求。\n日志位置 /var/log /var/log/syslog /var/log/daemon.log /var/log/mail.info /var/log/mail.warn /var/log/mail.err /var/log/mail.log /var/log/kern.log /var/log/auth.log /var/log/user.log /var/log/lpr.log /var/log/cron.log /var/log/debug /var/log/messages 配置 rsyslog 与 logrotate rsyslog 的配置文件为 /etc/rsyslog.conf, 找到其中 RULES 段\n############### #### RULES #### ############### # # First some standard log files. Log by facility. # auth,authpriv.* /var/log/auth.log *.*;auth,authpriv.none -/var/log/syslog #cron.* /var/log/cron.log #daemon.* -/var/log/daemon.log kern.* -/var/log/kern.log lpr.* -/var/log/lpr.log mail.* -/var/log/mail.log user.* -/var/log/user.log 将其中 daemon.* -/var/log/daemon.log 行注释掉，syslog中已经包含 daemon 的日志。","title":"树莓派系统日志配置"},{"content":"问题 在使用 Docker 或者 NFS 的时候，需要文件系统挂在到不同的系统中拥有正确的读写权限，需要指定文件所属用户和组的 uid 和 gid。在创建用户和组的时候，系统会自动分配对应的值，这导致在不同的系统中很容易造成 uid 和 gid 不一样而造成读写权限混乱。\n例如在系统 A 中，用户 git 的 uid 和组 git 的gid 如下:\n[sysops@cn-bj-aliyun-3 ~]$ id git uid=1001(git) gid=1001(git) groups=1001(git) 而系统 B 中的值如下:\n[sysops@cn-bj-aliyun-3 ~]$ id git uid=998(git) gid=998(git) groups=998(git) 我们在系统 A 以 git 用户创建目录或者文件:\n[git@cn-bj-aliyun-3 data]$ ls -lh total 60K -rw-r--r-- 1 git git 100 Jul 5 23:22 file1 -rw-r--r-- 1 git git 400 Dec 18 2018 file2 -rw-r--r-- 1 git git 349 Dec 18 2018 file3 将这个目录挂在到 B 系统中时，将会出现这种情况:\n[git@cn-bj-aliyun-3 data]$ ls -lh total 60K -rw-r--r-- 1 1001 1001 100 Jul 5 23:22 file1 -rw-r--r-- 1 1001 1001 400 Dec 18 2018 file2 -rw-r--r-- 1 1001 1001 349 Dec 18 2018 file3 这样就会导致在 B 系统中文件权限混乱，因为 B 系统中没有对应 uid 和 gid 的用户和组。接下来我们来修改 uid 和 gid，以下以修改系统 A 中的 git 为例。\n修改命令 修改 UID sudo usermod -u 998 git 修改文件的所属用户 find / -user 1001 -exec chown -h git {} \\; 修改 GID sudo groupmod -g 998 git 修改文件的所属用户 find / -group 1001 -exec chgrp -h git {} \\; 其它说明 另外在修改之前可以查看 /etc/passwd 和 /etc/group 文件，以便选取一个没有被使用的 uid 和 gid\n","permalink":"https://lewang.dev/posts/2019-07-16-change-uid-gid-in-linux/","summary":"问题 在使用 Docker 或者 NFS 的时候，需要文件系统挂在到不同的系统中拥有正确的读写权限，需要指定文件所属用户和组的 uid 和 gid。在创建用户和组的时候，系统会自动分配对应的值，这导致在不同的系统中很容易造成 uid 和 gid 不一样而造成读写权限混乱。\n例如在系统 A 中，用户 git 的 uid 和组 git 的gid 如下:\n[sysops@cn-bj-aliyun-3 ~]$ id git uid=1001(git) gid=1001(git) groups=1001(git) 而系统 B 中的值如下:\n[sysops@cn-bj-aliyun-3 ~]$ id git uid=998(git) gid=998(git) groups=998(git) 我们在系统 A 以 git 用户创建目录或者文件:\n[git@cn-bj-aliyun-3 data]$ ls -lh total 60K -rw-r--r-- 1 git git 100 Jul 5 23:22 file1 -rw-r--r-- 1 git git 400 Dec 18 2018 file2 -rw-r--r-- 1 git git 349 Dec 18 2018 file3 将这个目录挂在到 B 系统中时，将会出现这种情况:","title":"如何修改 Linux 用户的 UID 和组的 GID"},{"content":"概要 本文记录了在 CentOS 7.6 系统上通过 pyenv 安装 Python 3.7.3 的过程。\n环境 CentOS Linux release 7.6.1810 (Core) Kernel 3 3.10.0-957.el7.x86_64 Pyenv 1.2.11 安装 pyenv $ curl https://pyenv.run | bash 然后根据提示把以下内容放到 ~/.bashrc 文件末尾\n# Load pyenv automatically by adding # the following to ~/.bashrc: export PATH=\u0026#34;/root/.pyenv/bin:$PATH\u0026#34; eval \u0026#34;$(pyenv init -)\u0026#34; eval \u0026#34;$(pyenv virtualenv-init -)\u0026#34; 安装 Python 3.7.3 准备\n$ sudo yum -y install xz bzip2 bzip2-devel sqlite-devel gcc openssl-devel readline-devel zlib-devel libffi-devel 安装\npyenv install 3.7.3 验证\n$ pyenv versions * system (set by /root/.pyenv/version) 3.7.3 参考 https://github.com/pyenv/pyenv/issues/1183 https://github.com/pyenv/pyenv-installer https://github.com/pyenv/pyenv ","permalink":"https://lewang.dev/posts/2019-05-29-centos7-pyenv-install-python-3/","summary":"概要 本文记录了在 CentOS 7.6 系统上通过 pyenv 安装 Python 3.7.3 的过程。\n环境 CentOS Linux release 7.6.1810 (Core) Kernel 3 3.10.0-957.el7.x86_64 Pyenv 1.2.11 安装 pyenv $ curl https://pyenv.run | bash 然后根据提示把以下内容放到 ~/.bashrc 文件末尾\n# Load pyenv automatically by adding # the following to ~/.bashrc: export PATH=\u0026#34;/root/.pyenv/bin:$PATH\u0026#34; eval \u0026#34;$(pyenv init -)\u0026#34; eval \u0026#34;$(pyenv virtualenv-init -)\u0026#34; 安装 Python 3.7.3 准备\n$ sudo yum -y install xz bzip2 bzip2-devel sqlite-devel gcc openssl-devel readline-devel zlib-devel libffi-devel 安装","title":"CentOS 7 上使用 pyenv 安装 Python 3.7.3"},{"content":"自己学习 Java 和用 Java 过程中的理解和备忘的知识点。\nJDK 11 Oracle 不在免费提供 LTS 版本了，包括 JDK 8 ZGC, 可伸缩的、低延迟的垃圾收集器，STW 时间不超过 10ms Nashorn 标记为 Deprecate 了 JDK 9 module try-catch 简化 _ 为保留关键字 var 将在 JDK 10 中作为关键字, 作为本地变量类型推断关键字 字符串相关，主要是 Compact String, 用 byte[] 替换了 char[], char 在 Java 中占两个字节 G1 作为默认垃圾回收器 JVM 启动 JVM 相关的命令行参数 G1 垃圾回收器 内存 JVM(Hotspot) 内存结构 制造各种 OutOfMemery 和 StackOverflow 各种 JVM 相关工具(jstat/jmap/jstack/jps 等) 解决 FullGC 的问题 引用：WeakRefrence/PhantomReference/SoftRefrence/FinalRefrence 等 ClassLoader/URLClassLoader Spring Boot 的 ClassLoader 自定义 ClassLoader 多线程和并发 JVM 的线程模型 1:1 协程 创建线程的方法 线程同步 synchronzied/对象锁/类锁/锁方法/锁锁代码块 线程池 锁相关（Lock 接口和实现类） Condition volatile ThreadLocal 用途和实现 并发（CAS/乐观锁/无锁/无等待/无阻塞） 字节码 基本结构 操作字节码的工具 Javassist/ASM AOP 集合 Collection,List,ArrayList,Vector,LinkedList, SkipList, Stack Queue HashMap/HashTable HashMap 扩容死循环问题 LinkedHashMap TreeMap HashSet,TreeSet WeakHashMap 并发相关的集合 ConcurrentHashMap CopyOnWriteArrayList IO IO 模型 NIO Non-blocking IO Java 8 IO 相关的接口和类 Netty Vert.x 时间/日期 SimpleDateFormat 问题 Java 8 Joda 数值和二进制 数值类型在 Java 中的范围 浮点类型有什么问题 BigDecimal 位运算 格式化，有效数字 泛型 泛型使用中的一些点：类型擦除/父类中使用泛型的函数如何返回子类对象 异常 编译异常 运行时异常 非运行时异常 ","permalink":"https://lewang.dev/posts/2019-03-06-keynotes-of-new-java/","summary":"自己学习 Java 和用 Java 过程中的理解和备忘的知识点。\nJDK 11 Oracle 不在免费提供 LTS 版本了，包括 JDK 8 ZGC, 可伸缩的、低延迟的垃圾收集器，STW 时间不超过 10ms Nashorn 标记为 Deprecate 了 JDK 9 module try-catch 简化 _ 为保留关键字 var 将在 JDK 10 中作为关键字, 作为本地变量类型推断关键字 字符串相关，主要是 Compact String, 用 byte[] 替换了 char[], char 在 Java 中占两个字节 G1 作为默认垃圾回收器 JVM 启动 JVM 相关的命令行参数 G1 垃圾回收器 内存 JVM(Hotspot) 内存结构 制造各种 OutOfMemery 和 StackOverflow 各种 JVM 相关工具(jstat/jmap/jstack/jps 等) 解决 FullGC 的问题 引用：WeakRefrence/PhantomReference/SoftRefrence/FinalRefrence 等 ClassLoader/URLClassLoader Spring Boot 的 ClassLoader 自定义 ClassLoader 多线程和并发 JVM 的线程模型 1:1 协程 创建线程的方法 线程同步 synchronzied/对象锁/类锁/锁方法/锁锁代码块 线程池 锁相关（Lock 接口和实现类） Condition volatile ThreadLocal 用途和实现 并发（CAS/乐观锁/无锁/无等待/无阻塞） 字节码 基本结构 操作字节码的工具 Javassist/ASM AOP 集合 Collection,List,ArrayList,Vector,LinkedList, SkipList, Stack Queue HashMap/HashTable HashMap 扩容死循环问题 LinkedHashMap TreeMap HashSet,TreeSet WeakHashMap 并发相关的集合 ConcurrentHashMap CopyOnWriteArrayList IO IO 模型 NIO Non-blocking IO Java 8 IO 相关的接口和类 Netty Vert.","title":"Java 进阶要点"},{"content":"准备 阅读Flashing the Compute Module eMMC 准备一个可以刷系统的底板，我用的是微雪Compute-Module-IO-Board-Plus 步骤(Linux 系统下刷系统，可以使用树莓派来刷机) sudo apt install git libusb-1.0-0-dev git clone --depth=1 https://github.com/raspberrypi/usbboot \u0026amp;\u0026amp; cd usbboot \u0026amp;\u0026amp; make sudo ./rpiboot 连好线，跳线部分见各自底板的手册 拔掉 USB SLAVE 1/2/3/4 拔掉 SELECT 跳线帽 将 BOOT ENABLE USB SLAVE 跳线帽接到 EN 端 sudo fdisk -l 查看磁盘名称，这里是 /dev/sda sudo dd if=raspbian-lite.img of=/dev/sda bs=4MiB 刷入系统后，挂在启动分区，添加 SSH 来开启 SSH 服务，sudo mount /dev/sda1 /media cd /media \u0026amp;\u0026amp; touch SSH 使用慧通科技出品的 HuiBox-700 底板 省略上述的第4步，其它步骤完全一样\n","permalink":"https://lewang.dev/posts/2019-03-01-rpi-cm3-emmc-flashing/","summary":"准备 阅读Flashing the Compute Module eMMC 准备一个可以刷系统的底板，我用的是微雪Compute-Module-IO-Board-Plus 步骤(Linux 系统下刷系统，可以使用树莓派来刷机) sudo apt install git libusb-1.0-0-dev git clone --depth=1 https://github.com/raspberrypi/usbboot \u0026amp;\u0026amp; cd usbboot \u0026amp;\u0026amp; make sudo ./rpiboot 连好线，跳线部分见各自底板的手册 拔掉 USB SLAVE 1/2/3/4 拔掉 SELECT 跳线帽 将 BOOT ENABLE USB SLAVE 跳线帽接到 EN 端 sudo fdisk -l 查看磁盘名称，这里是 /dev/sda sudo dd if=raspbian-lite.img of=/dev/sda bs=4MiB 刷入系统后，挂在启动分区，添加 SSH 来开启 SSH 服务，sudo mount /dev/sda1 /media cd /media \u0026amp;\u0026amp; touch SSH 使用慧通科技出品的 HuiBox-700 底板 省略上述的第4步，其它步骤完全一样","title":"树莓派 CM3/CM3+ 刷写系统"},{"content":"为什么要写这篇文章？ 曾经几年前在 Docker 还没有广泛应用的时候，在公司使用过源码的方式安装和升级过 Gitlab，虽远没有 Docker 方便，因为自己对 Linux 系统的理解，所以整体上感觉还是挺简单的。这几年随着 Docker 的普及，使得安装 Gitlab 更加的容易，不仅方便了我这样的老鸟，也更方便了小白用户们。但是 Gitlab 官方的 Docker 安装文档并没有写得很完善, 除了官方文档之外，检索出来的安装文档也是人云亦云，东拼西凑，结果也就是能运行起来，凑合着能用而已。避免出现下图中“我已经用 Docker 部署好啦”，其实已经翻车的情形。\n我希望每做一件小事的时候也都能抱着“知其然知其所以然”的心态对待，用 Docker 方式安装 Gitlab，说简单来说就是一行命令的事儿，但是这样就够了吗？我看是不够的，所以就有了这篇文档。\n本文需要达成的事项 在 CentOS 7 系统中安装 Docker 使用 Docker 方式安装中文版 Gitlab 和宿主机器共用 22(SSH) 端口 支持 SSH(22)/HTTPS(443) 方式推拉仓库 使用 SMTP 方式配置通知邮箱(腾讯企业邮箱) 改写默认的项目标签(Labels) 在 CentOS 7 系统中安装 Docker 这部分参考 Docker 的官方文档, 罗列一下安装步骤, 细节请看 Docker 的官方文档。如果使用 root 用户安装，sudo 可以去掉。\n1. 删除老版本 Docker $ sudo yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-selinux \\ docker-engine-selinux \\ docker-engine 2. 安装 Docker CE 的仓库配置 $ sudo yum install -y yum-utils \\ device-mapper-persistent-data \\ lvm2 $ sudo yum-config-manager \\ --add-repo \\ https://download.docker.com/linux/centos/docker-ce.repo 3. 安装仓库中最高版本 Docker CE $ sudo yum install -y docker-ce 4. 启动 Docker $ sudo systemctl start docker 5. 验证 Docker 是否安装成功 $ sudo docker run hello-world 使用 Docker 方式安装中文版 Gitlab 目前我的团队习惯使用中文版的 Gitlab 的，并且使用的版本是 beginor/gitlab-ce:10.3.1-ce.0，所以还是以这个版本来说明安装配置过程。\n在启动 Gitlab 之前，创建几个目录作为 Docker 的卷，这样的配置或者升级 gitlab 的时候可以保留配置和数据。\n$ sudo mkdir -p /data/var/lib/gitlab/etc $ sudo mkdir -p /data/var/lib/gitlab/log $ sudo mkdir -p /data/var/lib/gitlab/data 启动 Gitlab\n$ sudo docker run \\ --detach \\ --sysctl net.core.somaxconn=1024 \\ --publish 8080:80 \\ --publish 8022:22 \\ --name gitlab \\ --restart unless-stopped \\ --volume /data/var/lib/gitlab/etc:/etc/gitlab \\ --volume /data/var/lib/gitlab/log:/var/log/gitlab \\ --volume /data/var/lib/gitlab/data:/var/opt/gitlab \\ beginor/gitlab-ce:10.3.1-ce.0 这个 Gitlab 的 Docker 镜像是基于 Ubuntu 16.04.3 LTS 这个版本来构建的，所以在 docker exec -it gitlab /bin/bash 进入 Docker 容器之后跟使用 Ubuntu 就没有什么差别了。\ngitlab 容器中启动了很多服务，主要包括：\ngitlab redis postgresql nginx sshd 通过查看 Dockerfile 发现，除了可以使用 docker exec -it gitlab /bin/bash 进入容器之外，还可以直接使用 SSH 登录到容器中。其实 Gitlab 这个镜像，并不符合 Dockerfile 最佳实践规范, 因为将会有太多的服务在这个镜像构建的容器之中，不利于服务的扩容和重用。不过通过这种超级包的方式确实大大降低了用户的使用门槛，对于高段位选手，自然也会自己去拆分去解耦，进而去构建自己的镜像。\n讲到这里，gitlab 服务已经在运行了，大多数人也认为自己任务完成了，一切到此为止。但是对于有些许强迫症的人来说，是无法接受 HTTP 得用 8080 端口， SSH 得用 8022 端口，这样 Git 的 URL 就不太美观了。\n偷懒的人有个很简单的方法来解决这个端口的问题， 可以使用这样的命令启动 Docker\n$ sudo docker stop gitlab $ sudo docker rm gitlab $ sudo docker run \\ --detach \\ --sysctl net.core.somaxconn=1024 \\ --publish 443:443 \\ --publish 80:80 \\ --publish 22:22 \\ --name gitlab \\ --restart unless-stopped \\ --volume /data/var/lib/gitlab/etc:/etc/gitlab \\ --volume /data/var/lib/gitlab/log:/var/log/gitlab \\ --volume /data/var/lib/gitlab/data:/var/opt/gitlab \\ beginor/gitlab-ce:10.3.1-ce.0 这样有带来了新问题:\n80/443 将会被 gitlab 独占，宿主机器上 Nginx 等 HTTP/HTTPS 服务将无法使用 80/443 22 将会被 gitlab 独占，那么宿主机器上的 SSHD 服务需要改为其它端口 这两个新问题大概对于有些许强迫症的人来说也是无法接受的。 我们还是回到这样的方式启动 Gitlab\n$ sudo docker stop gitlab $ sudo docker rm gitlab $ sudo docker run \\ --detach \\ --sysctl net.core.somaxconn=1024 \\ --publish 8080:80 \\ --publish 8022:22 \\ --name gitlab \\ --restart unless-stopped \\ --volume /data/var/lib/gitlab/etc:/etc/gitlab \\ --volume /data/var/lib/gitlab/log:/var/log/gitlab \\ --volume /data/var/lib/gitlab/data:/var/opt/gitlab \\ beginor/gitlab-ce:10.3.1-ce.0 然后寻找其它更好的解决方案：\n使用 Nginx 代理 8080 端口，这样很容易实现 HTTP(80)/HTTPS(443) 端口共用 共享宿主机器的 SSH(22) 端口，如果使用 git 这个账号登录，则转发 SSH 到 gitlab 的容器中 下面来讲如何解决这两个问题。\n使用宿主机器上的 Nginx 配置 HTTP 和 HTTPS 使用宿主机器上的 Nginx 使得我们安装 Gitlab 更加灵活。先停用 Gitlab 容器中的 HTTPS 服务, 需要这样改写配置文件, 需要编辑 /data/var/lib/gitlab/etc/gitlab.rb 文件相应的行，具体配置可以参考这里\nexternal_url \u0026#34;https://gitlab.example.com\u0026#34; nginx[\u0026#39;listen_port\u0026#39;] = 80 nginx[\u0026#39;listen_https\u0026#39;] = false 修改完成之后，可以在 Docker 容器中执行 gitlab-ctl reconfigure 来使之生效。这样配置以后，容器中讲只提供 HTTP 服务，不会根据 external_url 解析来自动启动 HTTPS 而导致日志中出现大量的缺少证书的日志。现在只需要配置宿主机器的 Nginx 就可以了。关于如何获取免费的 SSL 证书，这里就不在赘述了，读者可以自行搜索 Let\u0026rsquo;s Encrypt + Nginx 相关文章，如果没有域名，只有 IP，那可以试试 TrustOcean。\nGitlab Docker 和宿主服务器共享 SSH(22) 端口 Gitlab Docker 镜像中默认使用的 SSH 账户是 git，那能不能在宿主机器上也建一个账户 git，只是当 git 帐号进行操作的时候，我们转发命令到 gitlab 容器呢？答案是肯定的，宿主机器上非 git 帐号就不受影响了，还可以正常使用。\n我们在宿主机器上创建 git 账户，并且使他的 uid 和 gid 和容器中的值完全一样，Gitlab 容器中 uid 和 gid 都是 998, 修改宿主机器中的值，将便于未来容器的升级。\nadduser git id git uid=998(git) gid=998(git) groups=998(git) 要完成共享 22 端口，要求 gitlab 容器中的 git 账户的 uid 和 gid 和宿主机器上完全相同，这样读取 SSH Key 时就不会有权限问题。关于如何修改两个系统中 git 账户的 uid 和 gid，可以通过命令 usermod 和 groupmod 手动修改 git 用户的 uid 和 gid参考文档。或者通过编辑 /data/var/lib/gitlab/etc/gitlab.rb 这个配置文件，修改其中的行，来使用其他的用户具体请参考这里:\nuser[\u0026#39;username\u0026#39;] = \u0026#39;other-git\u0026#39; user[\u0026#39;group\u0026#39;] = \u0026#39;other-git\u0026#39; user[\u0026#39;uid\u0026#39;] = 1001 user[\u0026#39;gid\u0026#39;] = 1001 修改完成之后，可以在 Docker 容器中执行 gitlab-ctl reconfigure 来使之生效.\n在宿主机器上切换到 git 账户：su - git 然后执行 ln -s /data/var/lib/gitlab/data/.ssh .ssh 与 gitlab 容器共享 .ssh 下面的内容。为了在宿主机器上可以使用 git 账户无密码登录到 gitlab 容器中，需要创建在 .ssh 目录中添加一组密钥，并且把公钥加到 .ssh/authorized_keys 文件中去。\n在宿主机器上执行:\nssh-keygen -t rsa -P \u0026#39;\u0026#39; cat ~/.ssh/id_rsa.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys 添加 no-port-forwarding,no-X11-forwarding,no-agent-forwarding,no-pty 到 ~/.ssh/authorized_keys 所在的行首，结果看起来是这样的：\nno-port-forwarding,no-X11-forwarding,no-agent-forwarding,no-pty ssh-rsa AAAAB3NzaC1yc2EAAA......CzGuj git@cn-bj-aliyun-3 登录测试一下\nssh -p 8022 127.0.0.1 观察到 ~/.ssh/authorized_keys 其它行都是这样\ncommand=\u0026#34;/opt/gitlab/embedded/service/gitlab-shell/bin/gitlab-shell key-32\u0026#34;,no-port-forwarding,no-X11-forwarding,no-agent-forwarding,no-pty ssh-rsa AAAAB3NzaC1yc2EAA......hOtpAl7J 在宿主机看来，每次 git 账户进行操作是都会执行 /opt/gitlab/embedded/service/gitlab-shell/bin/gitlab-shell, 我们恰好可以使用这个脚本来实现转发。\nmkdir -p /opt/gitlab/embedded/service/gitlab-shell/bin/ touch gitlab-shell chmod +x gitlab-shell 并且输入以下内容到 /opt/gitlab/embedded/service/gitlab-shell/bin/gitlab-shell 中\n#!/bin/sh ssh -p 8022 -o StrictHostKeyChecking=no git@127.0.0.1 \u0026#34;SSH_ORIGINAL_COMMAND=\\\u0026#34;$SSH_ORIGINAL_COMMAND\\\u0026#34; $0 $@\u0026#34; 一切就绪了， 可以使用 https://gitlab.example.com/repo.git 或者 git@gitlab.example.com:repo.git 这样的 URL 了。\n使用 SMTP 方式配置通知邮箱(腾讯企业邮箱) Gitlab SMTP 文档参考这里\ngitlab_rails[\u0026#39;smtp_enable\u0026#39;] = true gitlab_rails[\u0026#39;smtp_address\u0026#39;] = \u0026#34;smtp.exmail.qq.com\u0026#34; gitlab_rails[\u0026#39;smtp_port\u0026#39;] = 465 gitlab_rails[\u0026#39;smtp_user_name\u0026#39;] = \u0026#34;xxxx@xx.com\u0026#34; gitlab_rails[\u0026#39;smtp_password\u0026#39;] = \u0026#34;password\u0026#34; gitlab_rails[\u0026#39;smtp_authentication\u0026#39;] = \u0026#34;login\u0026#34; gitlab_rails[\u0026#39;smtp_enable_starttls_auto\u0026#39;] = true gitlab_rails[\u0026#39;smtp_tls\u0026#39;] = true gitlab_rails[\u0026#39;gitlab_email_from\u0026#39;] = \u0026#39;xxxx@xx.com\u0026#39; gitlab_rails[\u0026#39;smtp_domain\u0026#39;] = \u0026#34;exmail.qq.com\u0026#34; 改写默认的项目标签(Labels) 添加丰富的标准，方便进行项目管理。修改 issues_labels.rb 文件\nlabels = [ {\u0026#34;title\u0026#34;: \u0026#34;优先级:P0(紧急)\u0026#34;, \u0026#34;color\u0026#34;: \u0026#34;#E99695\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;立即处理\u0026#34;}, {\u0026#34;title\u0026#34;: \u0026#34;优先级:P1(高)\u0026#34;, \u0026#34;color\u0026#34;: \u0026#34;#E99695\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;优先处理\u0026#34;}, {\u0026#34;title\u0026#34;: \u0026#34;优先级:P2(中)\u0026#34;, \u0026#34;color\u0026#34;: \u0026#34;#E99695\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;有时间再处理\u0026#34;}, {\u0026#34;title\u0026#34;: \u0026#34;优先级:P3(低)\u0026#34;, \u0026#34;color\u0026#34;: \u0026#34;#E99695\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;暂不处理\u0026#34;}, {\u0026#34;title\u0026#34;: \u0026#34;分类:BUG\u0026#34;, \u0026#34;color\u0026#34;: \u0026#34;#D4C5F9\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;发现的BUG\u0026#34;}, {\u0026#34;title\u0026#34;: \u0026#34;分类:功能增强\u0026#34;, \u0026#34;color\u0026#34;: \u0026#34;#D4C5F9\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;增强已有的功能，属于优化的环节\u0026#34;}, {\u0026#34;title\u0026#34;: \u0026#34;分类:功能完善\u0026#34;, \u0026#34;color\u0026#34;: \u0026#34;#D4C5F9\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;完善功能\u0026#34;}, {\u0026#34;title\u0026#34;: \u0026#34;分类:文档修改\u0026#34;, \u0026#34;color\u0026#34;: \u0026#34;#D4C5F9\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;只是做文档修改\u0026#34;}, {\u0026#34;title\u0026#34;: \u0026#34;分类:新功能\u0026#34;, \u0026#34;color\u0026#34;: \u0026#34;#D4C5F9\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;新的功能和需求\u0026#34;}, {\u0026#34;title\u0026#34;: \u0026#34;项目:已上线\u0026#34;, \u0026#34;color\u0026#34;: \u0026#34;#C5DEF5\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;已发布上线\u0026#34;}, {\u0026#34;title\u0026#34;: \u0026#34;项目:已排期\u0026#34;, \u0026#34;color\u0026#34;: \u0026#34;#C5DEF5\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;已经安排了开发时间milestone\u0026#34;}, {\u0026#34;title\u0026#34;: \u0026#34;项目:已确认\u0026#34;, \u0026#34;color\u0026#34;: \u0026#34;#C5DEF5\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;功能已经确认，后续进行排期\u0026#34;}, {\u0026#34;title\u0026#34;: \u0026#34;项目:延后\u0026#34;, \u0026#34;color\u0026#34;: \u0026#34;#C5DEF5\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;功能无法确定是否开发，延期处理\u0026#34;}, {\u0026#34;title\u0026#34;: \u0026#34;项目:开发中\u0026#34;, \u0026#34;color\u0026#34;: \u0026#34;#C5DEF5\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;功能正在开发\u0026#34;}, {\u0026#34;title\u0026#34;: \u0026#34;项目:待讨论\u0026#34;, \u0026#34;color\u0026#34;: \u0026#34;#C5DEF5\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;需求已经提出，但是需要讨论是否需要开发\u0026#34;}, {\u0026#34;title\u0026#34;: \u0026#34;项目:测试中\u0026#34;, \u0026#34;color\u0026#34;: \u0026#34;#C5DEF5\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;功能已经完成开发，正在测试\u0026#34;} ] 总结 使用 Docker 方式安装 Gitlab 部署过程很简单，但是想达到一个理想的配置状况还是挺繁琐的，Docker 并不是治疗百病的良药，打铁还得自身硬。\n","permalink":"https://lewang.dev/posts/2018-12-18-gitlab-docker-install/","summary":"为什么要写这篇文章？ 曾经几年前在 Docker 还没有广泛应用的时候，在公司使用过源码的方式安装和升级过 Gitlab，虽远没有 Docker 方便，因为自己对 Linux 系统的理解，所以整体上感觉还是挺简单的。这几年随着 Docker 的普及，使得安装 Gitlab 更加的容易，不仅方便了我这样的老鸟，也更方便了小白用户们。但是 Gitlab 官方的 Docker 安装文档并没有写得很完善, 除了官方文档之外，检索出来的安装文档也是人云亦云，东拼西凑，结果也就是能运行起来，凑合着能用而已。避免出现下图中“我已经用 Docker 部署好啦”，其实已经翻车的情形。\n我希望每做一件小事的时候也都能抱着“知其然知其所以然”的心态对待，用 Docker 方式安装 Gitlab，说简单来说就是一行命令的事儿，但是这样就够了吗？我看是不够的，所以就有了这篇文档。\n本文需要达成的事项 在 CentOS 7 系统中安装 Docker 使用 Docker 方式安装中文版 Gitlab 和宿主机器共用 22(SSH) 端口 支持 SSH(22)/HTTPS(443) 方式推拉仓库 使用 SMTP 方式配置通知邮箱(腾讯企业邮箱) 改写默认的项目标签(Labels) 在 CentOS 7 系统中安装 Docker 这部分参考 Docker 的官方文档, 罗列一下安装步骤, 细节请看 Docker 的官方文档。如果使用 root 用户安装，sudo 可以去掉。\n1. 删除老版本 Docker $ sudo yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-selinux \\ docker-engine-selinux \\ docker-engine 2.","title":"使用 Docker 方式安装 Gitlab，没你想得那么简单"},{"content":"好久没有写过文字了，前几篇文也是自己从 Google Doc 中摘出来的工作日志，拿来凑凑数，刷新下 Github 的时间线，有点儿不太像话。看看自己书桌上叠起来超过一尺高的新书才知道，想看的还没来得及看完，想学的也还没来得及学会，想做的也没有做得很好，一年就过去了。2017 是我来魔都的第 5 年，回想这 5 年，自己的成长还是很多的，但 2017 这一年，好像与 2016 并没有什么大的不同，这让自己感到很担忧。\n在 2017 年的最后几天，终于离开了自己熟悉的工作环境，从自己的舒适空间加入了一个新的环境，我想这就是改变的开始，一个新的起点。\n2017 是平淡的，可能和未来的每一年也不会有太大差别，尽管我不希望这样。元旦假期这 3 天有空的时候都在回想，但是又想不起有那些特别印象深刻的事情，以至于总结都不太好写下去。我想那不如就回想几个和自己有关系的场景，做一个清单好了：\nBye 2017 区块链和比特币 人工智能（AI） 物联网大数据 Insurtech 和 Fintech 关于个人职业发展的思考 Hello 2018 Bye 2017 编程语言学习 Golang：完成基本语法学习（官方文档和《Go 语言实战》），可以无障碍阅读 Golang 项目代码（《自己动手写 Java 虚拟机》），并且可手动完成简单 Golang 项目用 Python 重写，主要有 eureka client Kotlin：除协程外，完成官方文档中所有语言部分的学习内容，并使用 kotlin 开发了 2 个项目，其中一个是用 kotlin 重写了 Aprereo CAS 的核心功能 TypeScript：完成基本语法学习，目前没有实际应用的场景，希望从 2018 起，自己在需要写 JavaScript 的地方，全部用 TypeScript 来代替 书籍阅读 阅读量太少，希望在 2018 年里能增大阅读量。\n技术类 《图说区块链》 严格讲不算技术类书籍 《自己动手写 Java 虚拟机》 《Go 语言实战》 《贝叶斯思维》未读完 《Spark 高级数据分析》未读完 《垃圾回收的算法和实现》未读完 《机器学习》未读完 文艺类 《追风筝的人》 今年读到最长的一篇小说， 从作者笔下故事了解了阿富汗的人文历史，很是感动和惊讶。另外就是觉得译者也很厉害，从头读到尾，除了人名，没觉得是在读一本英文翻译过来的书 《灿烂千阳》未读完 《上帝掷骰子吗》 感觉写这本书的作者应该是个天才，搜了一下，很神秘的作者 《乡关何处》 看着也挺有意思的 《野火集》 读晚了，读的大陆删节版，我觉得每一个人都应该读下这本书 《自私的基因》 《创业者的窘境》 看完觉得最该读这本书的人应该是我老婆 还有就是身边的亲密好友或同学 《人类简史》未读完 Kindle 版，用手机看的，亚马逊真牛逼，让我买了一个 kindle 放在家里吃灰 开源技术 计划搭建一个开源物联网平台，还没有想好具体要做的事情，所以没有什么进展 整理了常用的 docker templates，docker 和 python 一样成为自己不可或缺的工具 家庭网络 升级了硬件和软件，让家里无线网络有了更好的覆盖，并且让所有家庭联网设备都可以自由的访问互联网 儿子最喜欢的应用是 Youtube Kids 区块链和比特币 不记得是哪一天了，大约是在几个月之前，和同事在兰州料理吃午饭，这段时间大家都在讨论 ICO，区块链，交易所的事情，我突然想起自己在 2013 年的时候曾经关注过比特币和区块链，并且那个时候买了一些瑞波币，于是回去查了一下，私钥和地址都还在，并且由此莫名其妙赚到了人生的“第一桶金”。\n区块链（主要是数字货币、交易所和 ICO）在 2017 这一年全面爆发，各行各业的创业者都在想如何跟区块链技术搭上边，用区块链行业里的话来讲：区块链技术就是未来。但是大家谈论的最多的还是代币或者加密货币交易，比特币它自身就带着商业模式，大概只需要一个 DEMO 就可以大获成功。\n我比较认同 Coinbase 他们的愿景之一：为全世界的“低端人口”提供金融服务。不过 Coinbase 他们却把中国用户抛弃了。要是谈论金融服务，那又得思考，什么样的金融服务才是我等“低端人口”需要的。大家都在号称在做“普惠金融”，所以看看目前各类公司都在做什么，便可略知一二，很多时候，别人比我们自己还了解我们自己。\n人工智能（AI） 我想 2017 年的每一个技术人都应该从各种媒体渠道听说过 AlphaGo 的事迹，仿佛至此之后，人工智能变得特别的火，铺天盖地都是 AI 将要取代人类的信息。在 2017 年最后一个月里，有幸参加了 Google Developer Day 2017（GDD2017）大会，当然大会主题基本也都是 AI/IOT/Bigdata 相关的东西。记得李飞飞演讲中的这句话：The AI has changed the world，and who will change the AI？是的，Tensorflow API 工程师们，得好好思考一番了。\n另外有件事，我本人在读研期间是研究数据库方向，最近 Jeff Dean 的论文 《The Case for Learned Index Structures》 把机器学习带到了数据库研究领域，我想很快，类似思路就会出现在计算机科学相关领域，一下子仿佛又打开了一扇窗的感觉。对于我来讲，目前我希望自己弄清楚人工智能，机器学习，深度学习这几个名词之间的关系是怎样的，不至于在茶余饭后瞎扯淡时不知道别人在讨论什么就行。\n物联网大数据 把物联网和大数据放在一起应该是一个超热的话题了。在这两个领域，常见情景下技术方案已经没有任何所谓的技术壁垒。各大云厂商（Google，AWS，MS，Aliyun 等等）都推出或者增强了自己的物联网平台以及配套设施，智能硬件门槛也变得非常的低，让创业者或者企业不用费太大力气就可以搭建数据采集平台。\n短板效应不在：除了厂商提供云服务外，自行搭建也不再是难题。各种开源软件和组件都已经经过了长期的验证，只要用好了这些软件或者服务，相当于全世界最牛的程序员都在为你“打工”。这也是我计划搭建开源物联网平台的初衷。\n2017 年，NB-IoT 的新闻也越来越多，万物相连的未来已经到来。\nInsurtech 和 Fintech 就我个人而言，头次把这两个词放在一起的是在一场面试上。我在前家公司工作的 4 年半时间里，公司发展得很慢，远远低于我的预期。从开始的智能硬件创业到最近（2017）的 Insurtech，业务虽然有转型，但是总能看到最初 UBI 车险的影子。保险是一个强监管的行业，里面水很深，但也到处都是机会。\n像金融服务一样，越来越多的人，在各种场景下都需要各类保险来增加自身抗风险的能力。2017 年是我深入了解保险业和保险科技，包括但不限于车险、运费险、健康险以及各类创新险的元年，也是我进入金融科技领域（互联网金融）的元年。\n到了今天，除了维持银行对我的用户等级的要求，一般情况下，我已经全部使用各类新兴的理财 APP 管理自己的血汗钱了，并且只需要在 APP 上简单的按几下，各类账户就自动开通，并且收益率很容易就可以跑赢 CPI。\n目前自己 2017 年自己用过的理财 APP（除银行/证券 APP 外） 有：\n理财通（在微信钱包九宫格里，总体年收益率 5%，组成：活期 74% + 基金 26% ） 陆金所（各类抵用券大概有几百块，总体年收益率大约有 7.6%, 组成：定期（企业融资） 85% + 活期 5% + 基金 10%） 挖财宝（刚刚开始用，目测第一个月投入 1w，大概会有 200 左右的收益） 行业总是在不断的发展和变化的，自己也在不断的成长。\n2018 年希望理财方面能增加股票（主要是美股和港股）和指数型基金比例，稍微提高下自己对风险的耐受度。\n关于个人职业发展的思考 前几天看到自己的母校天大发了文章列了 2012 年到 2017 年这 5 年学校的变化，我看完后大为感叹：明显这 5 年学校的发展变化大大超过了我待在学校的 8 年。跳出学校这个小群里，整个社会这 5 年也是变化特别大的：比如北上广深等城市房价的暴涨，车辆保有量的暴增；再看看看互联网行业：BAT 中 B 的掉队，以及无数新兴行业颠覆者的出现。自己虽身在其中却只能作为浪潮中一个好不起眼的存在，去看着别人战火烽烟，我希望自己也能真正的进入战场，有对手（或者别人把你当对手）拼个你死我活（一同成长）。\n带着这样的天马行空的梦想，自己从毕业到现在一直都在很小，甚至是微小的创业公司工作。刚好前几天在朋友圈看到一篇讲职业规划的文章（牛人都需要职场规划指导，何况平凡如你我）, 自己看完后是有些感悟的。\n就这篇文章里来讲，我就是一个最好的反例。就像软件设计或者建筑设计一样，很多事情都是有范式的（或者模式），只要大家按照范式来做，一定不会差得太远。这件事，自己爱折腾的个性也就恰好体现出来了：我自以为范式是给一般人准备的，却没料想到自己其实就是一般人，而只是自己不太愿意承认而已。\n另外还有一个就是忽略了平台（大公司/明星公司）威力：一个好平台可能就是一条捷径或者是一个招牌。\n不过，我还是觉得选择是没有对和错的，也没有好和坏，只要知道自己要干什么就行。\nHello 2018 2018 希望自己能努力工作，努力学习，好好生活。\n","permalink":"https://lewang.dev/posts/2017-12-31-year-end-reviews-of-2017/","summary":"好久没有写过文字了，前几篇文也是自己从 Google Doc 中摘出来的工作日志，拿来凑凑数，刷新下 Github 的时间线，有点儿不太像话。看看自己书桌上叠起来超过一尺高的新书才知道，想看的还没来得及看完，想学的也还没来得及学会，想做的也没有做得很好，一年就过去了。2017 是我来魔都的第 5 年，回想这 5 年，自己的成长还是很多的，但 2017 这一年，好像与 2016 并没有什么大的不同，这让自己感到很担忧。\n在 2017 年的最后几天，终于离开了自己熟悉的工作环境，从自己的舒适空间加入了一个新的环境，我想这就是改变的开始，一个新的起点。\n2017 是平淡的，可能和未来的每一年也不会有太大差别，尽管我不希望这样。元旦假期这 3 天有空的时候都在回想，但是又想不起有那些特别印象深刻的事情，以至于总结都不太好写下去。我想那不如就回想几个和自己有关系的场景，做一个清单好了：\nBye 2017 区块链和比特币 人工智能（AI） 物联网大数据 Insurtech 和 Fintech 关于个人职业发展的思考 Hello 2018 Bye 2017 编程语言学习 Golang：完成基本语法学习（官方文档和《Go 语言实战》），可以无障碍阅读 Golang 项目代码（《自己动手写 Java 虚拟机》），并且可手动完成简单 Golang 项目用 Python 重写，主要有 eureka client Kotlin：除协程外，完成官方文档中所有语言部分的学习内容，并使用 kotlin 开发了 2 个项目，其中一个是用 kotlin 重写了 Aprereo CAS 的核心功能 TypeScript：完成基本语法学习，目前没有实际应用的场景，希望从 2018 起，自己在需要写 JavaScript 的地方，全部用 TypeScript 来代替 书籍阅读 阅读量太少，希望在 2018 年里能增大阅读量。\n技术类 《图说区块链》 严格讲不算技术类书籍 《自己动手写 Java 虚拟机》 《Go 语言实战》 《贝叶斯思维》未读完 《Spark 高级数据分析》未读完 《垃圾回收的算法和实现》未读完 《机器学习》未读完 文艺类 《追风筝的人》 今年读到最长的一篇小说， 从作者笔下故事了解了阿富汗的人文历史，很是感动和惊讶。另外就是觉得译者也很厉害，从头读到尾，除了人名，没觉得是在读一本英文翻译过来的书 《灿烂千阳》未读完 《上帝掷骰子吗》 感觉写这本书的作者应该是个天才，搜了一下，很神秘的作者 《乡关何处》 看着也挺有意思的 《野火集》 读晚了，读的大陆删节版，我觉得每一个人都应该读下这本书 《自私的基因》 《创业者的窘境》 看完觉得最该读这本书的人应该是我老婆 还有就是身边的亲密好友或同学 《人类简史》未读完 Kindle 版，用手机看的，亚马逊真牛逼，让我买了一个 kindle 放在家里吃灰 开源技术 计划搭建一个开源物联网平台，还没有想好具体要做的事情，所以没有什么进展 整理了常用的 docker templates，docker 和 python 一样成为自己不可或缺的工具 家庭网络 升级了硬件和软件，让家里无线网络有了更好的覆盖，并且让所有家庭联网设备都可以自由的访问互联网 儿子最喜欢的应用是 Youtube Kids 区块链和比特币 不记得是哪一天了，大约是在几个月之前，和同事在兰州料理吃午饭，这段时间大家都在讨论 ICO，区块链，交易所的事情，我突然想起自己在 2013 年的时候曾经关注过比特币和区块链，并且那个时候买了一些瑞波币，于是回去查了一下，私钥和地址都还在，并且由此莫名其妙赚到了人生的“第一桶金”。","title":"有关 2017 流水账和胡思乱想的记录"},{"content":"背景 阿里云云主机两块 100G 的云盘合一个逻辑卷（LV）来使用，单个的 100G 磁盘不够用，需要合在一起使用，并且方便以后扩容\n基本知识 磁盘 /dev/xvdb /dev/xvdc 分区, 使用 fdisk 进行分区 fdisk \u0026gt; n \u0026gt; p \u0026gt; 1..4, 主分区最多只有 4 个 准备分区后，将分区类型变为 LVM 分区，fdisk \u0026gt; t \u0026gt; 8e, 8e 是 LVM 类型 ID 物理卷（PV），卷组（VG），逻辑卷（LV），从磁盘分区创建 PV，通过 PV 创建 VG 或者把 PV 加入已有的 VG，在 VG 上创建 LV，LV 看起来就是逻辑的上磁盘，使用和真实的磁盘没什么明显区别, 在 LV 上构建文件系统 创建 创建物理卷 pvcreate /dev/xvdb1，对分区进行操作 创建 vg0 卷组 vgcreate vg0 /dev/xvdb1 查看卷组 vgdisplay， 可以看到卷组有多大 在 vg0 上创建 data 逻辑卷 lvcreate -L 99G -n data vg0 或者 lvcreate -l 25556 -n data vg0 创建文件系统 mkfs.ext4 /dev/vg0/data 挂载到系统目录即可使用 mount /dev/vg0/data /mnt 或者在 /etc/fstab 添加一行，然后 mount -a 添加磁盘 创建物理卷 pvcreate /dev/xvdc1，对分区进行操作 添加到 vg0 卷组 vgextend vg0 /dev/xvdc1 扩容逻辑卷 lvextend -L +99G /dev/vg0/data, 可以通过 vgdispaly 查看卷组剩余空间有多少 扩容文件系统 resize2fs /dev/vg0/data, 不需要卸载逻辑卷，可以在线完成扩容 备注 过程中有一块磁盘已经在使用，需要 umount 后再加入 LVM，出现了 device is busy 的情况，系统提示使用 lsof 或者 fuser 查询哪些进程在使用这个磁盘或者目录，最后通过 fuser 查询到进程号后，kill -9 pid 后解决 fuser -m /mnt\n参考链接 Linux 下 LVM 的配置详解 Linux 命令大全 ","permalink":"https://lewang.dev/posts/2017-08-03-lvm-in-action/","summary":"背景 阿里云云主机两块 100G 的云盘合一个逻辑卷（LV）来使用，单个的 100G 磁盘不够用，需要合在一起使用，并且方便以后扩容\n基本知识 磁盘 /dev/xvdb /dev/xvdc 分区, 使用 fdisk 进行分区 fdisk \u0026gt; n \u0026gt; p \u0026gt; 1..4, 主分区最多只有 4 个 准备分区后，将分区类型变为 LVM 分区，fdisk \u0026gt; t \u0026gt; 8e, 8e 是 LVM 类型 ID 物理卷（PV），卷组（VG），逻辑卷（LV），从磁盘分区创建 PV，通过 PV 创建 VG 或者把 PV 加入已有的 VG，在 VG 上创建 LV，LV 看起来就是逻辑的上磁盘，使用和真实的磁盘没什么明显区别, 在 LV 上构建文件系统 创建 创建物理卷 pvcreate /dev/xvdb1，对分区进行操作 创建 vg0 卷组 vgcreate vg0 /dev/xvdb1 查看卷组 vgdisplay， 可以看到卷组有多大 在 vg0 上创建 data 逻辑卷 lvcreate -L 99G -n data vg0 或者 lvcreate -l 25556 -n data vg0 创建文件系统 mkfs.","title":"LVM 实战记录"},{"content":"背景 微服务，日志分散且种类多（php/java/python），用 docker 起应用，日志通过卷放在宿主机器指定目录下，服务有众多实例，metrics 数据也不仅相同，无论是日志还是 metrics 数据，都可以看作是时间序列数据\n分散主要表现为：\n多个主机 多个目录下多个文件 应用开发所使用的技术栈不同日志格式不同 web log（主要是 nginx） 各类事件 一些其它事务性的日志 日志为时间序列数据，包括：\n系统日志: 各类系统产生的跟业务有关的日志或者与业务无关的日志 web 服务器日志：如 access.log/error.log 等有固定格式的日志 性能监控日志：打点记录各类服务的 metrics(全部为数值类型 long/double/bool) 系统日志 由时间戳、一些枚举值以及日志内容(变长字符串)组成\n日志时间颗粒度：支持毫秒/秒 枚举值包括： [必选]主机名/host [必选]服务名/service [必选]实例编号/instance [必选]日记级别/level：info/debug/warn/trace/error 等 [可选]异常名/exception: 如果是异常，把异常名作为枚举值记录 [可选]线程名/thread: [可选]方法名/method： [可选]文件名/file： [可选]行号/line： 日志内容(变长字符串): 为实际记录的内容以及异常堆栈信息 web 服务器日志 access log（nginx） 日志内容：主要是文本(string）或者一些系统 metrics 数据(数值类型 long/double)\n日志存储和处理： 数据磁带（1 周）：kafka 提供热数据检索（1 个月）：solr(or lucence based on cassandra) 日志存储（永久）： kariosdb/cassandra: 支持 double/long/string 类型，kariosdb 相当于在 cassandra 上面套了一个壳，这样简化了很多时间序列数据处理的操作 数据展示：grafana，官方支持 kariosdb 扩展：数据深度挖掘分析 系统架构 特点：\n服务现在，面向未来的架构（每层可单独升级或者替换技术栈） 低入侵，原有系统日志不需要改造，使用 flume agent 收集 整个系统无单点，保证可靠性 层次清晰，好扩展，无论 Flume，kafka 还是 cassandra 都方便扩容，存储层使用 kafka 滚动存储数据，cassandra 存储所有日志数据和 metrics 利用现有社区活跃的开源产品构建，除了 kalka 引入了 zk 外，没有其它依赖，整个存储层可以结合现有的资源 其它方案 ELK ELK 技术栈在整体架构上与前面的比较接近（几乎差不多），将会引入数个与目前系统没有太大联系的产品（E/L），前面的架构不仅用于日志的处理，并且可扩展支持处理所有的事件（数据流）处理，更符合目前业务。ELK 优点是拆箱可用，经过一段时间的试用，目前是放弃状态\n其它非 JVM 解决方案没有在考虑范围之类，包括但不限于： scribe https://github.com/facebookarchive TICK Stack https://www.influxdata.com/time-series-platform/, 比较适合收集服务器和各类服务的 metrics 数据，配合 grafana，可以替代 zabbix 的工作，其中日志存储（output）默认使用 influxdb，influxdb 目前开源只有单机版，但 telegraf 官方支持 output 到 cassandra/kafka/rabbit 等，所以存储也不是问题。前端可以 grafana（支持 kariosdb/influxdb/mysql/opentsdb 等作为数据源）。 rsync 直接同步日志到指定机器，然后在机器上集中处理，使用 mysql/postgresql 等存储日志，目前的量是可以的，但是也需要做不少开发工作 ","permalink":"https://lewang.dev/posts/2017-07-23-log-processing-system/","summary":"背景 微服务，日志分散且种类多（php/java/python），用 docker 起应用，日志通过卷放在宿主机器指定目录下，服务有众多实例，metrics 数据也不仅相同，无论是日志还是 metrics 数据，都可以看作是时间序列数据\n分散主要表现为：\n多个主机 多个目录下多个文件 应用开发所使用的技术栈不同日志格式不同 web log（主要是 nginx） 各类事件 一些其它事务性的日志 日志为时间序列数据，包括：\n系统日志: 各类系统产生的跟业务有关的日志或者与业务无关的日志 web 服务器日志：如 access.log/error.log 等有固定格式的日志 性能监控日志：打点记录各类服务的 metrics(全部为数值类型 long/double/bool) 系统日志 由时间戳、一些枚举值以及日志内容(变长字符串)组成\n日志时间颗粒度：支持毫秒/秒 枚举值包括： [必选]主机名/host [必选]服务名/service [必选]实例编号/instance [必选]日记级别/level：info/debug/warn/trace/error 等 [可选]异常名/exception: 如果是异常，把异常名作为枚举值记录 [可选]线程名/thread: [可选]方法名/method： [可选]文件名/file： [可选]行号/line： 日志内容(变长字符串): 为实际记录的内容以及异常堆栈信息 web 服务器日志 access log（nginx） 日志内容：主要是文本(string）或者一些系统 metrics 数据(数值类型 long/double)\n日志存储和处理： 数据磁带（1 周）：kafka 提供热数据检索（1 个月）：solr(or lucence based on cassandra) 日志存储（永久）： kariosdb/cassandra: 支持 double/long/string 类型，kariosdb 相当于在 cassandra 上面套了一个壳，这样简化了很多时间序列数据处理的操作 数据展示：grafana，官方支持 kariosdb 扩展：数据深度挖掘分析 系统架构 特点：","title":"日志收集和分析系统架构"},{"content":"背景 Java 生态下的日志库太多，配置也不同，大多数情况下会使用 SLF4j (又引入了一个库)来抽象日志接口。在使用 Log4j2 后，发现可以不使用 SLF4j 了，并且配置变得更简单，可以使用 lombok 的 log4j2 注解等。\n需要搞清楚\n如何设置哪些日志要记录下来 日志记录到哪里去 LEVEL 日志级别： 内置（有 Fatal）：All \u0026lt; Trace \u0026lt; Debug \u0026lt; Info \u0026lt; Warn \u0026lt; Error \u0026lt; Fatal \u0026lt; OFF 还可以自定义： https://logging.apache.org/log4j/2.0/manual/customloglevels.html Appender: 日志输出的目的地 内置的目的地有：\nconsole, files（FIle/RollingFile）, remote socket servers, Apache Flume, JMS, remote UNIX Syslog daemons, various database APIs \u0026hellip; Appender 在接受到日志以后，可以通过级别过滤选择记录日志，具体配置： https://logging.apache.org/log4j/2.0/manual/appenders.html\nLogger 负责决定哪些日志要记录和发配日志 哪些需要记日志，设置什么级别，并且配置日志输出到哪些个 Appender 中去都在 Logger 中配置。Logger 有类似继承的关系，名为 Root 的的 Logger 为所有 Logger 的根，也就是说没有做特殊设置（additivity=false), 那么这个 Logger 的日志将会记录到自己指定的 Appender，并且也都会记录到自己所有“父” Logger 设置的 Appender 中去\n继承关系由 Logger 的名称推断出来，名称可以认为是 Logger 树的前序遍历打印的节点路径。\nLogger 定义\nLogger Name 将会记录日志的 Logger Root Root X Root, X X.Y Root, X, Y X.Z Root, X,Z M Root, M Filter 日志过滤器 DENY,ACCEPT,NEUTRAL 三个选项，所有进入当前 Appender 的所有日志，Filter 可以设置来选择日志是否要记录\n","permalink":"https://lewang.dev/posts/2017-07-15-log4j2/","summary":"背景 Java 生态下的日志库太多，配置也不同，大多数情况下会使用 SLF4j (又引入了一个库)来抽象日志接口。在使用 Log4j2 后，发现可以不使用 SLF4j 了，并且配置变得更简单，可以使用 lombok 的 log4j2 注解等。\n需要搞清楚\n如何设置哪些日志要记录下来 日志记录到哪里去 LEVEL 日志级别： 内置（有 Fatal）：All \u0026lt; Trace \u0026lt; Debug \u0026lt; Info \u0026lt; Warn \u0026lt; Error \u0026lt; Fatal \u0026lt; OFF 还可以自定义： https://logging.apache.org/log4j/2.0/manual/customloglevels.html Appender: 日志输出的目的地 内置的目的地有：\nconsole, files（FIle/RollingFile）, remote socket servers, Apache Flume, JMS, remote UNIX Syslog daemons, various database APIs \u0026hellip; Appender 在接受到日志以后，可以通过级别过滤选择记录日志，具体配置： https://logging.apache.org/log4j/2.0/manual/appenders.html\nLogger 负责决定哪些日志要记录和发配日志 哪些需要记日志，设置什么级别，并且配置日志输出到哪些个 Appender 中去都在 Logger 中配置。Logger 有类似继承的关系，名为 Root 的的 Logger 为所有 Logger 的根，也就是说没有做特殊设置（additivity=false), 那么这个 Logger 的日志将会记录到自己指定的 Appender，并且也都会记录到自己所有“父” Logger 设置的 Appender 中去","title":"Log4j2 快速入门"},{"content":"背景 目前公司主要服务都是直接使用 MySQL 主服务器，从服务主要给离线数据分析服务使用，由于前期弄得比较简单的粗暴，从服务上还有一两个数据库在做生产使用, 并且从服数据已经不能和主服进行进行同步了，有大量错误，忽略都没有办法进行。此外，主服仅配置了三个核心数据的 binlog，随着业务的变化，其它数据库不能走主从这条路来同步数据，于是希望不停机的情形下重新调整主服配置，记录所有的数据库的 binlog，同时添加新的从服务器来同步数据\n方案 1 MySQL 的主从是通过同步 binlog 日志来实现数据同步的，于是需要想办法把从服数据先于主服同步，记录 binlog 的 pos 值，再配置从服从该 pos 处开始同步，考虑可以使用 mysqldump 导出所有 innodb 数据，使用 rsync 同步所有 myisam 数据文件，然后再开启主从同步。但是目前这种方案不适用，主服不能长时间停机\n方案 2 使用 xtrabackup 来完成目标\n主从服务器上都需要安装 xtrabackup（实际使用 xtrabackupex）：\nyum install http://www.percona.com/downloads/percona-release/redhat/0.1-4/percona-release-0.1-4.noarch.rpm yum install -y percona-xtrabackup-24 主服： 备份数据 # 注意数据库名称的转义，例如 - 号是 @002d innobackupex --defaults-file=/etc/my.cnf --socket=/var/lib/mysql/mysql.sock --user=root --password=xxxx --parallel=2 --databases=\u0026#34;db1 db2\u0026#34; /data/backup/xtrabackup/ 保持事务一致 innobackupex --apply-log /data/backup/xtrabackup/2017-06-06_13-16-21/ 同步数据 rsync -avHz 2017-06-06_13-16-21 sysops@cow:/data/backup 从服： 修改 my.cnf 相关配置，恢复备份数据\n# 关闭 MySQL Servier 后恢复数据 innobackupex --defaults-file=/etc/my.cnf --copy-back /data/backup/2017-06-06_13-16-21 修改数据权限\nchown -R mysql.mysql mysql 开启从服，登录 msyql 添加主从配置，并开启同步\n# Master 上执行 GRANT REPLICATION SLAVE ON *.* TO \u0026#39;repl\u0026#39;@\u0026#39;10.23.9.146\u0026#39; IDENTIFIED BY \u0026#39;password\u0026#39;; # Slave 上执行 [root@bull data]# cat backup/2018-04-26_21-27-31/xtrabackup_binlog_info mysql-bin.000058 103394265 CHANGE MASTER TO MASTER_HOST=\u0026#39;10.4.25.28\u0026#39;, MASTER_USER=\u0026#39;repl\u0026#39;, MASTER_PASSWORD=\u0026#39;password\u0026#39;, MASTER_PORT=3306, MASTER_LOG_FILE=\u0026#39;mysql-bin.000058\u0026#39;, MASTER_LOG_POS=103394265; 检查主从状态 show master status; show slave status\\G; 参考 [percona-xtrabackup] (https://www.percona.com/doc/percona-xtrabackup/LATEST/index.html) [wsgzao.github.io/post/xtrabackup] (https://wsgzao.github.io/post/xtrabackup/) ","permalink":"https://lewang.dev/posts/2017-06-06-xtrabackup/","summary":"背景 目前公司主要服务都是直接使用 MySQL 主服务器，从服务主要给离线数据分析服务使用，由于前期弄得比较简单的粗暴，从服务上还有一两个数据库在做生产使用, 并且从服数据已经不能和主服进行进行同步了，有大量错误，忽略都没有办法进行。此外，主服仅配置了三个核心数据的 binlog，随着业务的变化，其它数据库不能走主从这条路来同步数据，于是希望不停机的情形下重新调整主服配置，记录所有的数据库的 binlog，同时添加新的从服务器来同步数据\n方案 1 MySQL 的主从是通过同步 binlog 日志来实现数据同步的，于是需要想办法把从服数据先于主服同步，记录 binlog 的 pos 值，再配置从服从该 pos 处开始同步，考虑可以使用 mysqldump 导出所有 innodb 数据，使用 rsync 同步所有 myisam 数据文件，然后再开启主从同步。但是目前这种方案不适用，主服不能长时间停机\n方案 2 使用 xtrabackup 来完成目标\n主从服务器上都需要安装 xtrabackup（实际使用 xtrabackupex）：\nyum install http://www.percona.com/downloads/percona-release/redhat/0.1-4/percona-release-0.1-4.noarch.rpm yum install -y percona-xtrabackup-24 主服： 备份数据 # 注意数据库名称的转义，例如 - 号是 @002d innobackupex --defaults-file=/etc/my.cnf --socket=/var/lib/mysql/mysql.sock --user=root --password=xxxx --parallel=2 --databases=\u0026#34;db1 db2\u0026#34; /data/backup/xtrabackup/ 保持事务一致 innobackupex --apply-log /data/backup/xtrabackup/2017-06-06_13-16-21/ 同步数据 rsync -avHz 2017-06-06_13-16-21 sysops@cow:/data/backup 从服： 修改 my.cnf 相关配置，恢复备份数据","title":"MySQL 数据备份和不停机重新搭建主从同步"},{"content":" 政策已变，目前只能办理有效期为 15 天的临牌，并且最多只能办理两次\n问题 外地户口，上海购车办理机动车(出省)临牌(出省和不出省的临牌办理方法一样,出省临牌有效期是30天，不出省的是15天)\n文档记录状态 可用\n发生时间 2016年01月28日9:00至9:30\n体验得分 90\n办理地点 黄浦公安分局交警支队，地址上海黄浦区陆家浜路88号（地铁4号线南浦大桥站1号出口200米处）\n可办理时间 周一至周六 8:30-17:00\n需要材料 车辆合格证原件和复印件 购车发票原件和复印件 交强险保单原件和复印件 身份证原件和正反面复印件 零钱5元 办理流程记录 进入大厅后跟保安说办理机动车临牌，拿一张《申请办理机动车临时号牌单》，然后坐在椅子上排队并填好临时号牌单 等待办理, 交警会打印两张临牌出来 恭喜你，没有第3步，可以拿着临牌走了 提高效率的小提示 自带黑色签字笔一支 原件和复印件分开成两份 ","permalink":"https://lewang.dev/posts/2016-01-28-banlinpai/","summary":" 政策已变，目前只能办理有效期为 15 天的临牌，并且最多只能办理两次\n问题 外地户口，上海购车办理机动车(出省)临牌(出省和不出省的临牌办理方法一样,出省临牌有效期是30天，不出省的是15天)\n文档记录状态 可用\n发生时间 2016年01月28日9:00至9:30\n体验得分 90\n办理地点 黄浦公安分局交警支队，地址上海黄浦区陆家浜路88号（地铁4号线南浦大桥站1号出口200米处）\n可办理时间 周一至周六 8:30-17:00\n需要材料 车辆合格证原件和复印件 购车发票原件和复印件 交强险保单原件和复印件 身份证原件和正反面复印件 零钱5元 办理流程记录 进入大厅后跟保安说办理机动车临牌，拿一张《申请办理机动车临时号牌单》，然后坐在椅子上排队并填好临时号牌单 等待办理, 交警会打印两张临牌出来 恭喜你，没有第3步，可以拿着临牌走了 提高效率的小提示 自带黑色签字笔一支 原件和复印件分开成两份 ","title":"办理机动车临牌"},{"content":"问题 外地户口＋上海居住证，外地驾照即将到期，需要将外地驾照转入上海并且进行驾照到期换证。\n可用状态 可用\n发生时间 2015年10月15日8:00至10:00\n体验得分 90\n办理地点 车辆管理所三分所，地址浦东新区沪南公路2638 号\n可办理时间 周一至周五 9:00-17:00\n办理流程记录 前往4号楼的3层填表缴费并拍照，缴费需要排队，人较多，费用 25 元 拍好照片并拿到照片和表格后前往4号楼2层填表缴费并体检，缴费需要排队，人较多，费用 60 元 缴完体检费进去之后，需要填表并且贴好照片，体检项都是分开进行，主要体检内容包括视力，听力，身高体重，色盲等检测，其他项都是医生随手填上去的，哪个人少就先去体检哪个。我体检的顺序依次是视力，听力，身高体重，色盲检测。 每项体检完，看下体检表格，看看体检项有没有空的，如果没有就直接去出口处，把表格交上去，然后等报告 拿到体检报告后，直接去1号楼一层大厅门口右手处工作人员拿号，号码那张纸要保存好，最后一步领证还需要使用。 叫号后前往柜台管理，跟工作人员确认下需要办理的内容。我这里是办理转入和到期换证。这里会使用照片一张，工作人员会提供剪刀。办理过程大约需要5分钟 前往缴费处缴费，注意看下缴费窗口的号码，缴费处在大厅另外一侧，费用 10 元 前往发证处等待叫号领证 提高效率的小提示 8点30之前到达4号楼3层排队, 尽管 9 点才开始 自带黑色签字笔一支 身份证复印件和居住证复印件各一份 ","permalink":"https://lewang.dev/posts/2015-10-15-huanzheng/","summary":"问题 外地户口＋上海居住证，外地驾照即将到期，需要将外地驾照转入上海并且进行驾照到期换证。\n可用状态 可用\n发生时间 2015年10月15日8:00至10:00\n体验得分 90\n办理地点 车辆管理所三分所，地址浦东新区沪南公路2638 号\n可办理时间 周一至周五 9:00-17:00\n办理流程记录 前往4号楼的3层填表缴费并拍照，缴费需要排队，人较多，费用 25 元 拍好照片并拿到照片和表格后前往4号楼2层填表缴费并体检，缴费需要排队，人较多，费用 60 元 缴完体检费进去之后，需要填表并且贴好照片，体检项都是分开进行，主要体检内容包括视力，听力，身高体重，色盲等检测，其他项都是医生随手填上去的，哪个人少就先去体检哪个。我体检的顺序依次是视力，听力，身高体重，色盲检测。 每项体检完，看下体检表格，看看体检项有没有空的，如果没有就直接去出口处，把表格交上去，然后等报告 拿到体检报告后，直接去1号楼一层大厅门口右手处工作人员拿号，号码那张纸要保存好，最后一步领证还需要使用。 叫号后前往柜台管理，跟工作人员确认下需要办理的内容。我这里是办理转入和到期换证。这里会使用照片一张，工作人员会提供剪刀。办理过程大约需要5分钟 前往缴费处缴费，注意看下缴费窗口的号码，缴费处在大厅另外一侧，费用 10 元 前往发证处等待叫号领证 提高效率的小提示 8点30之前到达4号楼3层排队, 尽管 9 点才开始 自带黑色签字笔一支 身份证复印件和居住证复印件各一份 ","title":"驾照转入换证"},{"content":" 这是一篇译文，原文链接：Tuning NGINX for Performance\nNginx 为人熟知的是在负载均衡、静态缓存和 WEB 服务器等方面的高性能，目前世界上最繁忙的站点中大约有 40% 在使用 Nginx。绝大多数情况下，大多数默认的 Nginx 和 Linux 配置都可以工作得非常好，但也需要做一些优化以获得最好的性能。本文将讨论在优化系统时需要考虑的 Nginx 和 Linux 的部分配置。可配置的选项有很多，但是本文只涵盖推荐大多数用户调整的配置选项。本文没有涵盖的配置选项，只有那些对 Nginx 和 Linux 有了深入的理解的人或者获得了 Nginx 技术支持和专业的服务团队的推荐建议后，才可以考虑调整。Nginx 专业服务器团队已经为世界上一些最繁忙的站点通过优化 Nginx 获得了最高水平的性能，并且可以为任何需要获得自己系统最大产出的客户服务。\n简介 本文假设读者对 Nginx 架构和配置的概念已有了基本的了解。Nginx 的文档内容将不会在本文中重复，但本文会提供各项配置简要的介绍和相关文档的链接。\n在性能调优时，要遵循一个好的规则：一次只修改一个配置选项，如果这个修改没有在性能方面带来优化，那么要再改回默认值。\n我们从 Linux 性能优化的讨论开始，因为 Linux 性能优化的一些值会影响到 Nginx 的一些配置。\nLinux 配置 尽管现代 Linux 内核（2.6+）在各种配置情况下都工作得很好，但也有一些配置是想要修改的。如果操作系统的配置设置的太低，那内核日志将会有错误信息，从而得知哪些配置需要调整。Linux 性能优化可能涉及的配置有很多，这里我们只讨论那些优化达到正常工作负载最有可能涉及到的那些配置。调整这些配置请参考详细的 Linux 文档。\nBacklog 队列 下面的配置选项与网络连接和其排队方法直接相关。如果连入率很高（译者注：客户端发起的连接很多）且系统性能配置不匹配，例如一些连接表现得有所停顿，那么修改下面得配置将可能有用。\nnet.core.somaxconn: 设置等待 Nginx 接受的连接队列的大小。由于 Nginx 接受连接非常的快，这个值通常情况下不用设置得很大，但系统默认值可能比较小，所以对于流量比较大的站点，增大这个值是个不错的想法。如果这个值太小，在内核日志中应该会看到错误消息，那么就需要增大这个值，直到错误消失。注意：若将这个值设置为大于 512 的话，那么需要在 Nginx 配置中修改 listen 指令的 backlog 参数来匹配这个数字。\nnet.core.netdev_max_backlog: 设置数据包在被发送到 CPU 前可被网卡缓存的速率。对于带宽很大的机器来说，这个值需要增大。可以查阅网卡关于这项设置的建议文档或者查看内核日志中此项设置相关的错误。\n文件描述符 文件描述符是用于处理例如连接和打开的文件等的操作系统资源。Nginx 在一个连接中使用文件描述符可以达到两个，例如 Nginx 做代理，那文件描述符一个用于客户端连接，另外一个用于代理服务器，但如果开启 HTTP 保持连接，那这个比例将会很低。对于一个连接数量很大很大的系统来说，这个值可能需要调整：\nsys.fs.file_max: 文件描述符的系统级限制。\nnofile: 文件描述符用户级限制，可以在 /etc/security/limits.conf 文件中修改。\n临时端口范围(Ephemeral ports) 当 Nginx 用作代理，每一个到后端服务器的连接都会短暂的、临时的使用一个端口。\nnet.ipv4.ip_local_port_range: 设置端口启始范围。如果观察到端口耗尽，那么需要增大这个范围。通常的端口范围设置是 1024 到 65000。\nnet.ipv4.tcp_fin_timeout: 设置端口停止使用后可再次被其它连接使用所需要的时间。通常默认值是 60 秒，但通常减少到 30 秒或者 15 秒都是安全的\nNginx 配置 下面是一些影响系统性能的 Nginx 指令。前面已经说过，本文只讨论一些推荐给大多数人调整的指令。其它没有提到的任何指令，若没有 Nginx 团队的建议，推荐不要修改。\n工作进程 Nginx 可以运行多个工作进程，每一个都可以处理大量的连接。通过下面的指令可以控制运行工作进程的数量和每个进程处理连接的数量：\nworker_processes:控制 Nginx 运行工作进程的数量。多数情况下，每一个 CPU 核运行一个工作进程的方式可以很好的工作。可以通过设置指令的值为 \u0026ldquo;auto\u0026rdquo; 来达到这个效果。但也有需要增大这个数字的时候，例如工作进程需要做很多的磁盘 IO 操作。默认值是 1。\nworker_connections:这个值表示每一个工作进程可以同时处理连接的最大数目。默认是 512，但是大多数系统可以处理一个大得多的数字。这个值应该被设置成多少依赖与服务器的大小和网络流量的特征。通过具体的测试可以找到具体的值。\n连接持久化(Keepalives) 连接持久化可以在创建和关闭连接过程中降低 CPU 和网络开销，从而可对性能产生较大的影响。Nginx 会终止所有客户端连接以及和客户端连接分离开且独立的后端服务器连接。Nginx 支持客户端连接和后端服务器连接的持久化，可以通过下面的指令设置客户端连接持久化：\nkeepalive_requests:一个客户端使用一个持久化连接发送的请求数，默认值是 100. 这个值可以设置得很大，尤其在在做压力测试过程中，单一客户端发送大量请求得情况下会特别有用。\nkeepalive_timeout: 连接一旦空闲后还会保持多长时间（也就是空闲多长时间以后被关闭）。\n下面的指令可以设置后端服务器连接的持久化：\nkeepalive: 为每一个工作进程开启的到后端服务器空闲持久化连接的数量。这个指令没有默认值。 为了启用 Nginx 到后端服务器的持久化连接，需要添加一下指令：\nproxy_http_version 1.1; proxy_set_header Connection \u0026ldquo;\u0026rdquo;; 访问日志 记录每个请求的访问日志会占用 CPU 和 I/O 周期，启用访问日志缓冲可以减小影响。启动访问日志缓冲会使得 Nginx 缓存一些列日志记录到缓存中，然后在同一时间将他们写到文件中，而不是分开的执行每一个写操作。启用访问日志缓存功能需要在 Nginx 配置文件的 access_log 指令中使用 \u0026ldquo;buffer=size\u0026rdquo; 选项。这个是设置将要使用的缓存大小。也可以设置 \u0026ldquo;flush=time\u0026rdquo; 选项来告诉 Nginx 多长时间来将缓存中的记录写到磁盘日志文件中。如果配置了这两个选项，那当日志放不进缓存（缓存满了）或者缓存中日志记录比 flush 参数设置的时间还要老时，Nginx 将会写日志记录到日志文件中。当工作进程重新打开日志文件或者工作进程被关闭时，日志记录都会被写到日志文件中。当然，完全关闭访问日志也是可以的。\nSendfile Sendfile 是一个可以在 Nginx 中使用的操作系统的特性。这个特性可以使 TCP 数据传输得更快：它通过在内核中从一个文件描述符拷贝数据到另一个文件描述符，通常可以达到零拷贝。 Nginx 可以利用它通过 socket 发送缓存的或者磁盘上的内容，并且不需要任何的用户空间的上下文切换，从而使得发送数据的过程非常的快并且使用更少的 CPU 开销。由于数据从不触及用户空间，在处理链中添加需要访问数据的过滤器是行不通的，所以无法使用任何会改变数据内容的 Nginx 过滤器，例如 gzip 过滤器。Sendfile 默认是不启用的。\n限制(Limits) Nginx 和 Nginx Plus 允许设置一些列的限制项，可用于控制被客户端访问的资源，所以这些设置项会对系统性能产生影响，并且也会影响用户体验和安全。下面是其中的一些指令：\nlimit_conn/limit_conn_zone:这两个指令可用于限制 Nginx 允许的连接数目，例如限制单一的客户端 IP 地址。可以阻止单个客户端建立过多连接消耗过多资源的情况发生。\nlimit_rate: 限制一个客户端单个连接的带宽大小。可以防止由特定的客户端造成系统高负载的情况发生，从而保证所有客户端都可以获得好质量的服务。\nlimit_req/limit_req_zone: 这两个指令可以限制被 Nginx 处理的请求速率。和 limit_rate 一起使用 可以防止由特性的客户端造成系统高负载情况的发生，从而保证所有客户端都可以获得好质量的服务。这些指令可以用于改善系统安全，尤其是在登录页面，可以通过设置限制请求速率值，这个值完全胜任一个人类用户但又回减慢程序用户访问来提高系统的安全。（大概意思就是通过这个设置来限制机器程序的访问, 如爬虫）\nmax_conns: 设置允许同时连接到后端服务器组中一台服务器的最大连接数。这个设置可以防止后端服务器过载。默认值是 0， 表示无限制。\nqueue: 如果设置了 max_conns, 并且当一个请求由于没有可用的后端服务器或者后端服务器已到达 max_conns 上限而不能被处理时，此时发生什么就会交给 queue 指令来管理。这个指令设置存放到队列中请求数以及请求等待超时时间。如果这个指令没有设置，请求将不会出现排队的情形。\n附加配置 值得一提的是，Nginx 有一些附加的特性可以用来提高 Web 应用的性能，尽管他们不是真的属于调优的范畴，但对性能的影响也是显著的。下面将讨论其中的两个特性。\n缓存 有一个用于负载均衡一组后端 Web 应用的 Nginx 实例，通过启用这个实例的缓存配置，将会显著的增加到客户端的响应时间，同时也会显著的降低后端服务器的负载。缓存本身就是一个主题，这里不再详细讨论。需要了解更多的关于配置 Nginx 缓存的信息，可以参考 Nginx 管理指南 - 缓存篇\n压缩 压缩返回给客户端的数据可以大大减小返回数据的大小，从而需求更少的带宽，但压缩的操作需要占用 CPU 资源。所以在减少带宽有价值时使用压缩才是最好的。值得注意的还有不要压缩已经压缩过的对象， 譬如 jpeg 图片等。需要了解更多的关于配置 Nginx 压缩的信息，可以参考Nginx 管理指南 - 压缩篇\n更多阅读 Nginx 性能测试 Nginx 文档 Nginx 和 Nginx Plus 特性 Nginx Plus 技术规范 ","permalink":"https://lewang.dev/posts/2014-10-16-tuning-nginx/","summary":"这是一篇译文，原文链接：Tuning NGINX for Performance\nNginx 为人熟知的是在负载均衡、静态缓存和 WEB 服务器等方面的高性能，目前世界上最繁忙的站点中大约有 40% 在使用 Nginx。绝大多数情况下，大多数默认的 Nginx 和 Linux 配置都可以工作得非常好，但也需要做一些优化以获得最好的性能。本文将讨论在优化系统时需要考虑的 Nginx 和 Linux 的部分配置。可配置的选项有很多，但是本文只涵盖推荐大多数用户调整的配置选项。本文没有涵盖的配置选项，只有那些对 Nginx 和 Linux 有了深入的理解的人或者获得了 Nginx 技术支持和专业的服务团队的推荐建议后，才可以考虑调整。Nginx 专业服务器团队已经为世界上一些最繁忙的站点通过优化 Nginx 获得了最高水平的性能，并且可以为任何需要获得自己系统最大产出的客户服务。\n简介 本文假设读者对 Nginx 架构和配置的概念已有了基本的了解。Nginx 的文档内容将不会在本文中重复，但本文会提供各项配置简要的介绍和相关文档的链接。\n在性能调优时，要遵循一个好的规则：一次只修改一个配置选项，如果这个修改没有在性能方面带来优化，那么要再改回默认值。\n我们从 Linux 性能优化的讨论开始，因为 Linux 性能优化的一些值会影响到 Nginx 的一些配置。\nLinux 配置 尽管现代 Linux 内核（2.6+）在各种配置情况下都工作得很好，但也有一些配置是想要修改的。如果操作系统的配置设置的太低，那内核日志将会有错误信息，从而得知哪些配置需要调整。Linux 性能优化可能涉及的配置有很多，这里我们只讨论那些优化达到正常工作负载最有可能涉及到的那些配置。调整这些配置请参考详细的 Linux 文档。\nBacklog 队列 下面的配置选项与网络连接和其排队方法直接相关。如果连入率很高（译者注：客户端发起的连接很多）且系统性能配置不匹配，例如一些连接表现得有所停顿，那么修改下面得配置将可能有用。\nnet.core.somaxconn: 设置等待 Nginx 接受的连接队列的大小。由于 Nginx 接受连接非常的快，这个值通常情况下不用设置得很大，但系统默认值可能比较小，所以对于流量比较大的站点，增大这个值是个不错的想法。如果这个值太小，在内核日志中应该会看到错误消息，那么就需要增大这个值，直到错误消失。注意：若将这个值设置为大于 512 的话，那么需要在 Nginx 配置中修改 listen 指令的 backlog 参数来匹配这个数字。\nnet.core.netdev_max_backlog: 设置数据包在被发送到 CPU 前可被网卡缓存的速率。对于带宽很大的机器来说，这个值需要增大。可以查阅网卡关于这项设置的建议文档或者查看内核日志中此项设置相关的错误。","title":"Nginx 性能调优「译」"},{"content":"这几天每次 Push 博客到 Github Pages 时总会收到一封邮件：\nThe page build completed successfully, but returned the following warning:\nGitHub Pages recently underwent some improvements (https://github.com/blog/1715-faster-more-awesome-github-pages) to make your site faster and more awesome, but we\u0026rsquo;ve noticed that iforget.info isn\u0026rsquo;t properly configured to take advantage of these new features. While your site will continue to work just fine, updating your domain\u0026rsquo;s configuration offers some additional speed and performance benefits. Instructions on updating your site\u0026rsquo;s IP address can be found at https://help.github.com/articles/setting-up-a-custom-domain-with-github-pages#step-2-configure-dns-records, and of course, you can always get in touch with a human at support@github.com. For the more technical minded folks who want to skip the help docs: your site\u0026rsquo;s DNS records are pointed to a deprecated IP address.\nFor information on troubleshooting Jekyll see:\nhttps://help.github.com/articles/using-jekyll-with-pages#troubleshooting\nIf you have any questions please contact us at https://github.com/contact.\n大概意思就是我们 Github Pages 服务最近做了升级，这个升级将会使你的博客访问起来快到碉堡了，赶快来配置(修改域名记录就可以)一下用上吧。\n之前 iforget.info 这个域名有两条记录：\nA 记录： iforget.info 到 207.97.227.245\nCNAME(Alias) 记录：www.iforget.info 到 iforget.info\n207.97.227.245 是个美帝的 IP，所以速度比较慢。我还想着给 iforget.info 备个案，从此用上七牛的 CND 来加速了。好消息来了，Github Pages 支持全球 CDN 了，赶紧修改一下 DNS 记录(把之前的记录都删掉吧)：\nCNAME 记录: iforget.info 到 thisiswangle.github.io\nCNAME 记录: www.iforget.info 到 thisiswangle.github.io\n好了，静候 DNS 生效。\n➜ ~ dig iforget.info +nostats +nocomments +nocmd ; \u0026lt;\u0026lt;\u0026gt;\u0026gt; DiG 9.8.3-P1 \u0026lt;\u0026lt;\u0026gt;\u0026gt; iforget.info +nostats +nocomments +nocmd ;; global options: +cmd ;iforget.info. IN A iforget.info. 30 IN CNAME thisiswangle.github.io. thisiswangle.github.io. 1976 IN CNAME github.map.fastly.net. github.map.fastly.net. 30 IN A 103.245.222.133 fastly.net. 73096 IN NS ns3.p04.dynect.net. fastly.net. 73096 IN NS ns4.p04.dynect.net. fastly.net. 73096 IN NS ns2.p04.dynect.net. fastly.net. 73096 IN NS ns1.p04.dynect.net. ns1.p04.dynect.net. 74973 IN A 208.78.70.4 ns2.p04.dynect.net. 74756 IN A 204.13.250.4 ns3.p04.dynect.net. 74789 IN A 208.78.71.4 ns4.p04.dynect.net. 153 IN A 204.13.251.4 IP 变成了 103.245.222.133, 澳大利亚 IP ，进入亚洲组了。\n当同时设置了 iforget.info 和 www.iforget.info, 再添加一个 CNAME 文件到自己的博客根目录下。\n如果 CNAME 的内容是\niforget.info\n浏览器中输入 www.iforget.info 时，Github Pages 将会永久跳转(301)到 iforget.info, 反之亦然。\n如果你能看到本页，说明本站已经拿到了 GFW 认证。\n","permalink":"https://lewang.dev/posts/2014-05-06-github-pages-dns-settings/","summary":"这几天每次 Push 博客到 Github Pages 时总会收到一封邮件：\nThe page build completed successfully, but returned the following warning:\nGitHub Pages recently underwent some improvements (https://github.com/blog/1715-faster-more-awesome-github-pages) to make your site faster and more awesome, but we\u0026rsquo;ve noticed that iforget.info isn\u0026rsquo;t properly configured to take advantage of these new features. While your site will continue to work just fine, updating your domain\u0026rsquo;s configuration offers some additional speed and performance benefits. Instructions on updating your site\u0026rsquo;s IP address can be found at https://help.","title":"Github Pages 服务的域名设置"},{"content":"“悟性”是一个很虚的东西吗？\n前段时间和同学聊天，聊如何从众多的各方面初步看起来差不多应聘者中去做选择？聊来聊去最终落到了“悟性”上。我自己在突然想到悟性这个词的时候脑子几乎一片空白，不知道如何去判断一个人的悟性，或者说悟性到底是怎么样的，凭什么说一个人悟性好或者悟性差。\n昨天下午有个年龄不小的同学过来面试，聊了一个小时以后，向老板 汇报面试意见时，这同学各方面都很不错，但是总觉得有些地方不对，找不到词来形容自己内心当时的想法，于是结结巴巴的说，这种情况下，我要看一个人有没有悟性，接着我举了一个例子来说明什么时悟性：\n假如一个人，被安排了事情 A，我觉得有悟性的人，可能在做 A 事情的时候，把相关的事情 B、C 都做了，或者要求时做到A，但是主动把结果做成 A++\n说完后，我觉得不妥：这可能不是一个人有没有悟性的问题，而是这个人主动不主动、有没有热情的问题。\n到底什么怎样才能通过一些具体的例子体会悟性这个词的含义？\n佛家讲究悟性。《心经》仅有 260 个字，有悟性的人才可以写出《心经与生活智慧》，甚至心经和量子物理都有关系，你看了之后，才发现：哦，原来心经是说这些的啊。\n道家也讲究悟性。当年菩提老祖在孙猴子头上敲三下的时候，要是孙猴子没有悟性只有兽性的话，估计就没有后面的孙悟空了。\n自己之前团队中有个新同事，年龄比我长，团队之间大家相互做 Code Review，且不说代码质量， 从代码风格上我就对此人无语了：从不注意已有代码在变量、函数、文件命名上的一些基本的规范，别人不告诉他，就不会意识到这个问题。一些看得见的东西不一定非要教条式的写到文件里，然后去专门花时间去学,去强制。有些问题，还是自己意识到比较好，从别人口里说出来，那就不好玩了。\n一句话说得好：\n不怕狼一样的对手，就怕猪一样的队友。\n不多说了，不强求，悟性有可能就是天生的。做不了大师兄，做二师弟也不赖。\n","permalink":"https://lewang.dev/posts/2014-04-26-power-of-understanding/","summary":"“悟性”是一个很虚的东西吗？\n前段时间和同学聊天，聊如何从众多的各方面初步看起来差不多应聘者中去做选择？聊来聊去最终落到了“悟性”上。我自己在突然想到悟性这个词的时候脑子几乎一片空白，不知道如何去判断一个人的悟性，或者说悟性到底是怎么样的，凭什么说一个人悟性好或者悟性差。\n昨天下午有个年龄不小的同学过来面试，聊了一个小时以后，向老板 汇报面试意见时，这同学各方面都很不错，但是总觉得有些地方不对，找不到词来形容自己内心当时的想法，于是结结巴巴的说，这种情况下，我要看一个人有没有悟性，接着我举了一个例子来说明什么时悟性：\n假如一个人，被安排了事情 A，我觉得有悟性的人，可能在做 A 事情的时候，把相关的事情 B、C 都做了，或者要求时做到A，但是主动把结果做成 A++\n说完后，我觉得不妥：这可能不是一个人有没有悟性的问题，而是这个人主动不主动、有没有热情的问题。\n到底什么怎样才能通过一些具体的例子体会悟性这个词的含义？\n佛家讲究悟性。《心经》仅有 260 个字，有悟性的人才可以写出《心经与生活智慧》，甚至心经和量子物理都有关系，你看了之后，才发现：哦，原来心经是说这些的啊。\n道家也讲究悟性。当年菩提老祖在孙猴子头上敲三下的时候，要是孙猴子没有悟性只有兽性的话，估计就没有后面的孙悟空了。\n自己之前团队中有个新同事，年龄比我长，团队之间大家相互做 Code Review，且不说代码质量， 从代码风格上我就对此人无语了：从不注意已有代码在变量、函数、文件命名上的一些基本的规范，别人不告诉他，就不会意识到这个问题。一些看得见的东西不一定非要教条式的写到文件里，然后去专门花时间去学,去强制。有些问题，还是自己意识到比较好，从别人口里说出来，那就不好玩了。\n一句话说得好：\n不怕狼一样的对手，就怕猪一样的队友。\n不多说了，不强求，悟性有可能就是天生的。做不了大师兄，做二师弟也不赖。","title":"悟性"},{"content":" 成长就是看自己以前写的东西（包括微博、博客、说说等等）的时候觉得以前自己很 SB, 然后迫切地想把它们删掉\n这句话不止一次看到，反思自己，确实是那么回事儿，不能太赞同哦（我了个去上海腔了呢）。\n先前早些时候，把新浪博客和人人删的一干二净，也就是过把自己过去的所有文字的创造付之一炬，说没有一点惋惜，那是不可能的，想想当年自己顶着农村小孩黝黑皮肤初来乍到大城市，牛流不分，不怕喝不上牛奶只能喝豆浆的尴尬，给学校里各个杂志投稿，现在读来那些稿件，莫不觉得自己二逼。还好是些低年级学生玩的校办杂志，没多少人，为了回忆二逼的岁月，我特地还留了一本，没有其他人变态一样也留了一本吧。\n哦，对了，如果你想删掉所有的 SNS 平台的日志，不如学门编程的手艺，使用他们所谓的开放接口删了他们。不知道人人网的 3g.renren.com, 如果还能访问那可以试试小码哥几年前弄的人人自杀小工具 xiaomg.sinaapp.com，如果恰好能帮你删掉所有的东西，那么就是人人网的不对了，这么多年了，一点进步都没有，还有几个人在山寨机上开个ucweb访问你的3g网站。小工具的代码就不要看了，惨不忍闻，套用前面的话，写得太二逼了。说不定哪天就会被删掉，就像删这些日志一样。\n感性的文字都已经被删掉了，这下子没人看的得到我过去的无知，也只有我自己知道自己过去的无畏。\n准备把散落在各处的技术博文都挪到这里来，二逼 SB 可能不大适合形容一个人的手艺，但是菜鸟二字恰如其分。\n又一个菜鸟来了。大牛们见笑了。\n","permalink":"https://lewang.dev/posts/2014-04-25-grow-up/","summary":"成长就是看自己以前写的东西（包括微博、博客、说说等等）的时候觉得以前自己很 SB, 然后迫切地想把它们删掉\n这句话不止一次看到，反思自己，确实是那么回事儿，不能太赞同哦（我了个去上海腔了呢）。\n先前早些时候，把新浪博客和人人删的一干二净，也就是过把自己过去的所有文字的创造付之一炬，说没有一点惋惜，那是不可能的，想想当年自己顶着农村小孩黝黑皮肤初来乍到大城市，牛流不分，不怕喝不上牛奶只能喝豆浆的尴尬，给学校里各个杂志投稿，现在读来那些稿件，莫不觉得自己二逼。还好是些低年级学生玩的校办杂志，没多少人，为了回忆二逼的岁月，我特地还留了一本，没有其他人变态一样也留了一本吧。\n哦，对了，如果你想删掉所有的 SNS 平台的日志，不如学门编程的手艺，使用他们所谓的开放接口删了他们。不知道人人网的 3g.renren.com, 如果还能访问那可以试试小码哥几年前弄的人人自杀小工具 xiaomg.sinaapp.com，如果恰好能帮你删掉所有的东西，那么就是人人网的不对了，这么多年了，一点进步都没有，还有几个人在山寨机上开个ucweb访问你的3g网站。小工具的代码就不要看了，惨不忍闻，套用前面的话，写得太二逼了。说不定哪天就会被删掉，就像删这些日志一样。\n感性的文字都已经被删掉了，这下子没人看的得到我过去的无知，也只有我自己知道自己过去的无畏。\n准备把散落在各处的技术博文都挪到这里来，二逼 SB 可能不大适合形容一个人的手艺，但是菜鸟二字恰如其分。\n又一个菜鸟来了。大牛们见笑了。","title":"成长"},{"content":" 这张照片很多人应该都见过，名副其实的二十世纪最伟大科学家们的合影。爱因斯坦占据了最明显的位置，德布罗意也在其中。\n这里是摘自百度百科的一些内容：\n在光具有波粒二象性的启发下，法国物理学家德布罗意（1892～1987）在 1924 年提出一个假说，指出波粒二象性不只是光子才有，一切微观粒子，包括电子和质子、中子，都有波粒二象性。他把光子的动量与波长的关系式 p=h/λ 推广到一切微观粒子上，指出：具有质量 m 和速度 v 的运动粒子也具有波动性，这种波的波长等于普朗克恒量 h 跟粒子动量 mv 的比，即 λ=h/(mv)。这个关系式后来就叫做德布罗意公式。\n从德布罗意公式很容易算出运动粒子的波长。\n例如，电子的电荷是 1.6×10^-19 库，质量是 0.91×10^-30 千克，经过 200 伏电势差加速的电子获得的能量 E=Ue=200×1.6×10-19 焦 =3.2×10-17 焦。这个能量就是电子的动能，即0.5mv^2=3.2×10^-17 焦，因此 v=8.3910^6 米/秒。于是，按照德布罗意公式这运动电子的波长是 λ=h/(mv)=6.6310^-34/(9.110^-318.39*10^6)=8.7×10-11 米，或者 0.87 埃。\n我们看到，这个波长与伦琴射线的波长相仿。前面讲过，这样短的波长，只有用晶体做衍射光栅才能观察到衍射现象。后来人们的确用这种办法观察到了电子的衍射，从而证明了德布罗意假说的正确性。\n是不是有点印象了，这就是高中物理课本里面的内容吧。\n前几天和公司几个童鞋一起吃饭，先是有人说《水知道答案》，且先不说它是不是伪科普，我们试图用一些我们想得到的知识来说明一些问题，于是我想到了物质波，也就是德布罗意波。让我惊愕的是，那三位同学一致表示他们完全不知道什么是德布罗意波，搞得我仿佛穿越了，穿越到阿西莫夫的基地里去了。\n一定是在耍我。\n如果德布罗意波都不知道，那肯定也错过了德布罗意本人和他那篇博士论文的八卦故事了。不多说了，还是偷着乐吧。\n哈哈\n","permalink":"https://lewang.dev/posts/2014-03-13-who-is-de-broglie/","summary":"这张照片很多人应该都见过，名副其实的二十世纪最伟大科学家们的合影。爱因斯坦占据了最明显的位置，德布罗意也在其中。\n这里是摘自百度百科的一些内容：\n在光具有波粒二象性的启发下，法国物理学家德布罗意（1892～1987）在 1924 年提出一个假说，指出波粒二象性不只是光子才有，一切微观粒子，包括电子和质子、中子，都有波粒二象性。他把光子的动量与波长的关系式 p=h/λ 推广到一切微观粒子上，指出：具有质量 m 和速度 v 的运动粒子也具有波动性，这种波的波长等于普朗克恒量 h 跟粒子动量 mv 的比，即 λ=h/(mv)。这个关系式后来就叫做德布罗意公式。\n从德布罗意公式很容易算出运动粒子的波长。\n例如，电子的电荷是 1.6×10^-19 库，质量是 0.91×10^-30 千克，经过 200 伏电势差加速的电子获得的能量 E=Ue=200×1.6×10-19 焦 =3.2×10-17 焦。这个能量就是电子的动能，即0.5mv^2=3.2×10^-17 焦，因此 v=8.3910^6 米/秒。于是，按照德布罗意公式这运动电子的波长是 λ=h/(mv)=6.6310^-34/(9.110^-318.39*10^6)=8.7×10-11 米，或者 0.87 埃。\n我们看到，这个波长与伦琴射线的波长相仿。前面讲过，这样短的波长，只有用晶体做衍射光栅才能观察到衍射现象。后来人们的确用这种办法观察到了电子的衍射，从而证明了德布罗意假说的正确性。\n是不是有点印象了，这就是高中物理课本里面的内容吧。\n前几天和公司几个童鞋一起吃饭，先是有人说《水知道答案》，且先不说它是不是伪科普，我们试图用一些我们想得到的知识来说明一些问题，于是我想到了物质波，也就是德布罗意波。让我惊愕的是，那三位同学一致表示他们完全不知道什么是德布罗意波，搞得我仿佛穿越了，穿越到阿西莫夫的基地里去了。\n一定是在耍我。\n如果德布罗意波都不知道，那肯定也错过了德布罗意本人和他那篇博士论文的八卦故事了。不多说了，还是偷着乐吧。\n哈哈","title":"谁是德布罗意"},{"content":"为了自己做好网站的架构，找了知乎，豆瓣，大众点评和百姓网来做参考。这里主要来看域名和 CDN 相关的部分，后台的架构也还是要边学便实践。\n大概情况 从前端分析了知乎的域名和 DNS 情况，同时对比了一下豆瓣、大众点评和百姓网。从域名、DNS、CDN 等使用角度来说，他们之间大同小异。\n使用的分析工具 Chrome WHOIS DNSLookup 非 CDN 使用 记录 域名 用途 路径 A zhihu.com 使用 301 跳转到 www.zhuhu.com IP A zhi.hu 使用 302 跳转到 www.zhihu.com IP A www.zhihu.com IP A comet.zhihu.com WebSocket 推送消息 IP A analytics.zhihu.com 知乎自己的统计分析，同时使用了 Google Analytics IP 大部分都是用了 301 或者 302 跳转，注意他们的区别：301 是永久跳转(浏览器会做客户端端缓存)，而 302 是临时跳转。此外 baidu.com 到 www.baidu.com 并不是使用 301 或者 302 ，而是使用下面的一段 HTML 代码\n\u0026lt;html\u0026gt; \u0026lt;meta http-equiv=\u0026#34;refresh\u0026#34; content=\u0026#34;0;url=http://www.baidu.com/\u0026#34; /\u0026gt; \u0026lt;/html\u0026gt; 相比而言，我觉得使用 301 更 Geek，更好一些。\nCDN 使用 记录 域名 用途 路径 CNAME static.analytics.zhihu.com CDN, 看 CNAME 以为是七牛 CDN，其实用了 ChinaNetCenter 的 CDN d.qiniudn.com \u0026gt; wsall.36tr.com.wscdns.com \u0026gt; 08911.xdwscache.glb0.lxdns.com \u0026gt; IP CNAME static.zhihu.com 网页资源文件 cdn，包括 css，js，image，不包括用户头像、用户发布的图片等 同上 CNAME p1.zhimg.com 用户头像，用户发布的图片, 这里使用又拍云 CDN zhcdn-img.b0.aicdn.com \u0026gt; ctn.b9.aicdn.com \u0026gt; IP CNAME p2.zhimg.com 用户头像，用户发布的图片，这里使用了七牛 CDN zhimg0.qiniudn.com \u0026gt; 其它非七牛 CDN CNAME p3.zhimg.com 与 p1.zhimg.com 相同 CNAME p4.zhimg.com 与 p1.zhimg.com 相同 CNAME s1.zhimg.com 视频片段等 这里使用了七牛 CDN zhimg0.qiniudn.com \u0026gt; 其它非七牛 CDN CNAME s2.zhimg.com 这里使用了七牛 CDN zhimg0.qiniudn.com \u0026gt; 其它非七牛 CDN CNAME s3.zhimg.com 这里使用了七牛 CDN zhimg0.qiniudn.com \u0026gt; 其它非七牛 CDN CNAME s4.zhimg.com 这里使用了七牛 CDN zhimg0.qiniudn.com \u0026gt; 其它非七牛 CDN p1-p4， s1-s4 由知乎服务器端按照一定算法选择（有可能就是等概率随机）\n不得不有点疑问？为什么七牛 CDN 最后都直到别人的 CDN 服务器上去了，而又拍云全部是 A 记录到自己的服务器。又拍强调的自建机房就是这个意思？\n静态资源版本控制 方法 知乎 在文件名前添加类似 md5 的字符串，如 app.js, 发布版本为 f853b06af5428ff5f78f66e3d09397e2.app.js 百姓网 如 gallery.js 发布版本为 gallery.f07b79d6.js 豆瓣 将类似 md5 值放在路径中，如http://img3.douban.com/f/shire/55c9fe0e9ecb5725037e9839fc515504008dae74/js/ad.js 大众点评 和百姓网类似，如发布版本为 ga2.min.acd5dfe89e87135b4eef62dcf81ef849.js 由于 CDN 使用简单镜像＋缓存的功能，每一个缓存的文件有一定的时效性，而且基本都是静态文件，不支持 Query String （如 ?ver=201413），于是需要在源头控制将要被分发到 CDN 中文件的版本。最为简单的做法就是对开发人员透明，在发布项目的时候，通过计算文件的 hash 签名或者 md5 签名来做类 HTML 等文本代码的重构。\nDNS 选择 域名 DNS 服务商 zhihu.com DNSPOD 企业版 zhimg.com DNSPOD 免费版 baixing.com DNSPOD 企业版 baixing.net DNSPOD 企业版 dianping.com 自建 douban.com 自建 ","permalink":"https://lewang.dev/posts/2014-03-06-arch-of-website-domain-cdn/","summary":"为了自己做好网站的架构，找了知乎，豆瓣，大众点评和百姓网来做参考。这里主要来看域名和 CDN 相关的部分，后台的架构也还是要边学便实践。\n大概情况 从前端分析了知乎的域名和 DNS 情况，同时对比了一下豆瓣、大众点评和百姓网。从域名、DNS、CDN 等使用角度来说，他们之间大同小异。\n使用的分析工具 Chrome WHOIS DNSLookup 非 CDN 使用 记录 域名 用途 路径 A zhihu.com 使用 301 跳转到 www.zhuhu.com IP A zhi.hu 使用 302 跳转到 www.zhihu.com IP A www.zhihu.com IP A comet.zhihu.com WebSocket 推送消息 IP A analytics.zhihu.com 知乎自己的统计分析，同时使用了 Google Analytics IP 大部分都是用了 301 或者 302 跳转，注意他们的区别：301 是永久跳转(浏览器会做客户端端缓存)，而 302 是临时跳转。此外 baidu.com 到 www.baidu.com 并不是使用 301 或者 302 ，而是使用下面的一段 HTML 代码\n\u0026lt;html\u0026gt; \u0026lt;meta http-equiv=\u0026#34;refresh\u0026#34; content=\u0026#34;0;url=http://www.baidu.com/\u0026#34; /\u0026gt; \u0026lt;/html\u0026gt; 相比而言，我觉得使用 301 更 Geek，更好一些。","title":"从域名和 CDN 来看网站架构"},{"content":"Vagrant 是一个构建虚拟开发环境的利器，它使得在团队中很容易共享开发环境，有了它，不必每个人都搭建一个自己的开发环境了。在没有使用 vagrant 之前，我在 windows 中安装了 virtualbox，然后在 virtualbox 中安装了一个 ubuntu server。在 ubuntu 中安装了 mysql、jdk 等软件，并且设置了一个共享目录，以便于将工程代码直接共享给 ubuntu。在外部开发调试过程中（Java 项目），我需要在 virtualbox 中设置好几个端口映射，如 mysql，ssh 等等。这样在 cygwin 里面就可以通过 ssh 登录 ubuntu server 了，为了使得 ssh 登录不用每次设置密码，还需要手动生成公钥私钥。换机器了，这一切我又得重新配置。新同事来了，他也得像我这样重新配置一遍。有可能他还会有问题说：为什么按照你的说明，代码在我这里却无法运行呢？\n一切都从 Yining 告诉了我 vagrant 之后发生了变化，原来一切都这么简单。\n安装 VirtualBox Vagrant 其实是对 virtualbox 做了一层包装，它让使用 virtualbox 作为虚拟机更为简单。当然也可以使用 vmware，使用 vmware 那得找一个 license 了。\n好吧，去这里 下载 VirtualBox。我使用的是 4.3.8 for OSX\n安装 Vagrant 下载 vagrant\n添加虚拟机镜像到 Vagrant vagrant box add vdevenv ~/Workspace/vagrant/boxes/vdevenv-0.0.0.1.box vagrant 的干净的镜像可以在这里下载:\nUbuntu precise 32 VirtualBox Ubuntu precise 64 VirtualBox 更多镜像 在工作目录启动 Vagrant 进入自己的代码所在的目录，启动刚刚添加的虚拟机镜像\nvagrant init vdevenv vagrant up vagrant ssh # 登录到虚拟机 进入 /vagrant 目录，这里就是共享的目录，所有的代码都在这里。\nVagrant 设置 修改 Vagrantfile\n分享开发环境 vagrant package 执行之后在工作目录下面会生成一个*.bax 的文件，把这个文件拷给别人就可以了\n常用 Vagrant 命令 vagrant ssh vagrant status vagrant halt vagrant up ","permalink":"https://lewang.dev/posts/2014-03-03-building-devenv-by-vagrant/","summary":"Vagrant 是一个构建虚拟开发环境的利器，它使得在团队中很容易共享开发环境，有了它，不必每个人都搭建一个自己的开发环境了。在没有使用 vagrant 之前，我在 windows 中安装了 virtualbox，然后在 virtualbox 中安装了一个 ubuntu server。在 ubuntu 中安装了 mysql、jdk 等软件，并且设置了一个共享目录，以便于将工程代码直接共享给 ubuntu。在外部开发调试过程中（Java 项目），我需要在 virtualbox 中设置好几个端口映射，如 mysql，ssh 等等。这样在 cygwin 里面就可以通过 ssh 登录 ubuntu server 了，为了使得 ssh 登录不用每次设置密码，还需要手动生成公钥私钥。换机器了，这一切我又得重新配置。新同事来了，他也得像我这样重新配置一遍。有可能他还会有问题说：为什么按照你的说明，代码在我这里却无法运行呢？\n一切都从 Yining 告诉了我 vagrant 之后发生了变化，原来一切都这么简单。\n安装 VirtualBox Vagrant 其实是对 virtualbox 做了一层包装，它让使用 virtualbox 作为虚拟机更为简单。当然也可以使用 vmware，使用 vmware 那得找一个 license 了。\n好吧，去这里 下载 VirtualBox。我使用的是 4.3.8 for OSX\n安装 Vagrant 下载 vagrant\n添加虚拟机镜像到 Vagrant vagrant box add vdevenv ~/Workspace/vagrant/boxes/vdevenv-0.0.0.1.box vagrant 的干净的镜像可以在这里下载:\nUbuntu precise 32 VirtualBox Ubuntu precise 64 VirtualBox 更多镜像 在工作目录启动 Vagrant 进入自己的代码所在的目录，启动刚刚添加的虚拟机镜像","title":"使用 Vagrant 构建开发环境"},{"content":"前几天入手了一台 Macbook Pro Retina，把 BIG 提到了很爽的地步。经过几天的折腾，可以和 windows，ubuntu desktop 说 Byebye 了。之前整整用了一年的 Ubuntu 来工作，我用它来写 C、Java 和 Python, 要是 windows 没有 cygwin, 没有 MacType，那该多么恐怖。后来用了一段时间的 MBP，让我坚定了以后要自己买一个 MBP。\nubuntu 那么的惹人爱，因为它有个还挺好用的 GUI，从 debian 那继承过来的 apt-get, 一下子把一个从 redhat 9 用到 fedora 4 的穷学生拉到了 ubuntu 的阵营，至此，deskop 就被 ubuntu 占领了。在此之前，我还用段时间的 debian 和 gentoo。\n不得不说，debian 太伟大太牛逼了，有一次要在一个 MIPS 的小设备上编译安装 erlang， openssl，libcurl 等做一些实验, 要跨平台编译这些软件安装到小设备上去，费了半天终于把这些都编好了，还写了一个编译脚步，结果 erlang 运行的时候虚拟机总是报错，也不知道怎么回事。后来注意到 debian 居然有 MIPS，ARM 的源，后来在 MIPS 设备上安装软件做实验，我再也没有遇到问题，一切都用 apt-get 搞定了。\n除了 apt-get, 我想最令我惊喜还有 ubuntu 自带了 python 2.7，让我很容易在两台电脑之间拷贝文件：\npython -m SimpleHTTPServer 是不是很爽，rMBP 也带了 Python。不过传文件也不用 python 了，有更好用 Airdrop 可以用。\nrMBP 刚到手的时候，我创建了第一个目录是 Workspace，小四同学问我为啥第一个字母要大写，输入多不方便，我说我 home 目录下都是大写的，这样我 ls 会比较漂亮。\n其实我不想把我的系统变得很乱，我喜欢保持某些一致，让自己的心里觉得有点舒服。就像上学的时候，看到黑板上有点粉笔的字迹没有擦干净，就想伸手过去摸一下把它擦掉。\n我想，nodejs，ruby，python 的粉丝里不少都是这样的吧，不然怎么会有 nvm，rvm，virtualenv。\n如果你也在用 python，而且还经常在 github 上面拉别人的代码过来玩，或者安装一些 python lib, 我推荐你用 virtualenv:\nsudo easy_install pip sudo pip install virtualenv 接下来就可以在虚拟的环境里面随便折腾了，而且你的系统还会保持干干净净。\nvirtualenv venv 每次使用 venv 这个虚拟环境时都要记得激活它，所以可以 alias 到 .bash_profile 里面去。\n. venv/bin/activate 上面那个点(dot/period) 是 source 的代名词, 相当于\nsource venv/bin/activate 接下来通过 pip 安装的东西都会在这个虚拟环境中了，是不是很好玩。\nLove my rMBP, Love my python.\n","permalink":"https://lewang.dev/posts/2014-03-02-python-on-my-rmbp/","summary":"前几天入手了一台 Macbook Pro Retina，把 BIG 提到了很爽的地步。经过几天的折腾，可以和 windows，ubuntu desktop 说 Byebye 了。之前整整用了一年的 Ubuntu 来工作，我用它来写 C、Java 和 Python, 要是 windows 没有 cygwin, 没有 MacType，那该多么恐怖。后来用了一段时间的 MBP，让我坚定了以后要自己买一个 MBP。\nubuntu 那么的惹人爱，因为它有个还挺好用的 GUI，从 debian 那继承过来的 apt-get, 一下子把一个从 redhat 9 用到 fedora 4 的穷学生拉到了 ubuntu 的阵营，至此，deskop 就被 ubuntu 占领了。在此之前，我还用段时间的 debian 和 gentoo。\n不得不说，debian 太伟大太牛逼了，有一次要在一个 MIPS 的小设备上编译安装 erlang， openssl，libcurl 等做一些实验, 要跨平台编译这些软件安装到小设备上去，费了半天终于把这些都编好了，还写了一个编译脚步，结果 erlang 运行的时候虚拟机总是报错，也不知道怎么回事。后来注意到 debian 居然有 MIPS，ARM 的源，后来在 MIPS 设备上安装软件做实验，我再也没有遇到问题，一切都用 apt-get 搞定了。\n除了 apt-get, 我想最令我惊喜还有 ubuntu 自带了 python 2.7，让我很容易在两台电脑之间拷贝文件：","title":"Python on My rMBP"},{"content":"总体说明 我使用联通 10M 光网，SSH 在多个时间段登录两个主机都是非常的快，但是阿里云的 SSH 有时会断开连接，需要重新登录(一天遇到 n 次)，ucloud 一次都没有断开连接过。两者总体操作上都很流畅。平时我比较习惯于使用 ubuntu，于是在两个主机上都安装了 Ubuntu 12.04_64 的 Server 版本。在安装初始化系统过程中(测试过两次)，Ucloud 的速度要快于阿里云主机，粗略估计都是在 20s 以内，因此差别不大。\n阿里云主机安装过程中不需要人为参与，选好主机配置即可，主机一旦创建完成，用户名和口令会发送到测试者手机上，而且直接发送的是 root 账户口令。Ucloud 除了选择配置之外，还需要设置强登录密码，使用普通用户登录，感觉更 geek 一点。\n默认情况配置下，关闭重启服务器，Ucloud 会发送主机变化短信到手机，阿里云不会。阿里云在系统负载预警方面比较全面，ucloud 侧重于 server 上在线状态和相关服务的预警。\n在试用和测试过程中我主要偏向于静态的测试，后面还有一个好玩的 Super PI 测试。\n阿里云和 ucloud 都是主机，和实际的服务器使用上没有什么区别。另外阿里云有 paas，需要单独购买，目前支持 php 和 nodejs，一些基本的服务如 memcached 等都可直接使用。\n如果做互备，如果我们不使用这两个云平台各自特有的一些服务(主要是阿里云有一些如开放存储服务 OSS 等)，相互切换难度上应该是差不多的。\n主机概览 项目 阿里云 ucloud 按量付费 支持(不能升级或者调整主机配置*) 不支持 包年包月 支持 支持 操作系统 可重置 可重装 CPU 升级 支持(需要关机) 支持(需要关机) 内存升级 支持(需要关机) 支持(需要关机) 磁盘扩容 支持，可以升级或者添加新的磁盘，最大为 2000G 支持，可以扩容最大到 1000G（与系统盘在同一个主机上），\u0026lt;/br/\u0026gt;或者添加新的网络磁盘 udisk 磁盘镜像 支持 支持 带宽升级 支持 支持 其它服务[需要单独购买] 项目 阿里云 ucloud 负载均衡服务 支持(目前免费)，需要两台主机以上 支持(目前免费)，需要两台主机以上 关系型数据库服务 支持，mysql 和 sqlserver 支持，mysql 和 percona 特有的服务 开放存储服务 OSS、开放数据处理服务 ODPS、开放结构化数据服务 OTS CDN、短信服务（可二次开发）、与又拍、DNSPod 和搜狐 SendCloud 直接绑定 *按量付费不支持更换操作系统；不支持配置变更功能（包括带宽升级、CPU 和内存升级、新增数据盘）;“包年包月“和”按量付费“不支持相互更换;1 台云服务器只能选择 1 种，无法同时选择\n收费结构(参考) 项目 阿里云 ucloud 价格动态计算 http://buy.aliyun.com/ http://www.ucloud.cn/price 1 核 CPU/2GB 内存/100G 数据盘/10M 带宽 8,620 元/年 5,200 元/年 2 核 CPU/4GB 内存/100G 数据盘/10M 带宽 10,590 元/年 6,900 元/年 4 核 CPU/16GB 内存/1000G 数据盘/10M 带宽 24,030 元/年 19,800 元/年 4 核 CPU/16GB 内存/1000G 数据盘/20M 带宽 3,4030 元/年 24,900 元/年 2 核 CPU/4GB 内存/100G 数据盘/20M 带宽 20,590 元/年 11,400 元/年 4 核 CPU/8GB 内存/100G 数据盘/20M 带宽 24,530 元/年 14,800 元/年 …… …… …… 试用情况 项目 阿里云 ucloud 主机名 aliyun-s1 ucloud-s1 用户名 root ubuntu[默认普通用户权限] 登录口令 自动生成默认密码，弱密码 必须设置强密码 数据中心 华东青岛 BGP 北京 BGP(2M)，客服推荐使用北京 BGP，另外还有华东双线可选 CPU 2 核 Intel(R) Xeon(R) CPU E5-2420 0 @ 1.90GHz 2 核 QEMU Virtual CPU version (cpu64-rhel6) 内存 1.5GB 2GB 系统盘[ 免费] 20GB 20GB OS Ubuntu 12.04 64 位[只有 64 位]，支持 Centos(5.7,5.8,6.3)、Debian 6.06、Ubuntu 12.04, RHEL(5.4,5.7)、Windows(2003,2008r2)等 64 位版本 Ubuntu 12.04 64 位，比阿里云支持更多的 OS，并且都有 32 位版本可选 uptime 10:44:11 up 54 min, 1 user, load average: 0.00, 0.01, 0.04 10:44:11 up 54 min, 1 user, load average: 0.00, 0.01, 0.04 监控 默认没有发送短信 默认情况下会发送主机状态变化到注册者手机 ##监控和预警\n###站点可用性监控\n项目 阿里云 ucloud ping 支持 支持 端口或协议 支持，傻瓜式，预制好了一些常用的，如 HTTP 监控、TCP 端口监控、UDP 监控、DNS 监控、POP3 监控、SMTP 监控、FTP 监控 需要自己定义端口和监控策略 预警 短信或者邮件 短信或者邮件 ###服务器监控\n项目 阿里云 ucloud 内容 CPU 利用率监控、内存利用率监控、磁盘利用率监控、网络流量监控、进程状态监控、进程数量监控、进程 CPU 资源监控、进程内存资源监控、TCP 连接数监控、Swap 利用率监控、CPU 负载(load)监控、Filesystem 可用性监控、服务监控、日志监控 无，有数据视图，需要登录查看系统负载状态 ping 测试 测试工具 http://ping.chinaz.com/ 测试结果 阿里云(IP:115.28.3.138)\n线路 最快节点 响应 最慢节点 响应 平均响应 所有线路 上海[电信] 13 毫秒 德国[海外] 311 毫秒 73 毫秒 电信 上海[电信] 13 毫秒 香港[电信] 187 毫秒 62 毫秒 多线 上海[多线] 22 毫秒 北京[多线] 39 毫秒 30 毫秒 联通 北京[联通] 16 毫秒 泉州[联通] 65 毫秒 38 毫秒 移动 上海[移动] 22 毫秒 河北[移动] 68 毫秒 38 毫秒 海外 香港[海外] 46 毫秒 德国[海外] 311 毫秒 165 毫秒 ucloud(IP:42.62.56.129)\n线路 最快节点 响应 最慢节点 响应 平均响应 所有线路 北京[联通] 3 毫秒 德国[海外] 403 毫秒 64 毫秒 电信 陕西西安[电信] 21 毫秒 四川绵阳[电信] 53 毫秒 35 毫秒 多线 北京[多线] 4 毫秒 河南郑州[多线] 53 毫秒 28 毫秒 联通 北京[联通] 3 毫秒 深圳[联通] 73 毫秒 33 毫秒 移动 河北[移动] 26 毫秒 福建厦门[移动] 45 毫秒 35 毫秒 海外 韩国[海外] 49 毫秒 德国[海外] 403 毫秒 186 毫秒 经过多次 ping 测试，ucloud 要比阿里云快一些。这里使用的客服推荐的各自的 BGP 网络：阿里云华东青岛机房和 ucloud 北京 BGP 机房。\n下载测试 在各自主机上使用 wget 下载http://mirrors.163.com/ubuntu-releases/13.04/ubuntu-13.04-server-i386.iso\n项目 阿里云 ucloud 解析后 IP 123.58.173.106 123.58.173.106 平均速度 913K/s 5.41M/s ucloud 下载速度达到了 5.41M/s，可能它和网易的镜像比较近吧。好吧，那来测试一下 scp 吧。 在各自服务器上都 dd 一个 100M 文件出来，然后分别使用 scp 上传和下载。之后搭建一个 Niginx Server 来测试一下 HTTP。 新建的 20G 数据盘情况(tune2fs -l /dev/vdb |grep Block)\n项目 阿里云 ucloud Block Size 4096 4096 使用 dd 创建 2000M 文件，block 大小为 8K\ndd if=/dev/zero of=file_8k bs=8k count=250k 使用 dd 创建 2000M 文件，block 大小为 4K\ndd if=/dev/zero of=file_4k bs=4k count=500k 项目 阿里云 ucloud file_8k 79.3401 s, 26.4 MB/s 6.84755 s, 306 MB/s file_4k 77.6012 s, 27.0 MB/s 6.36673 s, 329 MB/s ucloud 数据盘是和系统盘在一起的，应该不是那种分布式存储，它的 udisk 估计和阿里云的数据盘比较类似，udisk 没有测。 使用 scp 主动拷贝文件\n项目 阿里云-\u0026gt;ucloud ucloud -\u0026gt;阿里云 file_8k 277.7KB/s 234.5KB/s file_4k 288.8KB/s 242.4KB/s 阿里云 ab 测试(n=1000, 4.1k 大小 html 文件)\n并发数 reqs/s 平均等待时间 平均处理时间 1 3751.57 0.267 ms 0.267 ms 10 8809.25 1.135 ms 0.114 ms 20 9596.84 2.084 ms 0.104 ms 50 9851.63 5.075 ms 0.102 ms 100 9382.89 10.658 ms 0.107 ms 150 8800.88 17.044 ms 0.114 ms 200 6666.13 30.002 ms 0.150 ms 500 3740.30 133.679 ms 0.267 ms ucloud ab 测试(n=1000, 4.1k 大小 html 文件)\n并发数 reqs/s 平均等待时间 平均处理时间 1 6135.53 0.163 ms 0.163 ms 10 10202.83 0.980 ms 0.098 ms 20 15624.27 1.280 ms 0.064 ms 50 16508.19 3.029 ms 0.061 ms 100 14707.14 6.799 ms 0.068 ms 150 14320.49 10.475 ms 0.070 ms 200 10312.57 19.394 ms 0.097 ms 500 3805.55 131.387 ms 0.263 ms UnixBench(分数越高越好) 项目 阿里云 ucloud running 1 copy of tests 731.3 1150.5 running 2 parallel copies of tests 1401.4 2310.9 分值上两个主机的差别还是很明显，从报告的细节上来看，磁盘 IO、CPU 等方面差别也很明显。\n","permalink":"https://lewang.dev/posts/2013-08-09-benchmark-of-aliyun-and-ucloud/","summary":"总体说明 我使用联通 10M 光网，SSH 在多个时间段登录两个主机都是非常的快，但是阿里云的 SSH 有时会断开连接，需要重新登录(一天遇到 n 次)，ucloud 一次都没有断开连接过。两者总体操作上都很流畅。平时我比较习惯于使用 ubuntu，于是在两个主机上都安装了 Ubuntu 12.04_64 的 Server 版本。在安装初始化系统过程中(测试过两次)，Ucloud 的速度要快于阿里云主机，粗略估计都是在 20s 以内，因此差别不大。\n阿里云主机安装过程中不需要人为参与，选好主机配置即可，主机一旦创建完成，用户名和口令会发送到测试者手机上，而且直接发送的是 root 账户口令。Ucloud 除了选择配置之外，还需要设置强登录密码，使用普通用户登录，感觉更 geek 一点。\n默认情况配置下，关闭重启服务器，Ucloud 会发送主机变化短信到手机，阿里云不会。阿里云在系统负载预警方面比较全面，ucloud 侧重于 server 上在线状态和相关服务的预警。\n在试用和测试过程中我主要偏向于静态的测试，后面还有一个好玩的 Super PI 测试。\n阿里云和 ucloud 都是主机，和实际的服务器使用上没有什么区别。另外阿里云有 paas，需要单独购买，目前支持 php 和 nodejs，一些基本的服务如 memcached 等都可直接使用。\n如果做互备，如果我们不使用这两个云平台各自特有的一些服务(主要是阿里云有一些如开放存储服务 OSS 等)，相互切换难度上应该是差不多的。\n主机概览 项目 阿里云 ucloud 按量付费 支持(不能升级或者调整主机配置*) 不支持 包年包月 支持 支持 操作系统 可重置 可重装 CPU 升级 支持(需要关机) 支持(需要关机) 内存升级 支持(需要关机) 支持(需要关机) 磁盘扩容 支持，可以升级或者添加新的磁盘，最大为 2000G 支持，可以扩容最大到 1000G（与系统盘在同一个主机上），\u0026lt;/br/\u0026gt;或者添加新的网络磁盘 udisk 磁盘镜像 支持 支持 带宽升级 支持 支持 其它服务[需要单独购买] 项目 阿里云 ucloud 负载均衡服务 支持(目前免费)，需要两台主机以上 支持(目前免费)，需要两台主机以上 关系型数据库服务 支持，mysql 和 sqlserver 支持，mysql 和 percona 特有的服务 开放存储服务 OSS、开放数据处理服务 ODPS、开放结构化数据服务 OTS CDN、短信服务（可二次开发）、与又拍、DNSPod 和搜狐 SendCloud 直接绑定 *按量付费不支持更换操作系统；不支持配置变更功能（包括带宽升级、CPU 和内存升级、新增数据盘）;“包年包月“和”按量付费“不支持相互更换;1 台云服务器只能选择 1 种，无法同时选择","title":"阿里云和 ucloud 云主机评测"},{"content":"相关的环境变量 LD_LIBRARY_PATH ld-linux.so 寻找 shared object 的路径，优先加载出现在路径前面的 shared object。如，export LD_LIBRARY_PATH=/home/user/lib:$LD_LIBRARY_PATH LD_PRELOAD 指定优先供 ld-linux.so 加载的 shared object。如，export LD_PRELAOD=/home/user/lib/glibc.so，可以使用这个变量来改变加载顺序，例如我们自定义的 glibc.so 中实现了新的 strcmp 之类的函数，那么可以使用这个变量来实现函数的替换，实现注入 LD_DEBUG 使用这个环境变量来 debug 载入 shared object 的情况。如，export LD_DEBUG=files,这样会打印所有所有加载 shared object 的记录 一些工具 如何查看一个程序或者 shared object 加载哪些 shared object ldd，可以查看程序或者.so，如，\n$ ldd ./foo_test $ ldd ./libfoo.so 对于已经运行的程序，可以这样 $ cat /proc/PID/maps | awk \u0026#39;{print $6}\u0026#39;| grep \u0026#39;\\.so\u0026#39;| sort | uniq $ lsof -p PID | awk \u0026#39;{print $9}\u0026#39; | grep \u0026#39;\\.so\u0026#39; 没有启动的程序可以这样 $ strace ./foo_test 2\u0026gt;\u0026amp;1 | grep \u0026#39;^open(\u0026#34;.*\\.so\u0026#39; 也可以用上面提到的环境变量来看 shared object 的加载顺序\n$ export LD_DEBUG=files $ ./foo_test 顺便介绍下 lsof 查看占用端口的进程\nle@SH:~$ sudo lsof -i TCP:80 COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME nginx 1309 root 7u IPv4 8740 0t0 TCP *:http (LISTEN) nginx 1310 www-data 7u IPv4 8740 0t0 TCP *:http (LISTEN) nginx 1311 www-data 7u IPv4 8740 0t0 TCP *:http (LISTEN) nginx 1312 www-data 7u IPv4 8740 0t0 TCP *:http (LISTEN) nginx 1313 www-data 7u IPv4 8740 0t0 TCP *:http (LISTEN) 具体的请man lsof\nobjdump 和 readelf objdump 查看 object 的信息 $ objdump -t libfoo.so $ objdump -s -j .rodata -t libfoo.so readelf 读 elf 的信息 readelf -r libfoo.so ","permalink":"https://lewang.dev/posts/2013-03-04-so-load-path-in-linux/","summary":"相关的环境变量 LD_LIBRARY_PATH ld-linux.so 寻找 shared object 的路径，优先加载出现在路径前面的 shared object。如，export LD_LIBRARY_PATH=/home/user/lib:$LD_LIBRARY_PATH LD_PRELOAD 指定优先供 ld-linux.so 加载的 shared object。如，export LD_PRELAOD=/home/user/lib/glibc.so，可以使用这个变量来改变加载顺序，例如我们自定义的 glibc.so 中实现了新的 strcmp 之类的函数，那么可以使用这个变量来实现函数的替换，实现注入 LD_DEBUG 使用这个环境变量来 debug 载入 shared object 的情况。如，export LD_DEBUG=files,这样会打印所有所有加载 shared object 的记录 一些工具 如何查看一个程序或者 shared object 加载哪些 shared object ldd，可以查看程序或者.so，如，\n$ ldd ./foo_test $ ldd ./libfoo.so 对于已经运行的程序，可以这样 $ cat /proc/PID/maps | awk \u0026#39;{print $6}\u0026#39;| grep \u0026#39;\\.so\u0026#39;| sort | uniq $ lsof -p PID | awk \u0026#39;{print $9}\u0026#39; | grep \u0026#39;\\.so\u0026#39; 没有启动的程序可以这样 $ strace .","title":"Linux 共享库（动态链接库）相关的一些记录"},{"content":"前一篇帖子使用了 xpath，后来了解到 xpath 的性能可能比较差，而且在遇到有命名空间的时候还有点小麻烦。这里都已豆瓣提供的 API 返回的 xml 为例。豆瓣返回的 xml 不是 rss 格式的，而是 Atom 格式，有很多的命名空间，如果习惯于操作 rss 格式的 xml，那么可以直接把 xml 里面的命名空间的字符串都 replace 掉，这个方法貌似很简单很暴力，就不会遇到命名空间的问题了。\n从豆瓣 API 开始，点击这个链接 http://api.douban.com/book/subjects?q=java 你就可以看到 xml 格式，由于返回的是 Atom 格式的 xml，浏览器会自动帮你解析，所以应该这样\n# 这样就可以得到一个java.xml文件。 $ wget -O java.xml http://api.douban.com/book/subjects?q=java 这样就可以得到一个 java.xml 文件，接下来使用 SimplePHP 处理这个文件。\n首先要创建一个 SimpleXML 对象\n//$content为xml的内容 $xml = new SimpleXMLElement($content); 现在要获取 opensearch 命名空间下的 totalResults 节点的文本，代码如下：\n$children = $xml-\u0026gt;children(\u0026#39;http://a9.com/-/spec/opensearchrss/1.0/\u0026#39;); $totalResults = $children-\u0026gt;totalResults; 处理所有 xml 文档中所有的 entry 节点\n//处理所有找到的记录 $entries = $xml-\u0026gt;entry; foreach($entries as $entry){ //取命名空间下的孩子节点 $entryChildren = $entry-\u0026gt;children(\u0026#39;http://www.douban.com/xmlns/\u0026#39;); //... } 好了，这里只是抛砖引玉，其它具体的操作还得参考 SimpleXML 的文档。\n","permalink":"https://lewang.dev/posts/2012-03-22-a-short-discuss-of-simplexml-of-php/","summary":"前一篇帖子使用了 xpath，后来了解到 xpath 的性能可能比较差，而且在遇到有命名空间的时候还有点小麻烦。这里都已豆瓣提供的 API 返回的 xml 为例。豆瓣返回的 xml 不是 rss 格式的，而是 Atom 格式，有很多的命名空间，如果习惯于操作 rss 格式的 xml，那么可以直接把 xml 里面的命名空间的字符串都 replace 掉，这个方法貌似很简单很暴力，就不会遇到命名空间的问题了。\n从豆瓣 API 开始，点击这个链接 http://api.douban.com/book/subjects?q=java 你就可以看到 xml 格式，由于返回的是 Atom 格式的 xml，浏览器会自动帮你解析，所以应该这样\n# 这样就可以得到一个java.xml文件。 $ wget -O java.xml http://api.douban.com/book/subjects?q=java 这样就可以得到一个 java.xml 文件，接下来使用 SimplePHP 处理这个文件。\n首先要创建一个 SimpleXML 对象\n//$content为xml的内容 $xml = new SimpleXMLElement($content); 现在要获取 opensearch 命名空间下的 totalResults 节点的文本，代码如下：\n$children = $xml-\u0026gt;children(\u0026#39;http://a9.com/-/spec/opensearchrss/1.0/\u0026#39;); $totalResults = $children-\u0026gt;totalResults; 处理所有 xml 文档中所有的 entry 节点\n//处理所有找到的记录 $entries = $xml-\u0026gt;entry; foreach($entries as $entry){ //取命名空间下的孩子节点 $entryChildren = $entry-\u0026gt;children(\u0026#39;http://www.","title":"再说 PHP 中 SimpleXML"},{"content":"这句话是 FACEBOOK 的马克·扎克伯格说的。\n我很认同，并且感觉自己也是这么做的。现在自己做得很多事情，从来没有考虑过它会不会值钱，只是感觉把自己的想法做出来，变成实物的过程就已经很酷。\n对于酷，我觉得至少有两方面的意义。\n一种酷，是一种自我实现的感觉，是一种认同感，成就感。比如自己把自己的不错的想法实现了，当自己看到自己作品的时候，肯定觉得这种感觉很酷。接着你的作品有很多人用了，看了，然后给与了肯定或者赞扬的评价，这时候感到酷，我觉得就应该是一种认同感和成就感。都是内心的感觉，一种推进自我完善的感觉。\n还有一种酷，那就是表面上的酷，比如你的网页效果做得很酷很炫，你实现的功能很酷。虽然这些是表面上的酷，但这些酷的背后却隐藏着无数的思考和磨练。这么表面上的酷，却恰恰可以给人带来内心上的酷。\n就拿摆摊网来说，小小的网站，做得很简单。但是为了实现页面小小的效果，还不得不去多学点东西多花些时间。我喜欢自己东西能弄得那种能给人至简至美的感觉，但是却不能因为简而不“美”了，这里的美是给人一种更好的感觉。所以自己总是在觉得不破坏简的前提下，尽量的让自己的应用让人使用的体验更好更酷。比如说发布书籍信息的页面，以前必须使用 ISBN 号，现在这里点击查看的将要改成 @林风琦 推荐的 chegg 的效果，是不是比豆瓣的书籍检索要酷很多。进一步思考，对于摆摊首页的检索，以后是不是应该结合用户的搜索习惯和本身的书籍物品数据也实现这种 AutoComplete 功能。还比如说摆摊还将开发 Android 手机客户端，到时候只要一拍，就可以把书信息扫下来了，看，多酷！\n现在自己的科研也是这样，能给自己带来一种很酷的感觉，但是就科研的实际应用来说，我觉得可以应用的范围很小。但是想着能把 Jim Gray 这位数据库大神[此大神已经被外星人带走了，详情看这里]负责的基于微软 SQL Server 的 SDSS 项目迁移到适合科学运算的数组模型的数据库上来，然后我们还有可能就性能 PK 一把，想想就觉得很酷。更酷的是，自己还想到了一种自动迁移的方法[还没有经过深思和验证]。反正就是觉得酷儿！\n为了更酷，继续努力！\n我是 A Lucky Apple，@小码哥\n","permalink":"https://lewang.dev/posts/2012-03-13-things-i-create-must-be-cool/","summary":"这句话是 FACEBOOK 的马克·扎克伯格说的。\n我很认同，并且感觉自己也是这么做的。现在自己做得很多事情，从来没有考虑过它会不会值钱，只是感觉把自己的想法做出来，变成实物的过程就已经很酷。\n对于酷，我觉得至少有两方面的意义。\n一种酷，是一种自我实现的感觉，是一种认同感，成就感。比如自己把自己的不错的想法实现了，当自己看到自己作品的时候，肯定觉得这种感觉很酷。接着你的作品有很多人用了，看了，然后给与了肯定或者赞扬的评价，这时候感到酷，我觉得就应该是一种认同感和成就感。都是内心的感觉，一种推进自我完善的感觉。\n还有一种酷，那就是表面上的酷，比如你的网页效果做得很酷很炫，你实现的功能很酷。虽然这些是表面上的酷，但这些酷的背后却隐藏着无数的思考和磨练。这么表面上的酷，却恰恰可以给人带来内心上的酷。\n就拿摆摊网来说，小小的网站，做得很简单。但是为了实现页面小小的效果，还不得不去多学点东西多花些时间。我喜欢自己东西能弄得那种能给人至简至美的感觉，但是却不能因为简而不“美”了，这里的美是给人一种更好的感觉。所以自己总是在觉得不破坏简的前提下，尽量的让自己的应用让人使用的体验更好更酷。比如说发布书籍信息的页面，以前必须使用 ISBN 号，现在这里点击查看的将要改成 @林风琦 推荐的 chegg 的效果，是不是比豆瓣的书籍检索要酷很多。进一步思考，对于摆摊首页的检索，以后是不是应该结合用户的搜索习惯和本身的书籍物品数据也实现这种 AutoComplete 功能。还比如说摆摊还将开发 Android 手机客户端，到时候只要一拍，就可以把书信息扫下来了，看，多酷！\n现在自己的科研也是这样，能给自己带来一种很酷的感觉，但是就科研的实际应用来说，我觉得可以应用的范围很小。但是想着能把 Jim Gray 这位数据库大神[此大神已经被外星人带走了，详情看这里]负责的基于微软 SQL Server 的 SDSS 项目迁移到适合科学运算的数组模型的数据库上来，然后我们还有可能就性能 PK 一把，想想就觉得很酷。更酷的是，自己还想到了一种自动迁移的方法[还没有经过深思和验证]。反正就是觉得酷儿！\n为了更酷，继续努力！\n我是 A Lucky Apple，@小码哥","title":"我想做的东西可以不值钱，但是它必须‘酷’"},{"content":"今天组会不用开了，报告也不用做了，感觉比较爽，于是晚上的时候决定给摆摊写一些新的东西。\n于是刚刚给摆摊的首页添加了一个小小的功能，就是能够随机的选取5本书在首页上循环展示，另外修正了一些网友提出的问题。\n首页图片轮换是用jquery实现的，做法也很简单，当然实现的功能和效果还是比较弱的，这里是我用到一些资料。 CSS定位：http://www.haozi.cn/code/position-static-relative-absolute-float/\n好了，摆摊这几天暂时就这个样子了，得放下心思继续去搞自己的科研了。\n过段时间一定要好好总结一下，写一些关于数组数据库系列的文章。\n","permalink":"https://lewang.dev/posts/2012-03-10-at-a-late-night/","summary":"今天组会不用开了，报告也不用做了，感觉比较爽，于是晚上的时候决定给摆摊写一些新的东西。\n于是刚刚给摆摊的首页添加了一个小小的功能，就是能够随机的选取5本书在首页上循环展示，另外修正了一些网友提出的问题。\n首页图片轮换是用jquery实现的，做法也很简单，当然实现的功能和效果还是比较弱的，这里是我用到一些资料。 CSS定位：http://www.haozi.cn/code/position-static-relative-absolute-float/\n好了，摆摊这几天暂时就这个样子了，得放下心思继续去搞自己的科研了。\n过段时间一定要好好总结一下，写一些关于数组数据库系列的文章。","title":"在这安静的夜里"},{"content":"我期待 2012 的到来，这一年我将有一个新的开始，好期待。\n最近一直在忙着做实验，读论文，都没有什么时间来弄弄摆摊，自己心里的那种对于摆摊的激情也渐渐淡了很多，但是想想自己当初的想法，立马又有动力拾起摆摊。\n一个小小的网站，看起来确实很简单，也就是拿 php 连连数据库，做做一些简单的操作，可自己在写这个网站的时候总是很慢。时间少而且比较凌乱是一个原因，但是总的还是缺少一个全面完善细致的规划，自己大部分也是照着当初的设计，然后想到哪儿做到哪儿，如今的摆摊，已经和当初的相去甚远了。越写越复杂，问题也越来越多，停下来一想，还是挥起大刀把乱乱的东西都砍了吧，弄得越简单越好。\n加油！过几天就要回家了，不知道什么时候才能做好，让自己心里舒服一下。这几天赶紧将域名绑定好，将人人、新浪微博等的接入做好，大概就这个样子了。\n大家新年快乐！\n","permalink":"https://lewang.dev/posts/2012-01-09-for-baigetan-2012/","summary":"我期待 2012 的到来，这一年我将有一个新的开始，好期待。\n最近一直在忙着做实验，读论文，都没有什么时间来弄弄摆摊，自己心里的那种对于摆摊的激情也渐渐淡了很多，但是想想自己当初的想法，立马又有动力拾起摆摊。\n一个小小的网站，看起来确实很简单，也就是拿 php 连连数据库，做做一些简单的操作，可自己在写这个网站的时候总是很慢。时间少而且比较凌乱是一个原因，但是总的还是缺少一个全面完善细致的规划，自己大部分也是照着当初的设计，然后想到哪儿做到哪儿，如今的摆摊，已经和当初的相去甚远了。越写越复杂，问题也越来越多，停下来一想，还是挥起大刀把乱乱的东西都砍了吧，弄得越简单越好。\n加油！过几天就要回家了，不知道什么时候才能做好，让自己心里舒服一下。这几天赶紧将域名绑定好，将人人、新浪微博等的接入做好，大概就这个样子了。\n大家新年快乐！","title":"写给 2012 的摆摊"},{"content":"这几天没心情看论文，于是开始写写摆摊网的代码。摆摊主要做高校二手书籍信息的分享，于是需要从豆瓣上获取图书信息，豆瓣提供了一个完整的 xml 来描述一本书，例如http://api.douban.com/book/subject/isbn/9787543639136，于是需要处理这个 xml 来获取相应信息，这里小码哥采用的是直接使用 xpath 来获取 xml 文档中相应的信息。摆摊使用了 sae，于是使用 SimpleXML 来处理 xml，加上自己还只是 PHP 的初学者，于是出现了一些问题。\n这里是一些学习资料：\nxpath:http://www.w3school.com.cn/xpath/ simplexml:http://cn2.php.net/manual/en/simplexmlelement.xpath.php 新建 SimpleXMLElement 对象，xml 文件内容在$content 中\n$bookFromDouban = new SimpleXMLElement($content); 直接查询，在命名空间 db 下的所有 attribute，且有 name 属性，以下 xpath 查询是没有问题的，\n$result = $bookFromDouban-\u0026gt;xpath(\u0026#34;//db:attribute[@name]\u0026#34;); 但是，这条查询就有问题了，如下，\n$result = $bookFromDouban-\u0026gt;xpath(\u0026#34;//link[@rel=\u0026#39;self\u0026#39;]|//link[@rel=\u0026#39;image\u0026#39;]\u0026#34;); 上面的代码表示在默认的命名空间里面查询 link 节点，但是在 php 5.0 以上却不能查出数据。需要这样操作\n//获取这个xml的所有的命名空间 $namespaces = $bookFromDouban-\u0026gt;getNamespaces(); //注册默认的命名空间为\u0026#39;d\u0026#39; $bookFromDouban-\u0026gt;registerXPathNamespace(\u0026#39;d\u0026#39;, $namespaces[\u0026#39;\u0026#39;]); //现在这个查询就ok了 $result = $bookFromDouban-\u0026gt;xpath(\u0026#34;//d:link[@rel=\u0026#39;self\u0026#39;]|//d:link[@rel=\u0026#39;image\u0026#39;]\u0026#34;); 对$result 遍历就简单了，这里也给出一个简单的例子，遍历完，变量就初始化了。PS：代码写的不优雅，欢迎拍砖。\ntranslator = array(); $author = array(); $i = $j = 0; foreach($result as $item) { foreach($item-\u0026gt;attributes() as $val) { $val = str_replace(\u0026#39;-\u0026#39;,\u0026#39;_\u0026#39;,$val); if($val == \u0026#39;author\u0026#39;) { $author[$i++] = \u0026#39;\u0026#39;.$item; } else if($val == \u0026#39;translator\u0026#39;) translator[$j++] = \u0026#39;\u0026#39;.$item; else $$val = $item; } } ","permalink":"https://lewang.dev/posts/2011-12-01-how-to-use-simplexml-of-php/","summary":"这几天没心情看论文，于是开始写写摆摊网的代码。摆摊主要做高校二手书籍信息的分享，于是需要从豆瓣上获取图书信息，豆瓣提供了一个完整的 xml 来描述一本书，例如http://api.douban.com/book/subject/isbn/9787543639136，于是需要处理这个 xml 来获取相应信息，这里小码哥采用的是直接使用 xpath 来获取 xml 文档中相应的信息。摆摊使用了 sae，于是使用 SimpleXML 来处理 xml，加上自己还只是 PHP 的初学者，于是出现了一些问题。\n这里是一些学习资料：\nxpath:http://www.w3school.com.cn/xpath/ simplexml:http://cn2.php.net/manual/en/simplexmlelement.xpath.php 新建 SimpleXMLElement 对象，xml 文件内容在$content 中\n$bookFromDouban = new SimpleXMLElement($content); 直接查询，在命名空间 db 下的所有 attribute，且有 name 属性，以下 xpath 查询是没有问题的，\n$result = $bookFromDouban-\u0026gt;xpath(\u0026#34;//db:attribute[@name]\u0026#34;); 但是，这条查询就有问题了，如下，\n$result = $bookFromDouban-\u0026gt;xpath(\u0026#34;//link[@rel=\u0026#39;self\u0026#39;]|//link[@rel=\u0026#39;image\u0026#39;]\u0026#34;); 上面的代码表示在默认的命名空间里面查询 link 节点，但是在 php 5.0 以上却不能查出数据。需要这样操作\n//获取这个xml的所有的命名空间 $namespaces = $bookFromDouban-\u0026gt;getNamespaces(); //注册默认的命名空间为\u0026#39;d\u0026#39; $bookFromDouban-\u0026gt;registerXPathNamespace(\u0026#39;d\u0026#39;, $namespaces[\u0026#39;\u0026#39;]); //现在这个查询就ok了 $result = $bookFromDouban-\u0026gt;xpath(\u0026#34;//d:link[@rel=\u0026#39;self\u0026#39;]|//d:link[@rel=\u0026#39;image\u0026#39;]\u0026#34;); 对$result 遍历就简单了，这里也给出一个简单的例子，遍历完，变量就初始化了。PS：代码写的不优雅，欢迎拍砖。\ntranslator = array(); $author = array(); $i = $j = 0; foreach($result as $item) { foreach($item-\u0026gt;attributes() as $val) { $val = str_replace(\u0026#39;-\u0026#39;,\u0026#39;_\u0026#39;,$val); if($val == \u0026#39;author\u0026#39;) { $author[$i++] = \u0026#39;\u0026#39;.","title":"SimpleXML使用xpath"},{"content":"最近在为摆摊写点前端 js 的时候，在使用 jquery 的 $.ajax()这个方法的时候，当 datatype 设置为 json 时，总是不执行 success 回调，而是执行 error 回调。而将 datatype 设置成 text，就可以执行 success 回调了，摆摊使用的是 jQuery JavaScript Library v1.6.2，查看 jQuery 文档可知：\n“json”: Evaluates the response as JSON and returns a JavaScript object. In jQuery 1.4 the JSON data is parsed in a strict manner; any malformed JSON is rejected and a parse error is thrown. (See json.org for more information on proper JSON formatting.)\n我用 php 产生的字符串是\n{‘isbn’:\u0026#39;ISBN号码格式不正确，应为10位或者13位的字符串’} 很明显，json.org 规则使用的是双引号，而不是单引号，jQuery1.4 以后都要求更为严格的 json 格式\n对于以上单引号的字符串，可以使用 datatype 为 text，然后使用\n//content = {‘isbn’:\u0026#39;ISBN号码格式不正确，应为10位或者13位的字符串’} var json = eval(‘(‘+ content +’)\u0026#39;) ","permalink":"https://lewang.dev/posts/2011-12-01-when-datatype-is-json/","summary":"最近在为摆摊写点前端 js 的时候，在使用 jquery 的 $.ajax()这个方法的时候，当 datatype 设置为 json 时，总是不执行 success 回调，而是执行 error 回调。而将 datatype 设置成 text，就可以执行 success 回调了，摆摊使用的是 jQuery JavaScript Library v1.6.2，查看 jQuery 文档可知：\n“json”: Evaluates the response as JSON and returns a JavaScript object. In jQuery 1.4 the JSON data is parsed in a strict manner; any malformed JSON is rejected and a parse error is thrown. (See json.org for more information on proper JSON formatting.)\n我用 php 产生的字符串是","title":"jquery $.ajax() 中 datatype 为 json 时的问题"},{"content":"未来是个未知数，自己的未来自己都不知道会是什么样子，问别人，别人又怎么会知道你的未来。\n不要忘了自己心中想要的东西，即使是为了养家糊口而从事自己不喜欢的工作，也不要忘记自己希望做什么，静静的准备着，迟早有一天会爆发的。\n单纯的做着自己的业余爱好，业余爱好也就会发展成职业的。但是我不会忘了我心中想要去做什么，我会为之而积累准备。\n未来是个未知数，没有方程组能解开这个未知数，只能去试，试试才会知道。\n摆摊网的未来也是个未知数，很大的可能就是被淹没在数以亿计的小小站点之中，被互联网大潮一扫而过，什么也不会留下，但是，这就是我的爱好，我喜欢把自己的想法实现，不管别人喜不喜欢用，但是，我喜欢摆摊网，它是我想法的一个实体，我每次尝试的一个印记。\n自己的工作也定下来了，有接着研究自己的课题，但这几天不能安静下来搞自己的课题，总想着摆摊网还没有做好，于是拿出了两天，把摆摊的页面都做了出来，接下来就要做网站的逻辑部分了。\n网站很简单，但是要做好做的精致做得完美做得好用也是很不容易的。自己还是慢慢来搞，每天写点代码吧，还是要干些要紧的事儿，后天又得做报告了，得赶论文ppt了。\n期待有同学加入，一起来开发摆摊网，让摆摊网早点上线！！！\n要开始为了毕业而忙碌了。\n我是小码哥（新浪微博）\n","permalink":"https://lewang.dev/posts/2011-11-09-future-is-unknown/","summary":"未来是个未知数，自己的未来自己都不知道会是什么样子，问别人，别人又怎么会知道你的未来。\n不要忘了自己心中想要的东西，即使是为了养家糊口而从事自己不喜欢的工作，也不要忘记自己希望做什么，静静的准备着，迟早有一天会爆发的。\n单纯的做着自己的业余爱好，业余爱好也就会发展成职业的。但是我不会忘了我心中想要去做什么，我会为之而积累准备。\n未来是个未知数，没有方程组能解开这个未知数，只能去试，试试才会知道。\n摆摊网的未来也是个未知数，很大的可能就是被淹没在数以亿计的小小站点之中，被互联网大潮一扫而过，什么也不会留下，但是，这就是我的爱好，我喜欢把自己的想法实现，不管别人喜不喜欢用，但是，我喜欢摆摊网，它是我想法的一个实体，我每次尝试的一个印记。\n自己的工作也定下来了，有接着研究自己的课题，但这几天不能安静下来搞自己的课题，总想着摆摊网还没有做好，于是拿出了两天，把摆摊的页面都做了出来，接下来就要做网站的逻辑部分了。\n网站很简单，但是要做好做的精致做得完美做得好用也是很不容易的。自己还是慢慢来搞，每天写点代码吧，还是要干些要紧的事儿，后天又得做报告了，得赶论文ppt了。\n期待有同学加入，一起来开发摆摊网，让摆摊网早点上线！！！\n要开始为了毕业而忙碌了。\n我是小码哥（新浪微博）","title":"未来是个未知数"},{"content":"今天是十一假期归来的第一天，实验室也启用了新的管理制度，坐在北洋楼的实验室也有一会儿了，刚发了一会儿呆，对摆摊又有了一些新的思考。\n我的目标是想把摆摊做成高校的网上交易平台，也就是类似淘宝，但是作为摆摊网的初期是不合适的，因为这个交易平台太大太复杂。\n所以摆摊的第一步还是做交易信息的发布和检索，主打高校的书籍和物品交易信息，交易还是线下完成，这样，初期的摆摊应该就和赶集、百姓、58 等类似了，而且这样摆摊的实现难度也会大大降低，在加上 SNS 和 LBS，摆摊就可以提供比赶集、百姓、58 等更精准的信息服务了。\n这几天只是做了一些准备工作，熟悉了 sae 的环境，网站的架构也基本完成，页面上的设计也差不多了，接下来就是定下摆摊网的初步方向，确定第一阶段的核心功能，将其业务逻辑实现了。\n加油！\n","permalink":"https://lewang.dev/posts/2011-11-08-think-of-baigetan/","summary":"今天是十一假期归来的第一天，实验室也启用了新的管理制度，坐在北洋楼的实验室也有一会儿了，刚发了一会儿呆，对摆摊又有了一些新的思考。\n我的目标是想把摆摊做成高校的网上交易平台，也就是类似淘宝，但是作为摆摊网的初期是不合适的，因为这个交易平台太大太复杂。\n所以摆摊的第一步还是做交易信息的发布和检索，主打高校的书籍和物品交易信息，交易还是线下完成，这样，初期的摆摊应该就和赶集、百姓、58 等类似了，而且这样摆摊的实现难度也会大大降低，在加上 SNS 和 LBS，摆摊就可以提供比赶集、百姓、58 等更精准的信息服务了。\n这几天只是做了一些准备工作，熟悉了 sae 的环境，网站的架构也基本完成，页面上的设计也差不多了，接下来就是定下摆摊网的初步方向，确定第一阶段的核心功能，将其业务逻辑实现了。\n加油！","title":"关于摆摊的一些思考"},{"content":"从泰山回来这几天，抽得空把摆摊网的页面做了出来，包括 css 和 html 的编写等，现在可以从 baitan.sinaapp.com 看到页面效果了，目前兼容 ie8、ff、chrome、safari 等。\nbaitan001.com 也在备案之中，应该很快就可以使用 baitan001.com 域名访问了。\n有同学想练习 js，php 等 web 技术的，不妨联系我，我肯定能让你参与进来！\n我是小码哥\n","permalink":"https://lewang.dev/posts/2011-11-07-design-of-baigetan/","summary":"从泰山回来这几天，抽得空把摆摊网的页面做了出来，包括 css 和 html 的编写等，现在可以从 baitan.sinaapp.com 看到页面效果了，目前兼容 ie8、ff、chrome、safari 等。\nbaitan001.com 也在备案之中，应该很快就可以使用 baitan001.com 域名访问了。\n有同学想练习 js，php 等 web 技术的，不妨联系我，我肯定能让你参与进来！\n我是小码哥","title":"摆摊网页面设计"},{"content":"前几天一场大降温，把我给冻着了，肚子疼了好几天，还发烧，还好有个小盆友给我“打针喂药”，使得我这几天才得以康复，重现往日风采。\n本来这周五得做论文的报告，于是这周基本都在看论文。谁知这周又冒出了几个公司让我去面试，论文的报告又就此作罢，挪到下周。\n自己的外语很烂，基本没有投什么外企，昨天参加了微策略的面试之后，反而对自己的外语变得有些自信，最后和那位印度面试官聊天，他说我外语挺好，可是小盆友却说他那是在说客套话，不管客套不客套，反正我觉得挺开心，哈哈。。。\n这周末还有几个知名互联网公司的笔试面试，加油！\n关于摆摊，我还是抽出了一些时间来做了一些开发工作。先是看了赶集网吴石展杭州Qcon的关于MySQL数据库开发的三十六条军规，然后立马按照这些军规，对摆摊的数据库结构做了一些更改。此外，还开发了用户注册模块，只是页面还没有美化。\n还是一点一点的来，事情太多，还要搞科研毕业，加油！\n我是小码哥（新浪微博）\n","permalink":"https://lewang.dev/posts/2011-10-27-winter-is-coming/","summary":"前几天一场大降温，把我给冻着了，肚子疼了好几天，还发烧，还好有个小盆友给我“打针喂药”，使得我这几天才得以康复，重现往日风采。\n本来这周五得做论文的报告，于是这周基本都在看论文。谁知这周又冒出了几个公司让我去面试，论文的报告又就此作罢，挪到下周。\n自己的外语很烂，基本没有投什么外企，昨天参加了微策略的面试之后，反而对自己的外语变得有些自信，最后和那位印度面试官聊天，他说我外语挺好，可是小盆友却说他那是在说客套话，不管客套不客套，反正我觉得挺开心，哈哈。。。\n这周末还有几个知名互联网公司的笔试面试，加油！\n关于摆摊，我还是抽出了一些时间来做了一些开发工作。先是看了赶集网吴石展杭州Qcon的关于MySQL数据库开发的三十六条军规，然后立马按照这些军规，对摆摊的数据库结构做了一些更改。此外，还开发了用户注册模块，只是页面还没有美化。\n还是一点一点的来，事情太多，还要搞科研毕业，加油！\n我是小码哥（新浪微博）","title":"冬天来了"},{"content":"这段时间都在进行密集的笔试面试，但还是没有停下摆摊网的开发进程。目前摆摊网已经由吴江川同学设计好了产品的原型，我也在原型的基础上做好了全部页面的设计工作，接下来就是开始后台逻辑的开发。\n目前后台数据库部分已经设计完毕。\n加油！\n我是小码哥\n","permalink":"https://lewang.dev/posts/2011-10-21-process-of-baigetan/","summary":"这段时间都在进行密集的笔试面试，但还是没有停下摆摊网的开发进程。目前摆摊网已经由吴江川同学设计好了产品的原型，我也在原型的基础上做好了全部页面的设计工作，接下来就是开始后台逻辑的开发。\n目前后台数据库部分已经设计完毕。\n加油！\n我是小码哥","title":"摆摊的一些进展"},{"content":"早上睡到9点才起床，然后下楼载着小盆友去学三吃了早饭，一人吃了六个小包子，出了食堂发现天气真好，决定去拍些照片，然后又载着小盆友回到宿舍拿了相机。\n今天天气真好，微微的风，蓝蓝的天，枝头的树叶也变成了整片整片的金黄，好美！\n东西都已经收拾好了，明天一早出发，去泰山，看日出。\n我是小码哥\n","permalink":"https://lewang.dev/posts/2011-10-01-snapshot-of-10-1/","summary":"早上睡到9点才起床，然后下楼载着小盆友去学三吃了早饭，一人吃了六个小包子，出了食堂发现天气真好，决定去拍些照片，然后又载着小盆友回到宿舍拿了相机。\n今天天气真好，微微的风，蓝蓝的天，枝头的树叶也变成了整片整片的金黄，好美！\n东西都已经收拾好了，明天一早出发，去泰山，看日出。\n我是小码哥","title":"十一掠影"},{"content":"小碼哥，或樂哥\n过往与向往 兲朝哏都七里台职业技术学院相声专业(CS)硕士毕业 混迹六七八三个里台八年，走了一条学生、老师、学生曲折漫长的校园之路，除了一纸文凭之外，更是收获了爱情、友情和师生情 喜折腾，瞎折腾，机缘巧合来到魔都并定居在此 技校授得一技之长，努力成为一名匠人 联系方式 Email: atob('bGV3YW5nLmRldkBnbWFpbC5jb20=') 微博: @小码哥 Twitter: @lewangdev GitHub: @lewangdev GPG Key GPG Public Key Fingerprint: 535B 1620 1E5F 16DC 1DF1 59FA A1D0 BEAD 740F 69DE 关于本站 本网站使用 Hugo 静态博客生成器构建，托管在 Github Pages 服务上，本站 GitHub 仓库地址是 lewangdev.github.io。\n","permalink":"https://lewang.dev/about/","summary":"小碼哥，或樂哥\n过往与向往 兲朝哏都七里台职业技术学院相声专业(CS)硕士毕业 混迹六七八三个里台八年，走了一条学生、老师、学生曲折漫长的校园之路，除了一纸文凭之外，更是收获了爱情、友情和师生情 喜折腾，瞎折腾，机缘巧合来到魔都并定居在此 技校授得一技之长，努力成为一名匠人 联系方式 Email: atob('bGV3YW5nLmRldkBnbWFpbC5jb20=') 微博: @小码哥 Twitter: @lewangdev GitHub: @lewangdev GPG Key GPG Public Key Fingerprint: 535B 1620 1E5F 16DC 1DF1 59FA A1D0 BEAD 740F 69DE 关于本站 本网站使用 Hugo 静态博客生成器构建，托管在 Github Pages 服务上，本站 GitHub 仓库地址是 lewangdev.github.io。","title":"关于我"},{"content":" 点评：留在这里，让自己可以看到以往无知的自己\n一转眼，20 年就过去了，终于要和自己 20 年的学生身份说拜拜了。\n那天去图书馆借书，回来的路上敬业湖桥边的那棵树的时候，心不由得感叹起来，这棵树，我已经拍下了它的春夏秋冬，它叶枯叶落，相似年年，只因它生根于此，我是要走的。\n去图书馆，边走边想，就想到了前几天在知乎上看到的社会化图书馆网站，感觉很不错(而且 UI 做的很不错，想借鉴一下)。想着自己买了好多书，都闲在书架上，是不是也可以搞一个校园图书馆，把同学校的闲书都利用起来。然后又马上否定了自己，因为我自己其实并不愿意把自己买的书借给别人看。这个想法就此作罢。\n想想自己倒是有不少二手书带不走了，得卖掉，还有一些小物件，也带不走了，扔了还挺可惜，也可以卖掉。于是想找找哪里去买，学校 BBS 感觉还可以，但是信息没有分类，不易于检索，而且用户体验很不好。百姓、赶集、58 同城确实可以发布二手信息，但是信息又接近海量，不能针对目标人群——学生，比如我想找同专业学长学姐的书，那就不好找了，再比如我要找我考研学校的资料，那也不好找了，除非去相应的论坛，不然也是很难找。还有个大学生 C2C，这个网站感觉心太大，不靠谱，而且用户体验很差。而且到学生毕业的时候，将会有大量的二手信息，是不是可以考虑搭建一个大学生专用的二手物品交易平台，而且融入校园 SNS 和 LBS 元素，主打二手书籍的交易呢。综合考虑以上，我觉得这挺靠谱的。\n于是我打算开发一个这样的平台——摆摊网\n天大每年有 6000 多的毕业生，如果有 30%的毕业生能使用，那就将近 2000 人，融入 SNS 元素之后，用户会不会爆炸是增加？我觉得流量肯定会有的。\n于是立马动手，先是在美橙互联上注册了域名 baitan001.com (正宗的开心网也是 kaixin001.com )，然后找了几个同学听了他们意见，同时还邀请了两个同学一起来做这个小项目。\n感谢新浪 SAE 给了我实现自己的这个小小梦想的机会，前段时间参加新浪微博应用大赛，对 SAE 也有了一些了解，综合考虑之后，决定就在 SAE 平台上来做摆摊网的开发。\n花了昨天一晚上加上今天一下午，结合以往自己用过的 PHP 框架代码，而且动手折腾出了 Baitan 0.0.1 版本 PHP 框架，兼容 SAE 平台，接下来就是一步一步的把摆摊做出来了。\n这段时间一直忙于找工作，参加各种笔试面试，然后被各种鄙视，当然也收获了不少，短短不到一个月，也已经有了好几个巨头互联网公司的 offer 了，自己的工作也大概就这么定下来了。自己在大学和研究生阶段也折腾过不少东西了，但是还是没有做出一个让自己满意的东西，我想把摆摊网做好，即使没人用，我也自己去维护去完善，当做是自己在种地吧。我有梦想，但最开心的还是有个她愿意倾听我。\n今天把baitan001.com做了域名备案，申请了腾讯的企业邮箱，Baitan 0.0.1 框架的相关测试也已经基本完成，敬请期待摆摊网的到来吧！\n","permalink":"https://lewang.dev/posts/2011-09-28-hello-baigetan/","summary":"点评：留在这里，让自己可以看到以往无知的自己\n一转眼，20 年就过去了，终于要和自己 20 年的学生身份说拜拜了。\n那天去图书馆借书，回来的路上敬业湖桥边的那棵树的时候，心不由得感叹起来，这棵树，我已经拍下了它的春夏秋冬，它叶枯叶落，相似年年，只因它生根于此，我是要走的。\n去图书馆，边走边想，就想到了前几天在知乎上看到的社会化图书馆网站，感觉很不错(而且 UI 做的很不错，想借鉴一下)。想着自己买了好多书，都闲在书架上，是不是也可以搞一个校园图书馆，把同学校的闲书都利用起来。然后又马上否定了自己，因为我自己其实并不愿意把自己买的书借给别人看。这个想法就此作罢。\n想想自己倒是有不少二手书带不走了，得卖掉，还有一些小物件，也带不走了，扔了还挺可惜，也可以卖掉。于是想找找哪里去买，学校 BBS 感觉还可以，但是信息没有分类，不易于检索，而且用户体验很不好。百姓、赶集、58 同城确实可以发布二手信息，但是信息又接近海量，不能针对目标人群——学生，比如我想找同专业学长学姐的书，那就不好找了，再比如我要找我考研学校的资料，那也不好找了，除非去相应的论坛，不然也是很难找。还有个大学生 C2C，这个网站感觉心太大，不靠谱，而且用户体验很差。而且到学生毕业的时候，将会有大量的二手信息，是不是可以考虑搭建一个大学生专用的二手物品交易平台，而且融入校园 SNS 和 LBS 元素，主打二手书籍的交易呢。综合考虑以上，我觉得这挺靠谱的。\n于是我打算开发一个这样的平台——摆摊网\n天大每年有 6000 多的毕业生，如果有 30%的毕业生能使用，那就将近 2000 人，融入 SNS 元素之后，用户会不会爆炸是增加？我觉得流量肯定会有的。\n于是立马动手，先是在美橙互联上注册了域名 baitan001.com (正宗的开心网也是 kaixin001.com )，然后找了几个同学听了他们意见，同时还邀请了两个同学一起来做这个小项目。\n感谢新浪 SAE 给了我实现自己的这个小小梦想的机会，前段时间参加新浪微博应用大赛，对 SAE 也有了一些了解，综合考虑之后，决定就在 SAE 平台上来做摆摊网的开发。\n花了昨天一晚上加上今天一下午，结合以往自己用过的 PHP 框架代码，而且动手折腾出了 Baitan 0.0.1 版本 PHP 框架，兼容 SAE 平台，接下来就是一步一步的把摆摊做出来了。\n这段时间一直忙于找工作，参加各种笔试面试，然后被各种鄙视，当然也收获了不少，短短不到一个月，也已经有了好几个巨头互联网公司的 offer 了，自己的工作也大概就这么定下来了。自己在大学和研究生阶段也折腾过不少东西了，但是还是没有做出一个让自己满意的东西，我想把摆摊网做好，即使没人用，我也自己去维护去完善，当做是自己在种地吧。我有梦想，但最开心的还是有个她愿意倾听我。\n今天把baitan001.com做了域名备案，申请了腾讯的企业邮箱，Baitan 0.0.1 框架的相关测试也已经基本完成，敬请期待摆摊网的到来吧！","title":"摆摊网"},{"content":"","permalink":"https://lewang.dev/archives/","summary":"","title":"归档"}]